Binary Muzzifier_2dim, number of iterations: 10

Parameters info
Tradeoffs parameter: [1.e-02 1.e-01 1.e+00 1.e+01 1.e+02]
Gaussian kernel sigmas: [1.e-03 1.e-02 1.e-01 1.e+00 1.e+01 1.e+02]
Number of principal dimension considerated: 2
Dataset length: 150

Clusterization info
Minimum size of a cluster: in perc: 0.01, in int: 2
Type of mu: Binary Muzzifier
Fuzzifier: Linear
Cluster to label info
Force the number of cluster to be the number of different labels: False
Force the labels to be always represent by a cluster: False

Validation info
Conflict resolution: random


RESULTS

On TEST set

Accuracy on test set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 1.0, 0.1): 0.8

(1, 10.0, 0.1): 0.8

(2, 10.0, 0.1): 0.466666666667

(3, 100.0, 0.1): 0.6

(4, 10.0, 1.0): 0.466666666667

(5, 10.0, 10.0): 0.0666666666667

(6, 10.0, 0.1): 0.733333333333

(7, 1.0, 1.0): 0.266666666667

(8, 1.0, 0.1): 0.666666666667

(9, 10.0, 0.1): 0.6

Loss on test set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 1.0, 0.1): 0.2
(1, 10.0, 0.1): 0.2
(2, 10.0, 0.1): 0.533333333333
(3, 100.0, 0.1): 0.4
(4, 10.0, 1.0): 0.533333333333
(5, 10.0, 10.0): 0.933333333333
(6, 10.0, 0.1): 0.266666666667
(7, 1.0, 1.0): 0.733333333333
(8, 1.0, 0.1): 0.333333333333
(9, 10.0, 0.1): 0.4

Accuracy mean :0.5466666666666666
Std deviation :0.2246973272847029
Loss mean :0.4533333333333334
Std deviation :0.2246973272847029

On TRAINING set

Accuracy on training set for every iteration (n_of_the_iter, c, sigma):
(0, 1.0, 0.1): 0.82962962963
(1, 10.0, 0.1): 0.8
(2, 10.0, 0.1): 0.725925925926
(3, 100.0, 0.1): 0.8
(4, 10.0, 1.0): 0.688888888889
(5, 10.0, 10.0): 0.362962962963
(6, 10.0, 0.1): 0.733333333333
(7, 1.0, 1.0): 0.340740740741
(8, 1.0, 0.1): 0.8
(9, 10.0, 0.1): 0.614814814815
Loss on training set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 1.0, 0.1): 0.17037037037
(1, 10.0, 0.1): 0.2
(2, 10.0, 0.1): 0.274074074074
(3, 100.0, 0.1): 0.2
(4, 10.0, 1.0): 0.311111111111
(5, 10.0, 10.0): 0.637037037037
(6, 10.0, 0.1): 0.266666666667
(7, 1.0, 1.0): 0.659259259259
(8, 1.0, 0.1): 0.2
(9, 10.0, 0.1): 0.385185185185

Accuracy mean :0.6696296296296296
Std deviation :0.17011897716691765
Loss mean :0.33037037037037037
Std deviation :0.17011897716691762

On ALL the sets

Accuracy on all the set for every iteration, for every couple c,sigma (n_of_the_iter, c, sigma):
(0, 0.1, 1.0): 0.2

(0, 0.1, 10.0): 0.2

(0, 0.1, 100.0): 0.2

(0, 1.0, 0.1): 0.8

(0, 1.0, 1.0): 0.2

(0, 1.0, 10.0): 0.2

(0, 1.0, 100.0): 0.2

(0, 10.0, 0.1): 0.733333333333

(0, 10.0, 1.0): 0.2

(0, 10.0, 10.0): 0.2

(0, 10.0, 100.0): 0.2

(0, 100.0, 0.1): 0.666666666667

(0, 100.0, 1.0): 0.2

(0, 100.0, 10.0): 0.2

(0, 100.0, 100.0): 0.2

(1, 0.1, 1.0): 0.266666666667

(1, 0.1, 10.0): 0.266666666667

(1, 0.1, 100.0): 0.266666666667

(1, 1.0, 0.1): 0.733333333333

(1, 1.0, 1.0): 0.266666666667

(1, 1.0, 10.0): 0.266666666667

(1, 1.0, 100.0): 0.266666666667

(1, 10.0, 0.1): 0.866666666667

(1, 10.0, 1.0): 0.266666666667

(1, 10.0, 10.0): 0.266666666667

(1, 10.0, 100.0): 0.266666666667

(1, 100.0, 0.1): 0.8

(1, 100.0, 1.0): 0.266666666667

(1, 100.0, 10.0): 0.266666666667

(1, 100.0, 100.0): 0.266666666667

(2, 0.1, 1.0): 0.2

(2, 0.1, 10.0): 0.2

(2, 0.1, 100.0): 0.2

(2, 1.0, 0.1): 0.8

(2, 1.0, 1.0): 0.2

(2, 1.0, 10.0): 0.2

(2, 1.0, 100.0): 0.2

(2, 10.0, 0.1): 0.866666666667

(2, 10.0, 1.0): 0.2

(2, 10.0, 10.0): 0.2

(2, 10.0, 100.0): 0.2

(2, 100.0, 0.1): 0.8

(2, 100.0, 1.0): 0.2

(2, 100.0, 10.0): 0.2

(2, 100.0, 100.0): 0.2

(3, 0.1, 10.0): 0.4

(3, 0.1, 100.0): 0.4

(3, 1.0, 0.1): 0.733333333333

(3, 1.0, 1.0): 0.4

(3, 1.0, 10.0): 0.4

(3, 1.0, 100.0): 0.4

(3, 10.0, 0.1): 0.666666666667

(3, 10.0, 1.0): 0.4

(3, 10.0, 10.0): 0.4

(3, 10.0, 100.0): 0.4

(3, 100.0, 0.1): 0.8

(3, 100.0, 1.0): 0.4

(3, 100.0, 10.0): 0.4

(3, 100.0, 100.0): 0.4

(4, 0.1, 1.0): 0.866666666667

(4, 0.1, 10.0): 0.266666666667

(4, 0.1, 100.0): 0.266666666667

(4, 1.0, 0.1): 0.6

(4, 1.0, 1.0): 0.866666666667

(4, 1.0, 10.0): 0.266666666667

(4, 1.0, 100.0): 0.266666666667

(4, 10.0, 0.1): 0.733333333333

(4, 10.0, 1.0): 0.866666666667

(4, 10.0, 10.0): 0.266666666667

(4, 10.0, 100.0): 0.266666666667

(4, 100.0, 0.1): 0.533333333333

(4, 100.0, 1.0): 0.866666666667

(4, 100.0, 10.0): 0.266666666667

(4, 100.0, 100.0): 0.266666666667

(5, 0.1, 1.0): 0.2

(5, 0.1, 10.0): 0.2

(5, 0.1, 100.0): 0.2

(5, 1.0, 0.1): 0.2

(5, 1.0, 1.0): 0.2

(5, 1.0, 10.0): 0.2

(5, 1.0, 100.0): 0.2

(5, 10.0, 1.0): 0.2

(5, 10.0, 10.0): 0.2

(5, 10.0, 100.0): 0.2

(5, 100.0, 1.0): 0.2

(5, 100.0, 10.0): 0.2

(5, 100.0, 100.0): 0.2

(6, 0.1, 1.0): 0.2

(6, 0.1, 10.0): 0.2

(6, 0.1, 100.0): 0.2

(6, 1.0, 0.1): 0.533333333333

(6, 1.0, 1.0): 0.2

(6, 1.0, 10.0): 0.2

(6, 1.0, 100.0): 0.2

(6, 10.0, 0.1): 0.8

(6, 10.0, 1.0): 0.2

(6, 10.0, 10.0): 0.2

(6, 10.0, 100.0): 0.2

(6, 100.0, 0.1): 0.6

(6, 100.0, 1.0): 0.2

(6, 100.0, 10.0): 0.2

(6, 100.0, 100.0): 0.2

(7, 0.1, 1.0): 0.2

(7, 0.1, 10.0): 0.2

(7, 0.1, 100.0): 0.2

(7, 1.0, 0.1): 0.266666666667

(7, 1.0, 1.0): 0.666666666667

(7, 1.0, 10.0): 0.2

(7, 1.0, 100.0): 0.2

(7, 10.0, 0.1): 0.333333333333

(7, 10.0, 1.0): 0.666666666667

(7, 10.0, 10.0): 0.2

(7, 10.0, 100.0): 0.2

(7, 100.0, 0.1): 0.6

(7, 100.0, 1.0): 0.666666666667

(7, 100.0, 10.0): 0.2

(7, 100.0, 100.0): 0.2

(8, 0.1, 1.0): 0.4

(8, 0.1, 10.0): 0.4

(8, 0.1, 100.0): 0.4

(8, 1.0, 0.1): 0.866666666667

(8, 1.0, 1.0): 0.4

(8, 1.0, 10.0): 0.4

(8, 1.0, 100.0): 0.4

(8, 10.0, 0.1): 0.733333333333

(8, 10.0, 1.0): 0.4

(8, 10.0, 10.0): 0.4

(8, 10.0, 100.0): 0.4

(8, 100.0, 0.1): 0.8

(8, 100.0, 1.0): 0.4

(8, 100.0, 10.0): 0.4

(8, 100.0, 100.0): 0.4

(9, 0.1, 1.0): 0.4

(9, 0.1, 10.0): 0.4

(9, 0.1, 100.0): 0.4

(9, 1.0, 0.1): 0.6

(9, 1.0, 1.0): 0.4

(9, 1.0, 10.0): 0.4

(9, 1.0, 100.0): 0.4

(9, 10.0, 0.1): 0.666666666667

(9, 10.0, 1.0): 0.4

(9, 10.0, 10.0): 0.4

(9, 10.0, 100.0): 0.4

(9, 100.0, 0.1): 0.533333333333

(9, 100.0, 1.0): 0.4

(9, 100.0, 10.0): 0.4

(9, 100.0, 100.0): 0.4

Loss on all the set for every iteration, for every couple c,sigma (n_of_the_iter, best_c, best_sigma):
(0, 0.1, 1.0): 0.8
(0, 0.1, 10.0): 0.8
(0, 0.1, 100.0): 0.8
(0, 1.0, 0.1): 0.2
(0, 1.0, 1.0): 0.8
(0, 1.0, 10.0): 0.8
(0, 1.0, 100.0): 0.8
(0, 10.0, 0.1): 0.266666666667
(0, 10.0, 1.0): 0.8
(0, 10.0, 10.0): 0.8
(0, 10.0, 100.0): 0.8
(0, 100.0, 0.1): 0.333333333333
(0, 100.0, 1.0): 0.8
(0, 100.0, 10.0): 0.8
(0, 100.0, 100.0): 0.8
(1, 0.1, 1.0): 0.733333333333
(1, 0.1, 10.0): 0.733333333333
(1, 0.1, 100.0): 0.733333333333
(1, 1.0, 0.1): 0.266666666667
(1, 1.0, 1.0): 0.733333333333
(1, 1.0, 10.0): 0.733333333333
(1, 1.0, 100.0): 0.733333333333
(1, 10.0, 0.1): 0.133333333333
(1, 10.0, 1.0): 0.733333333333
(1, 10.0, 10.0): 0.733333333333
(1, 10.0, 100.0): 0.733333333333
(1, 100.0, 0.1): 0.2
(1, 100.0, 1.0): 0.733333333333
(1, 100.0, 10.0): 0.733333333333
(1, 100.0, 100.0): 0.733333333333
(2, 0.1, 1.0): 0.8
(2, 0.1, 10.0): 0.8
(2, 0.1, 100.0): 0.8
(2, 1.0, 0.1): 0.2
(2, 1.0, 1.0): 0.8
(2, 1.0, 10.0): 0.8
(2, 1.0, 100.0): 0.8
(2, 10.0, 0.1): 0.133333333333
(2, 10.0, 1.0): 0.8
(2, 10.0, 10.0): 0.8
(2, 10.0, 100.0): 0.8
(2, 100.0, 0.1): 0.2
(2, 100.0, 1.0): 0.8
(2, 100.0, 10.0): 0.8
(2, 100.0, 100.0): 0.8
(3, 0.1, 10.0): 0.6
(3, 0.1, 100.0): 0.6
(3, 1.0, 0.1): 0.266666666667
(3, 1.0, 1.0): 0.6
(3, 1.0, 10.0): 0.6
(3, 1.0, 100.0): 0.6
(3, 10.0, 0.1): 0.333333333333
(3, 10.0, 1.0): 0.6
(3, 10.0, 10.0): 0.6
(3, 10.0, 100.0): 0.6
(3, 100.0, 0.1): 0.2
(3, 100.0, 1.0): 0.6
(3, 100.0, 10.0): 0.6
(3, 100.0, 100.0): 0.6
(4, 0.1, 1.0): 0.133333333333
(4, 0.1, 10.0): 0.733333333333
(4, 0.1, 100.0): 0.733333333333
(4, 1.0, 0.1): 0.4
(4, 1.0, 1.0): 0.133333333333
(4, 1.0, 10.0): 0.733333333333
(4, 1.0, 100.0): 0.733333333333
(4, 10.0, 0.1): 0.266666666667
(4, 10.0, 1.0): 0.133333333333
(4, 10.0, 10.0): 0.733333333333
(4, 10.0, 100.0): 0.733333333333
(4, 100.0, 0.1): 0.466666666667
(4, 100.0, 1.0): 0.133333333333
(4, 100.0, 10.0): 0.733333333333
(4, 100.0, 100.0): 0.733333333333
(5, 0.1, 1.0): 0.8
(5, 0.1, 10.0): 0.8
(5, 0.1, 100.0): 0.8
(5, 1.0, 0.1): 0.8
(5, 1.0, 1.0): 0.8
(5, 1.0, 10.0): 0.8
(5, 1.0, 100.0): 0.8
(5, 10.0, 1.0): 0.8
(5, 10.0, 10.0): 0.8
(5, 10.0, 100.0): 0.8
(5, 100.0, 1.0): 0.8
(5, 100.0, 10.0): 0.8
(5, 100.0, 100.0): 0.8
(6, 0.1, 1.0): 0.8
(6, 0.1, 10.0): 0.8
(6, 0.1, 100.0): 0.8
(6, 1.0, 0.1): 0.466666666667
(6, 1.0, 1.0): 0.8
(6, 1.0, 10.0): 0.8
(6, 1.0, 100.0): 0.8
(6, 10.0, 0.1): 0.2
(6, 10.0, 1.0): 0.8
(6, 10.0, 10.0): 0.8
(6, 10.0, 100.0): 0.8
(6, 100.0, 0.1): 0.4
(6, 100.0, 1.0): 0.8
(6, 100.0, 10.0): 0.8
(6, 100.0, 100.0): 0.8
(7, 0.1, 1.0): 0.8
(7, 0.1, 10.0): 0.8
(7, 0.1, 100.0): 0.8
(7, 1.0, 0.1): 0.733333333333
(7, 1.0, 1.0): 0.333333333333
(7, 1.0, 10.0): 0.8
(7, 1.0, 100.0): 0.8
(7, 10.0, 0.1): 0.666666666667
(7, 10.0, 1.0): 0.333333333333
(7, 10.0, 10.0): 0.8
(7, 10.0, 100.0): 0.8
(7, 100.0, 0.1): 0.4
(7, 100.0, 1.0): 0.333333333333
(7, 100.0, 10.0): 0.8
(7, 100.0, 100.0): 0.8
(8, 0.1, 1.0): 0.6
(8, 0.1, 10.0): 0.6
(8, 0.1, 100.0): 0.6
(8, 1.0, 0.1): 0.133333333333
(8, 1.0, 1.0): 0.6
(8, 1.0, 10.0): 0.6
(8, 1.0, 100.0): 0.6
(8, 10.0, 0.1): 0.266666666667
(8, 10.0, 1.0): 0.6
(8, 10.0, 10.0): 0.6
(8, 10.0, 100.0): 0.6
(8, 100.0, 0.1): 0.2
(8, 100.0, 1.0): 0.6
(8, 100.0, 10.0): 0.6
(8, 100.0, 100.0): 0.6
(9, 0.1, 1.0): 0.6
(9, 0.1, 10.0): 0.6
(9, 0.1, 100.0): 0.6
(9, 1.0, 0.1): 0.4
(9, 1.0, 1.0): 0.6
(9, 1.0, 10.0): 0.6
(9, 1.0, 100.0): 0.6
(9, 10.0, 0.1): 0.333333333333
(9, 10.0, 1.0): 0.6
(9, 10.0, 10.0): 0.6
(9, 10.0, 100.0): 0.6
(9, 100.0, 0.1): 0.466666666667
(9, 100.0, 1.0): 0.6
(9, 100.0, 10.0): 0.6
(9, 100.0, 100.0): 0.6

Accuracy mean :0.37324263038548755
Std deviation :0.2091858549991022
Loss mean :0.6267573696145124
Std deviation :0.20918585499910222



Linear Muzzifier_2dim, number of iterations: 10

Parameters info
Tradeoffs parameter: [1.e-02 1.e-01 1.e+00 1.e+01 1.e+02]
Gaussian kernel sigmas: [1.e-03 1.e-02 1.e-01 1.e+00 1.e+01 1.e+02]
Number of principal dimension considerated: 2
Dataset length: 150

Clusterization info
Minimum size of a cluster: in perc: 0.01, in int: 2
Type of mu: Linear Muzzifier
Fuzzifier: Linear
Cluster to label info
Force the number of cluster to be the number of different labels: False
Force the labels to be always represent by a cluster: False

Validation info
Conflict resolution: random


RESULTS

On TEST set

Accuracy on test set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 0.1, 1.0): 0.666666666667

(1, 100.0, 0.1): 0.466666666667

(2, 100.0, 0.1): 0.866666666667

(3, 10.0, 1.0): 0.266666666667

(4, 0.1, 1.0): 0.2

(5, 0.1, 100.0): 0.2

(6, 100.0, 0.1): 0.733333333333

(7, 1.0, 0.1): 0.333333333333

(8, 1.0, 0.1): 0.733333333333

(9, 10.0, 0.1): 0.8

Loss on test set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 0.1, 1.0): 0.333333333333
(1, 100.0, 0.1): 0.533333333333
(2, 100.0, 0.1): 0.133333333333
(3, 10.0, 1.0): 0.733333333333
(4, 0.1, 1.0): 0.8
(5, 0.1, 100.0): 0.8
(6, 100.0, 0.1): 0.266666666667
(7, 1.0, 0.1): 0.666666666667
(8, 1.0, 0.1): 0.266666666667
(9, 10.0, 0.1): 0.2

Accuracy mean :0.5266666666666667
Std deviation :0.24846193538112296
Loss mean :0.47333333333333333
Std deviation :0.248461935381123

On TRAINING set

Accuracy on training set for every iteration (n_of_the_iter, c, sigma):
(0, 0.1, 1.0): 0.666666666667
(1, 100.0, 0.1): 0.755555555556
(2, 100.0, 0.1): 0.822222222222
(3, 10.0, 1.0): 0.340740740741
(4, 0.1, 1.0): 0.348148148148
(5, 0.1, 100.0): 0.348148148148
(6, 100.0, 0.1): 0.57037037037
(7, 1.0, 0.1): 0.474074074074
(8, 1.0, 0.1): 0.711111111111
(9, 10.0, 0.1): 0.718518518519
Loss on training set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 0.1, 1.0): 0.333333333333
(1, 100.0, 0.1): 0.244444444444
(2, 100.0, 0.1): 0.177777777778
(3, 10.0, 1.0): 0.659259259259
(4, 0.1, 1.0): 0.651851851852
(5, 0.1, 100.0): 0.651851851852
(6, 100.0, 0.1): 0.42962962963
(7, 1.0, 0.1): 0.525925925926
(8, 1.0, 0.1): 0.288888888889
(9, 10.0, 0.1): 0.281481481481

Accuracy mean :0.5755555555555556
Std deviation :0.1758553464659475
Loss mean :0.42444444444444446
Std deviation :0.1758553464659475

On ALL the sets

Accuracy on all the set for every iteration, for every couple c,sigma (n_of_the_iter, c, sigma):
(0, 0.1, 1.0): 0.6

(0, 0.1, 10.0): 0.266666666667

(0, 0.1, 100.0): 0.266666666667

(0, 1.0, 0.1): 0.533333333333

(0, 1.0, 1.0): 0.266666666667

(0, 1.0, 10.0): 0.266666666667

(0, 1.0, 100.0): 0.266666666667

(0, 10.0, 0.1): 0.6

(0, 10.0, 1.0): 0.466666666667

(0, 10.0, 10.0): 0.266666666667

(0, 10.0, 100.0): 0.266666666667

(0, 100.0, 0.1): 0.466666666667

(0, 100.0, 1.0): 0.266666666667

(0, 100.0, 10.0): 0.266666666667

(0, 100.0, 100.0): 0.266666666667

(1, 0.1, 1.0): 0.2

(1, 0.1, 10.0): 0.2

(1, 0.1, 100.0): 0.2

(1, 1.0, 0.1): 0.666666666667

(1, 1.0, 1.0): 0.2

(1, 1.0, 10.0): 0.2

(1, 1.0, 100.0): 0.2

(1, 10.0, 0.1): 0.733333333333

(1, 10.0, 1.0): 0.2

(1, 10.0, 10.0): 0.2

(1, 10.0, 100.0): 0.2

(1, 100.0, 0.1): 0.8

(1, 100.0, 1.0): 0.2

(1, 100.0, 10.0): 0.2

(1, 100.0, 100.0): 0.2

(2, 0.1, 1.0): 0.333333333333

(2, 0.1, 10.0): 0.333333333333

(2, 0.1, 100.0): 0.333333333333

(2, 1.0, 0.1): 0.533333333333

(2, 1.0, 1.0): 0.333333333333

(2, 1.0, 10.0): 0.333333333333

(2, 1.0, 100.0): 0.333333333333

(2, 10.0, 0.1): 0.533333333333

(2, 10.0, 1.0): 0.333333333333

(2, 10.0, 10.0): 0.333333333333

(2, 10.0, 100.0): 0.333333333333

(2, 100.0, 0.1): 0.533333333333

(2, 100.0, 1.0): 0.333333333333

(2, 100.0, 10.0): 0.333333333333

(2, 100.0, 100.0): 0.333333333333

(3, 0.1, 1.0): 0.2

(3, 0.1, 10.0): 0.2

(3, 0.1, 100.0): 0.2

(3, 1.0, 1.0): 0.2

(3, 1.0, 10.0): 0.2

(3, 1.0, 100.0): 0.2

(3, 10.0, 1.0): 0.2

(3, 10.0, 10.0): 0.2

(3, 10.0, 100.0): 0.2

(3, 100.0, 1.0): 0.2

(3, 100.0, 10.0): 0.2

(3, 100.0, 100.0): 0.2

(4, 0.1, 1.0): 0.6

(4, 1.0, 0.1): 0.4

(4, 1.0, 1.0): 0.2

(4, 1.0, 10.0): 0.2

(4, 1.0, 100.0): 0.2

(4, 10.0, 0.1): 0.333333333333

(4, 10.0, 1.0): 0.2

(4, 10.0, 10.0): 0.2

(4, 10.0, 100.0): 0.2

(4, 100.0, 0.1): 0.533333333333

(4, 100.0, 1.0): 0.2

(4, 100.0, 10.0): 0.2

(4, 100.0, 100.0): 0.2

(5, 0.1, 1.0): 0.333333333333

(5, 0.1, 10.0): 0.333333333333

(5, 0.1, 100.0): 0.333333333333

(5, 1.0, 0.1): 0.333333333333

(5, 1.0, 1.0): 0.333333333333

(5, 1.0, 10.0): 0.333333333333

(5, 1.0, 100.0): 0.333333333333

(5, 10.0, 0.1): 0.333333333333

(5, 10.0, 1.0): 0.333333333333

(5, 10.0, 10.0): 0.333333333333

(5, 10.0, 100.0): 0.333333333333

(5, 100.0, 0.1): 0.333333333333

(5, 100.0, 1.0): 0.333333333333

(5, 100.0, 10.0): 0.333333333333

(5, 100.0, 100.0): 0.333333333333

(6, 0.1, 1.0): 0.2

(6, 0.1, 10.0): 0.2

(6, 0.1, 100.0): 0.2

(6, 1.0, 0.1): 0.666666666667

(6, 1.0, 1.0): 0.2

(6, 1.0, 10.0): 0.2

(6, 1.0, 100.0): 0.2

(6, 10.0, 0.1): 0.666666666667

(6, 10.0, 1.0): 0.2

(6, 10.0, 10.0): 0.2

(6, 10.0, 100.0): 0.2

(6, 100.0, 0.1): 0.733333333333

(6, 100.0, 1.0): 0.2

(6, 100.0, 10.0): 0.2

(6, 100.0, 100.0): 0.2

(7, 0.1, 1.0): 0.266666666667

(7, 0.1, 10.0): 0.266666666667

(7, 0.1, 100.0): 0.266666666667

(7, 1.0, 0.1): 0.6

(7, 1.0, 1.0): 0.266666666667

(7, 1.0, 10.0): 0.266666666667

(7, 1.0, 100.0): 0.266666666667

(7, 10.0, 0.1): 0.533333333333

(7, 10.0, 1.0): 0.266666666667

(7, 10.0, 10.0): 0.266666666667

(7, 10.0, 100.0): 0.266666666667

(7, 100.0, 0.1): 0.4

(7, 100.0, 1.0): 0.266666666667

(7, 100.0, 10.0): 0.266666666667

(7, 100.0, 100.0): 0.266666666667

(8, 0.1, 1.0): 0.266666666667

(8, 0.1, 10.0): 0.266666666667

(8, 0.1, 100.0): 0.266666666667

(8, 1.0, 0.1): 0.933333333333

(8, 1.0, 1.0): 0.266666666667

(8, 1.0, 10.0): 0.266666666667

(8, 1.0, 100.0): 0.266666666667

(8, 10.0, 0.1): 0.8

(8, 10.0, 1.0): 0.266666666667

(8, 10.0, 10.0): 0.266666666667

(8, 10.0, 100.0): 0.266666666667

(8, 100.0, 0.1): 0.866666666667

(8, 100.0, 1.0): 0.266666666667

(8, 100.0, 10.0): 0.266666666667

(8, 100.0, 100.0): 0.266666666667

(9, 0.1, 1.0): 0.133333333333

(9, 0.1, 10.0): 0.133333333333

(9, 1.0, 0.1): 0.333333333333

(9, 1.0, 1.0): 0.133333333333

(9, 1.0, 10.0): 0.133333333333

(9, 1.0, 100.0): 0.133333333333

(9, 10.0, 0.1): 0.4

(9, 10.0, 1.0): 0.133333333333

(9, 10.0, 10.0): 0.133333333333

(9, 10.0, 100.0): 0.133333333333

(9, 100.0, 0.1): 0.333333333333

(9, 100.0, 1.0): 0.133333333333

(9, 100.0, 10.0): 0.133333333333

(9, 100.0, 100.0): 0.133333333333

Loss on all the set for every iteration, for every couple c,sigma (n_of_the_iter, best_c, best_sigma):
(0, 0.1, 1.0): 0.4
(0, 0.1, 10.0): 0.733333333333
(0, 0.1, 100.0): 0.733333333333
(0, 1.0, 0.1): 0.466666666667
(0, 1.0, 1.0): 0.733333333333
(0, 1.0, 10.0): 0.733333333333
(0, 1.0, 100.0): 0.733333333333
(0, 10.0, 0.1): 0.4
(0, 10.0, 1.0): 0.533333333333
(0, 10.0, 10.0): 0.733333333333
(0, 10.0, 100.0): 0.733333333333
(0, 100.0, 0.1): 0.533333333333
(0, 100.0, 1.0): 0.733333333333
(0, 100.0, 10.0): 0.733333333333
(0, 100.0, 100.0): 0.733333333333
(1, 0.1, 1.0): 0.8
(1, 0.1, 10.0): 0.8
(1, 0.1, 100.0): 0.8
(1, 1.0, 0.1): 0.333333333333
(1, 1.0, 1.0): 0.8
(1, 1.0, 10.0): 0.8
(1, 1.0, 100.0): 0.8
(1, 10.0, 0.1): 0.266666666667
(1, 10.0, 1.0): 0.8
(1, 10.0, 10.0): 0.8
(1, 10.0, 100.0): 0.8
(1, 100.0, 0.1): 0.2
(1, 100.0, 1.0): 0.8
(1, 100.0, 10.0): 0.8
(1, 100.0, 100.0): 0.8
(2, 0.1, 1.0): 0.666666666667
(2, 0.1, 10.0): 0.666666666667
(2, 0.1, 100.0): 0.666666666667
(2, 1.0, 0.1): 0.466666666667
(2, 1.0, 1.0): 0.666666666667
(2, 1.0, 10.0): 0.666666666667
(2, 1.0, 100.0): 0.666666666667
(2, 10.0, 0.1): 0.466666666667
(2, 10.0, 1.0): 0.666666666667
(2, 10.0, 10.0): 0.666666666667
(2, 10.0, 100.0): 0.666666666667
(2, 100.0, 0.1): 0.466666666667
(2, 100.0, 1.0): 0.666666666667
(2, 100.0, 10.0): 0.666666666667
(2, 100.0, 100.0): 0.666666666667
(3, 0.1, 1.0): 0.8
(3, 0.1, 10.0): 0.8
(3, 0.1, 100.0): 0.8
(3, 1.0, 1.0): 0.8
(3, 1.0, 10.0): 0.8
(3, 1.0, 100.0): 0.8
(3, 10.0, 1.0): 0.8
(3, 10.0, 10.0): 0.8
(3, 10.0, 100.0): 0.8
(3, 100.0, 1.0): 0.8
(3, 100.0, 10.0): 0.8
(3, 100.0, 100.0): 0.8
(4, 0.1, 1.0): 0.4
(4, 1.0, 0.1): 0.6
(4, 1.0, 1.0): 0.8
(4, 1.0, 10.0): 0.8
(4, 1.0, 100.0): 0.8
(4, 10.0, 0.1): 0.666666666667
(4, 10.0, 1.0): 0.8
(4, 10.0, 10.0): 0.8
(4, 10.0, 100.0): 0.8
(4, 100.0, 0.1): 0.466666666667
(4, 100.0, 1.0): 0.8
(4, 100.0, 10.0): 0.8
(4, 100.0, 100.0): 0.8
(5, 0.1, 1.0): 0.666666666667
(5, 0.1, 10.0): 0.666666666667
(5, 0.1, 100.0): 0.666666666667
(5, 1.0, 0.1): 0.666666666667
(5, 1.0, 1.0): 0.666666666667
(5, 1.0, 10.0): 0.666666666667
(5, 1.0, 100.0): 0.666666666667
(5, 10.0, 0.1): 0.666666666667
(5, 10.0, 1.0): 0.666666666667
(5, 10.0, 10.0): 0.666666666667
(5, 10.0, 100.0): 0.666666666667
(5, 100.0, 0.1): 0.666666666667
(5, 100.0, 1.0): 0.666666666667
(5, 100.0, 10.0): 0.666666666667
(5, 100.0, 100.0): 0.666666666667
(6, 0.1, 1.0): 0.8
(6, 0.1, 10.0): 0.8
(6, 0.1, 100.0): 0.8
(6, 1.0, 0.1): 0.333333333333
(6, 1.0, 1.0): 0.8
(6, 1.0, 10.0): 0.8
(6, 1.0, 100.0): 0.8
(6, 10.0, 0.1): 0.333333333333
(6, 10.0, 1.0): 0.8
(6, 10.0, 10.0): 0.8
(6, 10.0, 100.0): 0.8
(6, 100.0, 0.1): 0.266666666667
(6, 100.0, 1.0): 0.8
(6, 100.0, 10.0): 0.8
(6, 100.0, 100.0): 0.8
(7, 0.1, 1.0): 0.733333333333
(7, 0.1, 10.0): 0.733333333333
(7, 0.1, 100.0): 0.733333333333
(7, 1.0, 0.1): 0.4
(7, 1.0, 1.0): 0.733333333333
(7, 1.0, 10.0): 0.733333333333
(7, 1.0, 100.0): 0.733333333333
(7, 10.0, 0.1): 0.466666666667
(7, 10.0, 1.0): 0.733333333333
(7, 10.0, 10.0): 0.733333333333
(7, 10.0, 100.0): 0.733333333333
(7, 100.0, 0.1): 0.6
(7, 100.0, 1.0): 0.733333333333
(7, 100.0, 10.0): 0.733333333333
(7, 100.0, 100.0): 0.733333333333
(8, 0.1, 1.0): 0.733333333333
(8, 0.1, 10.0): 0.733333333333
(8, 0.1, 100.0): 0.733333333333
(8, 1.0, 0.1): 0.0666666666667
(8, 1.0, 1.0): 0.733333333333
(8, 1.0, 10.0): 0.733333333333
(8, 1.0, 100.0): 0.733333333333
(8, 10.0, 0.1): 0.2
(8, 10.0, 1.0): 0.733333333333
(8, 10.0, 10.0): 0.733333333333
(8, 10.0, 100.0): 0.733333333333
(8, 100.0, 0.1): 0.133333333333
(8, 100.0, 1.0): 0.733333333333
(8, 100.0, 10.0): 0.733333333333
(8, 100.0, 100.0): 0.733333333333
(9, 0.1, 1.0): 0.866666666667
(9, 0.1, 10.0): 0.866666666667
(9, 1.0, 0.1): 0.666666666667
(9, 1.0, 1.0): 0.866666666667
(9, 1.0, 10.0): 0.866666666667
(9, 1.0, 100.0): 0.866666666667
(9, 10.0, 0.1): 0.6
(9, 10.0, 1.0): 0.866666666667
(9, 10.0, 10.0): 0.866666666667
(9, 10.0, 100.0): 0.866666666667
(9, 100.0, 0.1): 0.666666666667
(9, 100.0, 1.0): 0.866666666667
(9, 100.0, 10.0): 0.866666666667
(9, 100.0, 100.0): 0.866666666667

Accuracy mean :0.30648148148148147
Std deviation :0.15798098112685974
Loss mean :0.6935185185185184
Std deviation :0.15798098112685974



Binary Muzzifier_3dim, number of iterations: 10

Parameters info
Tradeoffs parameter: [1.e-02 1.e-01 1.e+00 1.e+01 1.e+02]
Gaussian kernel sigmas: [1.e-03 1.e-02 1.e-01 1.e+00 1.e+01 1.e+02]
Number of principal dimension considerated: 3
Dataset length: 150

Clusterization info
Minimum size of a cluster: in perc: 0.01, in int: 2
Type of mu: Binary Muzzifier
Fuzzifier: Linear
Cluster to label info
Force the number of cluster to be the number of different labels: False
Force the labels to be always represent by a cluster: False

Validation info
Conflict resolution: random


RESULTS

On TEST set

Accuracy on test set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 1.0, 1.0): 0.2

(1, 0.1, 10.0): 0.2

(2, 100.0, 1.0): 0.6

(3, 1.0, 100.0): 0.266666666667

(4, 1.0, 1.0): 0.266666666667

(5, 0.1, 1.0): 0.666666666667

(6, 100.0, 1.0): 0.133333333333

(7, 100.0, 1.0): 0.2

(8, 0.1, 1.0): 0.266666666667

(9, 1.0, 10.0): 0.266666666667

Loss on test set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 1.0, 1.0): 0.8
(1, 0.1, 10.0): 0.8
(2, 100.0, 1.0): 0.4
(3, 1.0, 100.0): 0.733333333333
(4, 1.0, 1.0): 0.733333333333
(5, 0.1, 1.0): 0.333333333333
(6, 100.0, 1.0): 0.866666666667
(7, 100.0, 1.0): 0.8
(8, 0.1, 1.0): 0.733333333333
(9, 1.0, 10.0): 0.733333333333

Accuracy mean :0.3066666666666667
Std deviation :0.16918103387266026
Loss mean :0.6933333333333334
Std deviation :0.16918103387266029

On TRAINING set

Accuracy on training set for every iteration (n_of_the_iter, c, sigma):
(0, 1.0, 1.0): 0.348148148148
(1, 0.1, 10.0): 0.348148148148
(2, 100.0, 1.0): 0.674074074074
(3, 1.0, 100.0): 0.340740740741
(4, 1.0, 1.0): 0.340740740741
(5, 0.1, 1.0): 0.666666666667
(6, 100.0, 1.0): 0.355555555556
(7, 100.0, 1.0): 0.348148148148
(8, 0.1, 1.0): 0.340740740741
(9, 1.0, 10.0): 0.340740740741
Loss on training set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 1.0, 1.0): 0.651851851852
(1, 0.1, 10.0): 0.651851851852
(2, 100.0, 1.0): 0.325925925926
(3, 1.0, 100.0): 0.659259259259
(4, 1.0, 1.0): 0.659259259259
(5, 0.1, 1.0): 0.333333333333
(6, 100.0, 1.0): 0.644444444444
(7, 100.0, 1.0): 0.651851851852
(8, 0.1, 1.0): 0.659259259259
(9, 1.0, 10.0): 0.659259259259

Accuracy mean :0.4103703703703704
Std deviation :0.13009229603234945
Loss mean :0.5896296296296296
Std deviation :0.13009229603234948

On ALL the sets

Accuracy on all the set for every iteration, for every couple c,sigma (n_of_the_iter, c, sigma):
(0, 0.1, 1.0): 0.4

(0, 0.1, 10.0): 0.4

(0, 0.1, 100.0): 0.4

(0, 1.0, 1.0): 0.4

(0, 1.0, 10.0): 0.4

(0, 1.0, 100.0): 0.4

(0, 10.0, 1.0): 0.4

(0, 10.0, 10.0): 0.4

(0, 10.0, 100.0): 0.4

(0, 100.0, 1.0): 0.4

(0, 100.0, 10.0): 0.4

(0, 100.0, 100.0): 0.4

(1, 0.1, 1.0): 0.333333333333

(1, 0.1, 10.0): 0.333333333333

(1, 0.1, 100.0): 0.333333333333

(1, 1.0, 1.0): 0.333333333333

(1, 1.0, 10.0): 0.333333333333

(1, 1.0, 100.0): 0.333333333333

(1, 10.0, 1.0): 0.333333333333

(1, 10.0, 10.0): 0.333333333333

(1, 10.0, 100.0): 0.333333333333

(1, 100.0, 1.0): 0.333333333333

(1, 100.0, 10.0): 0.333333333333

(1, 100.0, 100.0): 0.333333333333

(2, 0.1, 1.0): 0.2

(2, 0.1, 10.0): 0.2

(2, 0.1, 100.0): 0.2

(2, 1.0, 1.0): 0.2

(2, 1.0, 10.0): 0.2

(2, 1.0, 100.0): 0.2

(2, 10.0, 1.0): 0.666666666667

(2, 10.0, 10.0): 0.2

(2, 10.0, 100.0): 0.2

(2, 100.0, 1.0): 0.666666666667

(2, 100.0, 10.0): 0.2

(2, 100.0, 100.0): 0.2

(3, 0.1, 1.0): 0.266666666667

(3, 0.1, 10.0): 0.266666666667

(3, 0.1, 100.0): 0.266666666667

(3, 1.0, 1.0): 0.266666666667

(3, 1.0, 10.0): 0.266666666667

(3, 1.0, 100.0): 0.266666666667

(3, 10.0, 1.0): 0.266666666667

(3, 10.0, 10.0): 0.266666666667

(3, 10.0, 100.0): 0.266666666667

(3, 100.0, 1.0): 0.266666666667

(3, 100.0, 10.0): 0.266666666667

(3, 100.0, 100.0): 0.266666666667

(4, 0.1, 1.0): 0.0666666666667

(4, 0.1, 10.0): 0.0666666666667

(4, 0.1, 100.0): 0.0666666666667

(4, 1.0, 1.0): 0.0666666666667

(4, 1.0, 10.0): 0.0666666666667

(4, 1.0, 100.0): 0.0666666666667

(4, 10.0, 1.0): 0.0666666666667

(4, 10.0, 10.0): 0.0666666666667

(4, 10.0, 100.0): 0.0666666666667

(4, 100.0, 1.0): 0.0666666666667

(4, 100.0, 10.0): 0.0666666666667

(4, 100.0, 100.0): 0.0666666666667

(5, 0.1, 1.0): 0.4

(5, 0.1, 10.0): 0.0666666666667

(5, 0.1, 100.0): 0.0666666666667

(5, 1.0, 1.0): 0.4

(5, 1.0, 10.0): 0.0666666666667

(5, 1.0, 100.0): 0.0666666666667

(5, 10.0, 1.0): 0.4

(5, 10.0, 10.0): 0.0666666666667

(5, 10.0, 100.0): 0.0666666666667

(5, 100.0, 1.0): 0.0666666666667

(5, 100.0, 10.0): 0.0666666666667

(5, 100.0, 100.0): 0.0666666666667

(6, 0.1, 1.0): 0.0666666666667

(6, 0.1, 10.0): 0.0666666666667

(6, 0.1, 100.0): 0.0666666666667

(6, 1.0, 1.0): 0.0666666666667

(6, 1.0, 10.0): 0.0666666666667

(6, 1.0, 100.0): 0.0666666666667

(6, 10.0, 1.0): 0.0666666666667

(6, 10.0, 10.0): 0.0666666666667

(6, 10.0, 100.0): 0.0666666666667

(6, 100.0, 1.0): 0.0666666666667

(6, 100.0, 10.0): 0.0666666666667

(6, 100.0, 100.0): 0.0666666666667

(7, 0.1, 1.0): 0.333333333333

(7, 0.1, 10.0): 0.333333333333

(7, 0.1, 100.0): 0.333333333333

(7, 1.0, 1.0): 0.333333333333

(7, 1.0, 10.0): 0.333333333333

(7, 1.0, 100.0): 0.333333333333

(7, 10.0, 1.0): 0.333333333333

(7, 10.0, 10.0): 0.333333333333

(7, 10.0, 100.0): 0.333333333333

(7, 100.0, 1.0): 0.666666666667

(7, 100.0, 10.0): 0.333333333333

(7, 100.0, 100.0): 0.333333333333

(8, 0.1, 1.0): 0.266666666667

(8, 0.1, 10.0): 0.266666666667

(8, 0.1, 100.0): 0.266666666667

(8, 1.0, 1.0): 0.266666666667

(8, 1.0, 10.0): 0.266666666667

(8, 1.0, 100.0): 0.266666666667

(8, 10.0, 1.0): 0.266666666667

(8, 10.0, 10.0): 0.266666666667

(8, 10.0, 100.0): 0.266666666667

(8, 100.0, 1.0): 0.266666666667

(8, 100.0, 10.0): 0.266666666667

(8, 100.0, 100.0): 0.266666666667

(9, 0.1, 1.0): 0.266666666667

(9, 0.1, 10.0): 0.266666666667

(9, 0.1, 100.0): 0.266666666667

(9, 1.0, 1.0): 0.266666666667

(9, 1.0, 10.0): 0.266666666667

(9, 1.0, 100.0): 0.266666666667

(9, 10.0, 1.0): 0.266666666667

(9, 10.0, 10.0): 0.266666666667

(9, 10.0, 100.0): 0.266666666667

(9, 100.0, 1.0): 0.266666666667

(9, 100.0, 10.0): 0.266666666667

(9, 100.0, 100.0): 0.266666666667

Loss on all the set for every iteration, for every couple c,sigma (n_of_the_iter, best_c, best_sigma):
(0, 0.1, 1.0): 0.6
(0, 0.1, 10.0): 0.6
(0, 0.1, 100.0): 0.6
(0, 1.0, 1.0): 0.6
(0, 1.0, 10.0): 0.6
(0, 1.0, 100.0): 0.6
(0, 10.0, 1.0): 0.6
(0, 10.0, 10.0): 0.6
(0, 10.0, 100.0): 0.6
(0, 100.0, 1.0): 0.6
(0, 100.0, 10.0): 0.6
(0, 100.0, 100.0): 0.6
(1, 0.1, 1.0): 0.666666666667
(1, 0.1, 10.0): 0.666666666667
(1, 0.1, 100.0): 0.666666666667
(1, 1.0, 1.0): 0.666666666667
(1, 1.0, 10.0): 0.666666666667
(1, 1.0, 100.0): 0.666666666667
(1, 10.0, 1.0): 0.666666666667
(1, 10.0, 10.0): 0.666666666667
(1, 10.0, 100.0): 0.666666666667
(1, 100.0, 1.0): 0.666666666667
(1, 100.0, 10.0): 0.666666666667
(1, 100.0, 100.0): 0.666666666667
(2, 0.1, 1.0): 0.8
(2, 0.1, 10.0): 0.8
(2, 0.1, 100.0): 0.8
(2, 1.0, 1.0): 0.8
(2, 1.0, 10.0): 0.8
(2, 1.0, 100.0): 0.8
(2, 10.0, 1.0): 0.333333333333
(2, 10.0, 10.0): 0.8
(2, 10.0, 100.0): 0.8
(2, 100.0, 1.0): 0.333333333333
(2, 100.0, 10.0): 0.8
(2, 100.0, 100.0): 0.8
(3, 0.1, 1.0): 0.733333333333
(3, 0.1, 10.0): 0.733333333333
(3, 0.1, 100.0): 0.733333333333
(3, 1.0, 1.0): 0.733333333333
(3, 1.0, 10.0): 0.733333333333
(3, 1.0, 100.0): 0.733333333333
(3, 10.0, 1.0): 0.733333333333
(3, 10.0, 10.0): 0.733333333333
(3, 10.0, 100.0): 0.733333333333
(3, 100.0, 1.0): 0.733333333333
(3, 100.0, 10.0): 0.733333333333
(3, 100.0, 100.0): 0.733333333333
(4, 0.1, 1.0): 0.933333333333
(4, 0.1, 10.0): 0.933333333333
(4, 0.1, 100.0): 0.933333333333
(4, 1.0, 1.0): 0.933333333333
(4, 1.0, 10.0): 0.933333333333
(4, 1.0, 100.0): 0.933333333333
(4, 10.0, 1.0): 0.933333333333
(4, 10.0, 10.0): 0.933333333333
(4, 10.0, 100.0): 0.933333333333
(4, 100.0, 1.0): 0.933333333333
(4, 100.0, 10.0): 0.933333333333
(4, 100.0, 100.0): 0.933333333333
(5, 0.1, 1.0): 0.6
(5, 0.1, 10.0): 0.933333333333
(5, 0.1, 100.0): 0.933333333333
(5, 1.0, 1.0): 0.6
(5, 1.0, 10.0): 0.933333333333
(5, 1.0, 100.0): 0.933333333333
(5, 10.0, 1.0): 0.6
(5, 10.0, 10.0): 0.933333333333
(5, 10.0, 100.0): 0.933333333333
(5, 100.0, 1.0): 0.933333333333
(5, 100.0, 10.0): 0.933333333333
(5, 100.0, 100.0): 0.933333333333
(6, 0.1, 1.0): 0.933333333333
(6, 0.1, 10.0): 0.933333333333
(6, 0.1, 100.0): 0.933333333333
(6, 1.0, 1.0): 0.933333333333
(6, 1.0, 10.0): 0.933333333333
(6, 1.0, 100.0): 0.933333333333
(6, 10.0, 1.0): 0.933333333333
(6, 10.0, 10.0): 0.933333333333
(6, 10.0, 100.0): 0.933333333333
(6, 100.0, 1.0): 0.933333333333
(6, 100.0, 10.0): 0.933333333333
(6, 100.0, 100.0): 0.933333333333
(7, 0.1, 1.0): 0.666666666667
(7, 0.1, 10.0): 0.666666666667
(7, 0.1, 100.0): 0.666666666667
(7, 1.0, 1.0): 0.666666666667
(7, 1.0, 10.0): 0.666666666667
(7, 1.0, 100.0): 0.666666666667
(7, 10.0, 1.0): 0.666666666667
(7, 10.0, 10.0): 0.666666666667
(7, 10.0, 100.0): 0.666666666667
(7, 100.0, 1.0): 0.333333333333
(7, 100.0, 10.0): 0.666666666667
(7, 100.0, 100.0): 0.666666666667
(8, 0.1, 1.0): 0.733333333333
(8, 0.1, 10.0): 0.733333333333
(8, 0.1, 100.0): 0.733333333333
(8, 1.0, 1.0): 0.733333333333
(8, 1.0, 10.0): 0.733333333333
(8, 1.0, 100.0): 0.733333333333
(8, 10.0, 1.0): 0.733333333333
(8, 10.0, 10.0): 0.733333333333
(8, 10.0, 100.0): 0.733333333333
(8, 100.0, 1.0): 0.733333333333
(8, 100.0, 10.0): 0.733333333333
(8, 100.0, 100.0): 0.733333333333
(9, 0.1, 1.0): 0.733333333333
(9, 0.1, 10.0): 0.733333333333
(9, 0.1, 100.0): 0.733333333333
(9, 1.0, 1.0): 0.733333333333
(9, 1.0, 10.0): 0.733333333333
(9, 1.0, 100.0): 0.733333333333
(9, 10.0, 1.0): 0.733333333333
(9, 10.0, 10.0): 0.733333333333
(9, 10.0, 100.0): 0.733333333333
(9, 100.0, 1.0): 0.733333333333
(9, 100.0, 10.0): 0.733333333333
(9, 100.0, 100.0): 0.733333333333

Accuracy mean :0.24555555555555558
Std deviation :0.13415947760817634
Loss mean :0.7544444444444445
Std deviation :0.13415947760817634



Linear Muzzifier_3dim, number of iterations: 10

Parameters info
Tradeoffs parameter: [1.e-02 1.e-01 1.e+00 1.e+01 1.e+02]
Gaussian kernel sigmas: [1.e-03 1.e-02 1.e-01 1.e+00 1.e+01 1.e+02]
Number of principal dimension considerated: 3
Dataset length: 150

Clusterization info
Minimum size of a cluster: in perc: 0.01, in int: 2
Type of mu: Linear Muzzifier
Fuzzifier: Linear
Cluster to label info
Force the number of cluster to be the number of different labels: False
Force the labels to be always represent by a cluster: False

Validation info
Conflict resolution: random


RESULTS

On TEST set

Accuracy on test set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 100.0, 10.0): 0.2

(1, 1.0, 1.0): 0.266666666667

(2, 0.1, 100.0): 0.2

(3, 100.0, 100.0): 0.2

(4, 0.1, 10.0): 0.266666666667

(5, 1.0, 1.0): 0.2

(6, 0.1, 1.0): 0.266666666667

(7, 1.0, 100.0): 0.266666666667

(8, 100.0, 1.0): 0.333333333333

(9, 0.1, 1.0): 0.266666666667

Loss on test set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 100.0, 10.0): 0.8
(1, 1.0, 1.0): 0.733333333333
(2, 0.1, 100.0): 0.8
(3, 100.0, 100.0): 0.8
(4, 0.1, 10.0): 0.733333333333
(5, 1.0, 1.0): 0.8
(6, 0.1, 1.0): 0.733333333333
(7, 1.0, 100.0): 0.733333333333
(8, 100.0, 1.0): 0.666666666667
(9, 0.1, 1.0): 0.733333333333

Accuracy mean :0.24666666666666667
Std deviation :0.04268749491621898
Loss mean :0.7533333333333333
Std deviation :0.04268749491621903

On TRAINING set

Accuracy on training set for every iteration (n_of_the_iter, c, sigma):
(0, 100.0, 10.0): 0.348148148148
(1, 1.0, 1.0): 0.340740740741
(2, 0.1, 100.0): 0.348148148148
(3, 100.0, 100.0): 0.348148148148
(4, 0.1, 10.0): 0.340740740741
(5, 1.0, 1.0): 0.348148148148
(6, 0.1, 1.0): 0.340740740741
(7, 1.0, 100.0): 0.340740740741
(8, 100.0, 1.0): 0.333333333333
(9, 0.1, 1.0): 0.340740740741
Loss on training set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 100.0, 10.0): 0.651851851852
(1, 1.0, 1.0): 0.659259259259
(2, 0.1, 100.0): 0.651851851852
(3, 100.0, 100.0): 0.651851851852
(4, 0.1, 10.0): 0.659259259259
(5, 1.0, 1.0): 0.651851851852
(6, 0.1, 1.0): 0.659259259259
(7, 1.0, 100.0): 0.659259259259
(8, 100.0, 1.0): 0.666666666667
(9, 0.1, 1.0): 0.659259259259

Accuracy mean :0.3429629629629629
Std deviation :0.004743054990691006
Loss mean :0.657037037037037
Std deviation :0.004743054990690957

On ALL the sets

Accuracy on all the set for every iteration, for every couple c,sigma (n_of_the_iter, c, sigma):
(0, 0.1, 1.0): 0.4

(0, 0.1, 10.0): 0.4

(0, 0.1, 100.0): 0.4

(0, 1.0, 1.0): 0.4

(0, 1.0, 10.0): 0.4

(0, 1.0, 100.0): 0.4

(0, 10.0, 1.0): 0.4

(0, 10.0, 10.0): 0.4

(0, 10.0, 100.0): 0.4

(0, 100.0, 1.0): 0.4

(0, 100.0, 10.0): 0.4

(0, 100.0, 100.0): 0.4

(1, 0.1, 1.0): 0.333333333333

(1, 0.1, 10.0): 0.333333333333

(1, 0.1, 100.0): 0.333333333333

(1, 1.0, 1.0): 0.533333333333

(1, 1.0, 10.0): 0.333333333333

(1, 1.0, 100.0): 0.333333333333

(1, 10.0, 1.0): 0.266666666667

(1, 10.0, 10.0): 0.333333333333

(1, 10.0, 100.0): 0.333333333333

(1, 100.0, 1.0): 0.466666666667

(1, 100.0, 10.0): 0.333333333333

(1, 100.0, 100.0): 0.333333333333

(2, 0.1, 1.0): 0.266666666667

(2, 0.1, 10.0): 0.266666666667

(2, 0.1, 100.0): 0.266666666667

(2, 1.0, 1.0): 0.266666666667

(2, 1.0, 10.0): 0.266666666667

(2, 1.0, 100.0): 0.266666666667

(2, 10.0, 1.0): 0.266666666667

(2, 10.0, 10.0): 0.266666666667

(2, 10.0, 100.0): 0.266666666667

(2, 100.0, 1.0): 0.266666666667

(2, 100.0, 10.0): 0.266666666667

(2, 100.0, 100.0): 0.266666666667

(3, 0.1, 1.0): 0.333333333333

(3, 0.1, 10.0): 0.333333333333

(3, 0.1, 100.0): 0.333333333333

(3, 1.0, 1.0): 0.333333333333

(3, 1.0, 10.0): 0.333333333333

(3, 1.0, 100.0): 0.333333333333

(3, 10.0, 1.0): 0.333333333333

(3, 10.0, 10.0): 0.333333333333

(3, 10.0, 100.0): 0.333333333333

(3, 100.0, 1.0): 0.333333333333

(3, 100.0, 10.0): 0.333333333333

(3, 100.0, 100.0): 0.333333333333

(4, 0.1, 1.0): 0.266666666667

(4, 0.1, 10.0): 0.266666666667

(4, 0.1, 100.0): 0.266666666667

(4, 1.0, 1.0): 0.266666666667

(4, 1.0, 10.0): 0.266666666667

(4, 1.0, 100.0): 0.266666666667

(4, 10.0, 1.0): 0.266666666667

(4, 10.0, 10.0): 0.266666666667

(4, 10.0, 100.0): 0.266666666667

(4, 100.0, 1.0): 0.266666666667

(4, 100.0, 10.0): 0.266666666667

(4, 100.0, 100.0): 0.266666666667

(5, 0.1, 1.0): 0.333333333333

(5, 0.1, 10.0): 0.333333333333

(5, 0.1, 100.0): 0.333333333333

(5, 1.0, 1.0): 0.533333333333

(5, 1.0, 10.0): 0.333333333333

(5, 1.0, 100.0): 0.333333333333

(5, 10.0, 1.0): 0.466666666667

(5, 10.0, 10.0): 0.333333333333

(5, 10.0, 100.0): 0.333333333333

(5, 100.0, 1.0): 0.4

(5, 100.0, 10.0): 0.333333333333

(5, 100.0, 100.0): 0.333333333333

(6, 0.1, 1.0): 0.666666666667

(6, 0.1, 10.0): 0.2

(6, 0.1, 100.0): 0.2

(6, 1.0, 1.0): 0.6

(6, 1.0, 10.0): 0.2

(6, 1.0, 100.0): 0.2

(6, 10.0, 1.0): 0.466666666667

(6, 10.0, 10.0): 0.2

(6, 10.0, 100.0): 0.2

(6, 100.0, 1.0): 0.4

(6, 100.0, 10.0): 0.2

(6, 100.0, 100.0): 0.2

(7, 0.1, 1.0): 0.266666666667

(7, 0.1, 10.0): 0.266666666667

(7, 0.1, 100.0): 0.266666666667

(7, 1.0, 1.0): 0.266666666667

(7, 1.0, 10.0): 0.266666666667

(7, 1.0, 100.0): 0.266666666667

(7, 10.0, 1.0): 0.266666666667

(7, 10.0, 10.0): 0.266666666667

(7, 10.0, 100.0): 0.266666666667

(7, 100.0, 1.0): 0.266666666667

(7, 100.0, 10.0): 0.266666666667

(7, 100.0, 100.0): 0.266666666667

(8, 0.1, 1.0): 0.266666666667

(8, 0.1, 10.0): 0.266666666667

(8, 0.1, 100.0): 0.266666666667

(8, 1.0, 1.0): 0.266666666667

(8, 1.0, 10.0): 0.266666666667

(8, 1.0, 100.0): 0.266666666667

(8, 10.0, 1.0): 0.266666666667

(8, 10.0, 10.0): 0.266666666667

(8, 10.0, 100.0): 0.266666666667

(8, 100.0, 1.0): 0.266666666667

(8, 100.0, 10.0): 0.266666666667

(8, 100.0, 100.0): 0.266666666667

(9, 0.1, 1.0): 0.266666666667

(9, 0.1, 10.0): 0.266666666667

(9, 0.1, 100.0): 0.266666666667

(9, 1.0, 1.0): 0.266666666667

(9, 1.0, 10.0): 0.266666666667

(9, 1.0, 100.0): 0.266666666667

(9, 10.0, 1.0): 0.266666666667

(9, 10.0, 10.0): 0.266666666667

(9, 10.0, 100.0): 0.266666666667

(9, 100.0, 1.0): 0.266666666667

(9, 100.0, 10.0): 0.266666666667

(9, 100.0, 100.0): 0.266666666667

Loss on all the set for every iteration, for every couple c,sigma (n_of_the_iter, best_c, best_sigma):
(0, 0.1, 1.0): 0.6
(0, 0.1, 10.0): 0.6
(0, 0.1, 100.0): 0.6
(0, 1.0, 1.0): 0.6
(0, 1.0, 10.0): 0.6
(0, 1.0, 100.0): 0.6
(0, 10.0, 1.0): 0.6
(0, 10.0, 10.0): 0.6
(0, 10.0, 100.0): 0.6
(0, 100.0, 1.0): 0.6
(0, 100.0, 10.0): 0.6
(0, 100.0, 100.0): 0.6
(1, 0.1, 1.0): 0.666666666667
(1, 0.1, 10.0): 0.666666666667
(1, 0.1, 100.0): 0.666666666667
(1, 1.0, 1.0): 0.466666666667
(1, 1.0, 10.0): 0.666666666667
(1, 1.0, 100.0): 0.666666666667
(1, 10.0, 1.0): 0.733333333333
(1, 10.0, 10.0): 0.666666666667
(1, 10.0, 100.0): 0.666666666667
(1, 100.0, 1.0): 0.533333333333
(1, 100.0, 10.0): 0.666666666667
(1, 100.0, 100.0): 0.666666666667
(2, 0.1, 1.0): 0.733333333333
(2, 0.1, 10.0): 0.733333333333
(2, 0.1, 100.0): 0.733333333333
(2, 1.0, 1.0): 0.733333333333
(2, 1.0, 10.0): 0.733333333333
(2, 1.0, 100.0): 0.733333333333
(2, 10.0, 1.0): 0.733333333333
(2, 10.0, 10.0): 0.733333333333
(2, 10.0, 100.0): 0.733333333333
(2, 100.0, 1.0): 0.733333333333
(2, 100.0, 10.0): 0.733333333333
(2, 100.0, 100.0): 0.733333333333
(3, 0.1, 1.0): 0.666666666667
(3, 0.1, 10.0): 0.666666666667
(3, 0.1, 100.0): 0.666666666667
(3, 1.0, 1.0): 0.666666666667
(3, 1.0, 10.0): 0.666666666667
(3, 1.0, 100.0): 0.666666666667
(3, 10.0, 1.0): 0.666666666667
(3, 10.0, 10.0): 0.666666666667
(3, 10.0, 100.0): 0.666666666667
(3, 100.0, 1.0): 0.666666666667
(3, 100.0, 10.0): 0.666666666667
(3, 100.0, 100.0): 0.666666666667
(4, 0.1, 1.0): 0.733333333333
(4, 0.1, 10.0): 0.733333333333
(4, 0.1, 100.0): 0.733333333333
(4, 1.0, 1.0): 0.733333333333
(4, 1.0, 10.0): 0.733333333333
(4, 1.0, 100.0): 0.733333333333
(4, 10.0, 1.0): 0.733333333333
(4, 10.0, 10.0): 0.733333333333
(4, 10.0, 100.0): 0.733333333333
(4, 100.0, 1.0): 0.733333333333
(4, 100.0, 10.0): 0.733333333333
(4, 100.0, 100.0): 0.733333333333
(5, 0.1, 1.0): 0.666666666667
(5, 0.1, 10.0): 0.666666666667
(5, 0.1, 100.0): 0.666666666667
(5, 1.0, 1.0): 0.466666666667
(5, 1.0, 10.0): 0.666666666667
(5, 1.0, 100.0): 0.666666666667
(5, 10.0, 1.0): 0.533333333333
(5, 10.0, 10.0): 0.666666666667
(5, 10.0, 100.0): 0.666666666667
(5, 100.0, 1.0): 0.6
(5, 100.0, 10.0): 0.666666666667
(5, 100.0, 100.0): 0.666666666667
(6, 0.1, 1.0): 0.333333333333
(6, 0.1, 10.0): 0.8
(6, 0.1, 100.0): 0.8
(6, 1.0, 1.0): 0.4
(6, 1.0, 10.0): 0.8
(6, 1.0, 100.0): 0.8
(6, 10.0, 1.0): 0.533333333333
(6, 10.0, 10.0): 0.8
(6, 10.0, 100.0): 0.8
(6, 100.0, 1.0): 0.6
(6, 100.0, 10.0): 0.8
(6, 100.0, 100.0): 0.8
(7, 0.1, 1.0): 0.733333333333
(7, 0.1, 10.0): 0.733333333333
(7, 0.1, 100.0): 0.733333333333
(7, 1.0, 1.0): 0.733333333333
(7, 1.0, 10.0): 0.733333333333
(7, 1.0, 100.0): 0.733333333333
(7, 10.0, 1.0): 0.733333333333
(7, 10.0, 10.0): 0.733333333333
(7, 10.0, 100.0): 0.733333333333
(7, 100.0, 1.0): 0.733333333333
(7, 100.0, 10.0): 0.733333333333
(7, 100.0, 100.0): 0.733333333333
(8, 0.1, 1.0): 0.733333333333
(8, 0.1, 10.0): 0.733333333333
(8, 0.1, 100.0): 0.733333333333
(8, 1.0, 1.0): 0.733333333333
(8, 1.0, 10.0): 0.733333333333
(8, 1.0, 100.0): 0.733333333333
(8, 10.0, 1.0): 0.733333333333
(8, 10.0, 10.0): 0.733333333333
(8, 10.0, 100.0): 0.733333333333
(8, 100.0, 1.0): 0.733333333333
(8, 100.0, 10.0): 0.733333333333
(8, 100.0, 100.0): 0.733333333333
(9, 0.1, 1.0): 0.733333333333
(9, 0.1, 10.0): 0.733333333333
(9, 0.1, 100.0): 0.733333333333
(9, 1.0, 1.0): 0.733333333333
(9, 1.0, 10.0): 0.733333333333
(9, 1.0, 100.0): 0.733333333333
(9, 10.0, 1.0): 0.733333333333
(9, 10.0, 10.0): 0.733333333333
(9, 10.0, 100.0): 0.733333333333
(9, 100.0, 1.0): 0.733333333333
(9, 100.0, 10.0): 0.733333333333
(9, 100.0, 100.0): 0.733333333333

Accuracy mean :0.31
Std deviation :0.07776984086487608
Loss mean :0.6899999999999998
Std deviation :0.07776984086487607



Binary Muzzifier_4dim, number of iterations: 10

Parameters info
Tradeoffs parameter: [1.e-02 1.e-01 1.e+00 1.e+01 1.e+02]
Gaussian kernel sigmas: [1.e-03 1.e-02 1.e-01 1.e+00 1.e+01 1.e+02]
Number of principal dimension considerated: 4
Dataset length: 150

Clusterization info
Minimum size of a cluster: in perc: 0.01, in int: 2
Type of mu: Binary Muzzifier
Fuzzifier: Linear
Cluster to label info
Force the number of cluster to be the number of different labels: False
Force the labels to be always represent by a cluster: False

Validation info
Conflict resolution: random


RESULTS

On TEST set

Accuracy on test set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 100.0, 1.0): 0.2

(1, 0.1, 100.0): 0.0666666666667

(2, 100.0, 100.0): 0.266666666667

(3, 10.0, 10.0): 0.2

(4, 1.0, 10.0): 0.2

(5, 1.0, 10.0): 0.266666666667

(6, 0.1, 100.0): 0.2

(7, 100.0, 1.0): 0.666666666667

(8, 10.0, 1.0): 0.333333333333

(9, 1.0, 1.0): 0.266666666667

Loss on test set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 100.0, 1.0): 0.8
(1, 0.1, 100.0): 0.933333333333
(2, 100.0, 100.0): 0.733333333333
(3, 10.0, 10.0): 0.8
(4, 1.0, 10.0): 0.8
(5, 1.0, 10.0): 0.733333333333
(6, 0.1, 100.0): 0.8
(7, 100.0, 1.0): 0.333333333333
(8, 10.0, 1.0): 0.666666666667
(9, 1.0, 1.0): 0.733333333333

Accuracy mean :0.26666666666666666
Std deviation :0.14907119849998596
Loss mean :0.7333333333333334
Std deviation :0.14907119849998599

On TRAINING set

Accuracy on training set for every iteration (n_of_the_iter, c, sigma):
(0, 100.0, 1.0): 0.348148148148
(1, 0.1, 100.0): 0.362962962963
(2, 100.0, 100.0): 0.340740740741
(3, 10.0, 10.0): 0.348148148148
(4, 1.0, 10.0): 0.348148148148
(5, 1.0, 10.0): 0.340740740741
(6, 0.1, 100.0): 0.348148148148
(7, 100.0, 1.0): 0.666666666667
(8, 10.0, 1.0): 0.333333333333
(9, 1.0, 1.0): 0.340740740741
Loss on training set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 100.0, 1.0): 0.651851851852
(1, 0.1, 100.0): 0.637037037037
(2, 100.0, 100.0): 0.659259259259
(3, 10.0, 10.0): 0.651851851852
(4, 1.0, 10.0): 0.651851851852
(5, 1.0, 10.0): 0.659259259259
(6, 0.1, 100.0): 0.651851851852
(7, 100.0, 1.0): 0.333333333333
(8, 10.0, 1.0): 0.666666666667
(9, 1.0, 1.0): 0.659259259259

Accuracy mean :0.3777777777777777
Std deviation :0.09658077637337256
Loss mean :0.6222222222222221
Std deviation :0.09658077637337258

On ALL the sets

Accuracy on all the set for every iteration, for every couple c,sigma (n_of_the_iter, c, sigma):
(0, 0.1, 1.0): 0.4

(0, 0.1, 10.0): 0.4

(0, 0.1, 100.0): 0.4

(0, 1.0, 1.0): 0.4

(0, 1.0, 10.0): 0.4

(0, 1.0, 100.0): 0.4

(0, 10.0, 1.0): 0.4

(0, 10.0, 10.0): 0.4

(0, 10.0, 100.0): 0.4

(0, 100.0, 1.0): 0.4

(0, 100.0, 10.0): 0.4

(0, 100.0, 100.0): 0.4

(1, 0.1, 1.0): 0.333333333333

(1, 0.1, 10.0): 0.333333333333

(1, 0.1, 100.0): 0.333333333333

(1, 1.0, 1.0): 0.333333333333

(1, 1.0, 10.0): 0.333333333333

(1, 1.0, 100.0): 0.333333333333

(1, 10.0, 1.0): 0.333333333333

(1, 10.0, 10.0): 0.333333333333

(1, 10.0, 100.0): 0.333333333333

(1, 100.0, 1.0): 0.333333333333

(1, 100.0, 10.0): 0.333333333333

(1, 100.0, 100.0): 0.333333333333

(2, 0.1, 1.0): 0.2

(2, 0.1, 10.0): 0.2

(2, 0.1, 100.0): 0.2

(2, 1.0, 1.0): 0.2

(2, 1.0, 10.0): 0.2

(2, 1.0, 100.0): 0.2

(2, 10.0, 1.0): 0.2

(2, 10.0, 10.0): 0.2

(2, 10.0, 100.0): 0.2

(2, 100.0, 1.0): 0.2

(2, 100.0, 10.0): 0.2

(2, 100.0, 100.0): 0.2

(3, 0.1, 1.0): 0.2

(3, 0.1, 10.0): 0.2

(3, 0.1, 100.0): 0.2

(3, 1.0, 1.0): 0.2

(3, 1.0, 10.0): 0.2

(3, 1.0, 100.0): 0.2

(3, 10.0, 1.0): 0.2

(3, 10.0, 10.0): 0.2

(3, 10.0, 100.0): 0.2

(3, 100.0, 1.0): 0.2

(3, 100.0, 10.0): 0.2

(3, 100.0, 100.0): 0.2

(4, 0.1, 1.0): 0.266666666667

(4, 1.0, 1.0): 0.266666666667

(4, 1.0, 10.0): 0.266666666667

(4, 1.0, 100.0): 0.266666666667

(4, 10.0, 1.0): 0.266666666667

(4, 10.0, 10.0): 0.266666666667

(4, 10.0, 100.0): 0.266666666667

(4, 100.0, 1.0): 0.266666666667

(4, 100.0, 10.0): 0.266666666667

(4, 100.0, 100.0): 0.266666666667

(5, 0.1, 1.0): 0.333333333333

(5, 0.1, 10.0): 0.333333333333

(5, 0.1, 100.0): 0.333333333333

(5, 1.0, 1.0): 0.333333333333

(5, 1.0, 10.0): 0.333333333333

(5, 1.0, 100.0): 0.333333333333

(5, 10.0, 1.0): 0.333333333333

(5, 10.0, 10.0): 0.333333333333

(5, 10.0, 100.0): 0.333333333333

(5, 100.0, 1.0): 0.333333333333

(5, 100.0, 10.0): 0.333333333333

(5, 100.0, 100.0): 0.333333333333

(6, 0.1, 1.0): 0.2

(6, 0.1, 10.0): 0.2

(6, 0.1, 100.0): 0.2

(6, 1.0, 1.0): 0.2

(6, 1.0, 10.0): 0.2

(6, 1.0, 100.0): 0.2

(6, 10.0, 1.0): 0.2

(6, 10.0, 10.0): 0.2

(6, 10.0, 100.0): 0.2

(6, 100.0, 1.0): 0.2

(6, 100.0, 10.0): 0.2

(6, 100.0, 100.0): 0.2

(7, 0.1, 1.0): 0.333333333333

(7, 0.1, 10.0): 0.333333333333

(7, 0.1, 100.0): 0.333333333333

(7, 1.0, 1.0): 0.333333333333

(7, 1.0, 10.0): 0.333333333333

(7, 1.0, 100.0): 0.333333333333

(7, 10.0, 1.0): 0.333333333333

(7, 10.0, 10.0): 0.333333333333

(7, 10.0, 100.0): 0.333333333333

(7, 100.0, 1.0): 0.333333333333

(7, 100.0, 10.0): 0.333333333333

(7, 100.0, 100.0): 0.333333333333

(8, 0.1, 1.0): 0.666666666667

(8, 0.1, 10.0): 0.266666666667

(8, 0.1, 100.0): 0.266666666667

(8, 1.0, 1.0): 0.666666666667

(8, 1.0, 10.0): 0.266666666667

(8, 1.0, 100.0): 0.266666666667

(8, 10.0, 1.0): 0.666666666667

(8, 10.0, 10.0): 0.266666666667

(8, 10.0, 100.0): 0.266666666667

(8, 100.0, 1.0): 0.666666666667

(8, 100.0, 10.0): 0.266666666667

(8, 100.0, 100.0): 0.266666666667

(9, 0.1, 1.0): 0.333333333333

(9, 0.1, 10.0): 0.333333333333

(9, 0.1, 100.0): 0.333333333333

(9, 1.0, 1.0): 0.666666666667

(9, 1.0, 10.0): 0.333333333333

(9, 1.0, 100.0): 0.333333333333

(9, 10.0, 1.0): 0.333333333333

(9, 10.0, 10.0): 0.333333333333

(9, 10.0, 100.0): 0.333333333333

(9, 100.0, 1.0): 0.333333333333

(9, 100.0, 10.0): 0.333333333333

(9, 100.0, 100.0): 0.333333333333

Loss on all the set for every iteration, for every couple c,sigma (n_of_the_iter, best_c, best_sigma):
(0, 0.1, 1.0): 0.6
(0, 0.1, 10.0): 0.6
(0, 0.1, 100.0): 0.6
(0, 1.0, 1.0): 0.6
(0, 1.0, 10.0): 0.6
(0, 1.0, 100.0): 0.6
(0, 10.0, 1.0): 0.6
(0, 10.0, 10.0): 0.6
(0, 10.0, 100.0): 0.6
(0, 100.0, 1.0): 0.6
(0, 100.0, 10.0): 0.6
(0, 100.0, 100.0): 0.6
(1, 0.1, 1.0): 0.666666666667
(1, 0.1, 10.0): 0.666666666667
(1, 0.1, 100.0): 0.666666666667
(1, 1.0, 1.0): 0.666666666667
(1, 1.0, 10.0): 0.666666666667
(1, 1.0, 100.0): 0.666666666667
(1, 10.0, 1.0): 0.666666666667
(1, 10.0, 10.0): 0.666666666667
(1, 10.0, 100.0): 0.666666666667
(1, 100.0, 1.0): 0.666666666667
(1, 100.0, 10.0): 0.666666666667
(1, 100.0, 100.0): 0.666666666667
(2, 0.1, 1.0): 0.8
(2, 0.1, 10.0): 0.8
(2, 0.1, 100.0): 0.8
(2, 1.0, 1.0): 0.8
(2, 1.0, 10.0): 0.8
(2, 1.0, 100.0): 0.8
(2, 10.0, 1.0): 0.8
(2, 10.0, 10.0): 0.8
(2, 10.0, 100.0): 0.8
(2, 100.0, 1.0): 0.8
(2, 100.0, 10.0): 0.8
(2, 100.0, 100.0): 0.8
(3, 0.1, 1.0): 0.8
(3, 0.1, 10.0): 0.8
(3, 0.1, 100.0): 0.8
(3, 1.0, 1.0): 0.8
(3, 1.0, 10.0): 0.8
(3, 1.0, 100.0): 0.8
(3, 10.0, 1.0): 0.8
(3, 10.0, 10.0): 0.8
(3, 10.0, 100.0): 0.8
(3, 100.0, 1.0): 0.8
(3, 100.0, 10.0): 0.8
(3, 100.0, 100.0): 0.8
(4, 0.1, 1.0): 0.733333333333
(4, 1.0, 1.0): 0.733333333333
(4, 1.0, 10.0): 0.733333333333
(4, 1.0, 100.0): 0.733333333333
(4, 10.0, 1.0): 0.733333333333
(4, 10.0, 10.0): 0.733333333333
(4, 10.0, 100.0): 0.733333333333
(4, 100.0, 1.0): 0.733333333333
(4, 100.0, 10.0): 0.733333333333
(4, 100.0, 100.0): 0.733333333333
(5, 0.1, 1.0): 0.666666666667
(5, 0.1, 10.0): 0.666666666667
(5, 0.1, 100.0): 0.666666666667
(5, 1.0, 1.0): 0.666666666667
(5, 1.0, 10.0): 0.666666666667
(5, 1.0, 100.0): 0.666666666667
(5, 10.0, 1.0): 0.666666666667
(5, 10.0, 10.0): 0.666666666667
(5, 10.0, 100.0): 0.666666666667
(5, 100.0, 1.0): 0.666666666667
(5, 100.0, 10.0): 0.666666666667
(5, 100.0, 100.0): 0.666666666667
(6, 0.1, 1.0): 0.8
(6, 0.1, 10.0): 0.8
(6, 0.1, 100.0): 0.8
(6, 1.0, 1.0): 0.8
(6, 1.0, 10.0): 0.8
(6, 1.0, 100.0): 0.8
(6, 10.0, 1.0): 0.8
(6, 10.0, 10.0): 0.8
(6, 10.0, 100.0): 0.8
(6, 100.0, 1.0): 0.8
(6, 100.0, 10.0): 0.8
(6, 100.0, 100.0): 0.8
(7, 0.1, 1.0): 0.666666666667
(7, 0.1, 10.0): 0.666666666667
(7, 0.1, 100.0): 0.666666666667
(7, 1.0, 1.0): 0.666666666667
(7, 1.0, 10.0): 0.666666666667
(7, 1.0, 100.0): 0.666666666667
(7, 10.0, 1.0): 0.666666666667
(7, 10.0, 10.0): 0.666666666667
(7, 10.0, 100.0): 0.666666666667
(7, 100.0, 1.0): 0.666666666667
(7, 100.0, 10.0): 0.666666666667
(7, 100.0, 100.0): 0.666666666667
(8, 0.1, 1.0): 0.333333333333
(8, 0.1, 10.0): 0.733333333333
(8, 0.1, 100.0): 0.733333333333
(8, 1.0, 1.0): 0.333333333333
(8, 1.0, 10.0): 0.733333333333
(8, 1.0, 100.0): 0.733333333333
(8, 10.0, 1.0): 0.333333333333
(8, 10.0, 10.0): 0.733333333333
(8, 10.0, 100.0): 0.733333333333
(8, 100.0, 1.0): 0.333333333333
(8, 100.0, 10.0): 0.733333333333
(8, 100.0, 100.0): 0.733333333333
(9, 0.1, 1.0): 0.666666666667
(9, 0.1, 10.0): 0.666666666667
(9, 0.1, 100.0): 0.666666666667
(9, 1.0, 1.0): 0.333333333333
(9, 1.0, 10.0): 0.666666666667
(9, 1.0, 100.0): 0.666666666667
(9, 10.0, 1.0): 0.666666666667
(9, 10.0, 10.0): 0.666666666667
(9, 10.0, 100.0): 0.666666666667
(9, 100.0, 1.0): 0.666666666667
(9, 100.0, 10.0): 0.666666666667
(9, 100.0, 100.0): 0.666666666667

Accuracy mean :0.3033898305084747
Std deviation :0.10180941451260177
Loss mean :0.6966101694915254
Std deviation :0.1018094145126018



Linear Muzzifier_4dim, number of iterations: 10

Parameters info
Tradeoffs parameter: [1.e-02 1.e-01 1.e+00 1.e+01 1.e+02]
Gaussian kernel sigmas: [1.e-03 1.e-02 1.e-01 1.e+00 1.e+01 1.e+02]
Number of principal dimension considerated: 4
Dataset length: 150

Clusterization info
Minimum size of a cluster: in perc: 0.01, in int: 2
Type of mu: Linear Muzzifier
Fuzzifier: Linear
Cluster to label info
Force the number of cluster to be the number of different labels: False
Force the labels to be always represent by a cluster: False

Validation info
Conflict resolution: random


RESULTS

On TEST set

Accuracy on test set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 1.0, 1.0): 0.2

(1, 10.0, 100.0): 0.133333333333

(2, 1.0, 1.0): 0.2

(3, 10.0, 1.0): 0.133333333333

(4, 0.1, 1.0): 0.2

(5, 100.0, 10.0): 0.0666666666667

(6, 100.0, 100.0): 0.2

(7, 100.0, 1.0): 0.266666666667

(8, 1.0, 10.0): 0.2

(9, 100.0, 1.0): 0.533333333333

Loss on test set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 1.0, 1.0): 0.8
(1, 10.0, 100.0): 0.866666666667
(2, 1.0, 1.0): 0.8
(3, 10.0, 1.0): 0.866666666667
(4, 0.1, 1.0): 0.8
(5, 100.0, 10.0): 0.933333333333
(6, 100.0, 100.0): 0.8
(7, 100.0, 1.0): 0.733333333333
(8, 1.0, 10.0): 0.8
(9, 100.0, 1.0): 0.466666666667

Accuracy mean :0.21333333333333332
Std deviation :0.11850925889754117
Loss mean :0.7866666666666667
Std deviation :0.11850925889754119

On TRAINING set

Accuracy on training set for every iteration (n_of_the_iter, c, sigma):
(0, 1.0, 1.0): 0.348148148148
(1, 10.0, 100.0): 0.355555555556
(2, 1.0, 1.0): 0.348148148148
(3, 10.0, 1.0): 0.355555555556
(4, 0.1, 1.0): 0.348148148148
(5, 100.0, 10.0): 0.362962962963
(6, 100.0, 100.0): 0.348148148148
(7, 100.0, 1.0): 0.340740740741
(8, 1.0, 10.0): 0.348148148148
(9, 100.0, 1.0): 0.681481481481
Loss on training set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 1.0, 1.0): 0.651851851852
(1, 10.0, 100.0): 0.644444444444
(2, 1.0, 1.0): 0.651851851852
(3, 10.0, 1.0): 0.644444444444
(4, 0.1, 1.0): 0.651851851852
(5, 100.0, 10.0): 0.637037037037
(6, 100.0, 100.0): 0.651851851852
(7, 100.0, 1.0): 0.659259259259
(8, 1.0, 10.0): 0.651851851852
(9, 100.0, 1.0): 0.318518518519

Accuracy mean :0.3837037037037037
Std deviation :0.09942495843296306
Loss mean :0.6162962962962963
Std deviation :0.09942495843296308

On ALL the sets

Accuracy on all the set for every iteration, for every couple c,sigma (n_of_the_iter, c, sigma):
(0, 0.1, 1.0): 0.4

(0, 0.1, 10.0): 0.4

(0, 0.1, 100.0): 0.4

(0, 1.0, 1.0): 0.4

(0, 1.0, 10.0): 0.4

(0, 1.0, 100.0): 0.4

(0, 10.0, 1.0): 0.4

(0, 10.0, 10.0): 0.4

(0, 10.0, 100.0): 0.4

(0, 100.0, 1.0): 0.4

(0, 100.0, 10.0): 0.4

(0, 100.0, 100.0): 0.4

(1, 0.1, 1.0): 0.2

(1, 0.1, 10.0): 0.2

(1, 1.0, 1.0): 0.2

(1, 1.0, 10.0): 0.2

(1, 1.0, 100.0): 0.2

(1, 10.0, 1.0): 0.2

(1, 10.0, 10.0): 0.2

(1, 10.0, 100.0): 0.2

(1, 100.0, 1.0): 0.2

(1, 100.0, 10.0): 0.2

(1, 100.0, 100.0): 0.2

(2, 0.1, 1.0): 0.333333333333

(2, 0.1, 10.0): 0.333333333333

(2, 0.1, 100.0): 0.333333333333

(2, 1.0, 1.0): 0.333333333333

(2, 1.0, 10.0): 0.333333333333

(2, 1.0, 100.0): 0.333333333333

(2, 10.0, 1.0): 0.333333333333

(2, 10.0, 10.0): 0.333333333333

(2, 10.0, 100.0): 0.333333333333

(2, 100.0, 1.0): 0.333333333333

(2, 100.0, 10.0): 0.333333333333

(2, 100.0, 100.0): 0.333333333333

(3, 0.1, 1.0): 0.333333333333

(3, 1.0, 1.0): 0.333333333333

(3, 1.0, 10.0): 0.333333333333

(3, 1.0, 100.0): 0.333333333333

(3, 10.0, 1.0): 0.333333333333

(3, 10.0, 10.0): 0.333333333333

(3, 10.0, 100.0): 0.333333333333

(3, 100.0, 1.0): 0.333333333333

(3, 100.0, 10.0): 0.333333333333

(3, 100.0, 100.0): 0.333333333333

(4, 0.1, 1.0): 0.333333333333

(4, 0.1, 10.0): 0.333333333333

(4, 0.1, 100.0): 0.333333333333

(4, 1.0, 1.0): 0.333333333333

(4, 1.0, 10.0): 0.333333333333

(4, 1.0, 100.0): 0.333333333333

(4, 10.0, 1.0): 0.333333333333

(4, 10.0, 10.0): 0.333333333333

(4, 10.0, 100.0): 0.333333333333

(4, 100.0, 1.0): 0.333333333333

(4, 100.0, 10.0): 0.333333333333

(4, 100.0, 100.0): 0.333333333333

(5, 0.1, 1.0): 0.466666666667

(5, 0.1, 10.0): 0.466666666667

(5, 0.1, 100.0): 0.466666666667

(5, 1.0, 1.0): 0.466666666667

(5, 1.0, 10.0): 0.466666666667

(5, 1.0, 100.0): 0.466666666667

(5, 10.0, 1.0): 0.466666666667

(5, 10.0, 10.0): 0.466666666667

(5, 10.0, 100.0): 0.466666666667

(5, 100.0, 1.0): 0.466666666667

(5, 100.0, 10.0): 0.466666666667

(5, 100.0, 100.0): 0.466666666667

(6, 0.1, 1.0): 0.2

(6, 0.1, 10.0): 0.2

(6, 0.1, 100.0): 0.2

(6, 1.0, 1.0): 0.2

(6, 1.0, 10.0): 0.2

(6, 1.0, 100.0): 0.2

(6, 10.0, 1.0): 0.2

(6, 10.0, 10.0): 0.2

(6, 10.0, 100.0): 0.2

(6, 100.0, 1.0): 0.2

(6, 100.0, 10.0): 0.2

(6, 100.0, 100.0): 0.2

(7, 0.1, 1.0): 0.133333333333

(7, 0.1, 10.0): 0.133333333333

(7, 0.1, 100.0): 0.133333333333

(7, 1.0, 1.0): 0.133333333333

(7, 1.0, 10.0): 0.133333333333

(7, 1.0, 100.0): 0.133333333333

(7, 10.0, 1.0): 0.133333333333

(7, 10.0, 10.0): 0.133333333333

(7, 10.0, 100.0): 0.133333333333

(7, 100.0, 1.0): 0.133333333333

(7, 100.0, 10.0): 0.133333333333

(7, 100.0, 100.0): 0.133333333333

(8, 0.1, 1.0): 0.266666666667

(8, 0.1, 10.0): 0.266666666667

(8, 0.1, 100.0): 0.266666666667

(8, 1.0, 1.0): 0.266666666667

(8, 1.0, 10.0): 0.266666666667

(8, 1.0, 100.0): 0.266666666667

(8, 10.0, 1.0): 0.266666666667

(8, 10.0, 10.0): 0.266666666667

(8, 10.0, 100.0): 0.266666666667

(8, 100.0, 1.0): 0.266666666667

(8, 100.0, 10.0): 0.266666666667

(8, 100.0, 100.0): 0.266666666667

(9, 0.1, 1.0): 0.2

(9, 0.1, 10.0): 0.2

(9, 0.1, 100.0): 0.2

(9, 1.0, 1.0): 0.466666666667

(9, 1.0, 10.0): 0.2

(9, 1.0, 100.0): 0.2

(9, 10.0, 1.0): 0.4

(9, 10.0, 10.0): 0.2

(9, 10.0, 100.0): 0.2

(9, 100.0, 1.0): 0.466666666667

(9, 100.0, 10.0): 0.2

(9, 100.0, 100.0): 0.2

Loss on all the set for every iteration, for every couple c,sigma (n_of_the_iter, best_c, best_sigma):
(0, 0.1, 1.0): 0.6
(0, 0.1, 10.0): 0.6
(0, 0.1, 100.0): 0.6
(0, 1.0, 1.0): 0.6
(0, 1.0, 10.0): 0.6
(0, 1.0, 100.0): 0.6
(0, 10.0, 1.0): 0.6
(0, 10.0, 10.0): 0.6
(0, 10.0, 100.0): 0.6
(0, 100.0, 1.0): 0.6
(0, 100.0, 10.0): 0.6
(0, 100.0, 100.0): 0.6
(1, 0.1, 1.0): 0.8
(1, 0.1, 10.0): 0.8
(1, 1.0, 1.0): 0.8
(1, 1.0, 10.0): 0.8
(1, 1.0, 100.0): 0.8
(1, 10.0, 1.0): 0.8
(1, 10.0, 10.0): 0.8
(1, 10.0, 100.0): 0.8
(1, 100.0, 1.0): 0.8
(1, 100.0, 10.0): 0.8
(1, 100.0, 100.0): 0.8
(2, 0.1, 1.0): 0.666666666667
(2, 0.1, 10.0): 0.666666666667
(2, 0.1, 100.0): 0.666666666667
(2, 1.0, 1.0): 0.666666666667
(2, 1.0, 10.0): 0.666666666667
(2, 1.0, 100.0): 0.666666666667
(2, 10.0, 1.0): 0.666666666667
(2, 10.0, 10.0): 0.666666666667
(2, 10.0, 100.0): 0.666666666667
(2, 100.0, 1.0): 0.666666666667
(2, 100.0, 10.0): 0.666666666667
(2, 100.0, 100.0): 0.666666666667
(3, 0.1, 1.0): 0.666666666667
(3, 1.0, 1.0): 0.666666666667
(3, 1.0, 10.0): 0.666666666667
(3, 1.0, 100.0): 0.666666666667
(3, 10.0, 1.0): 0.666666666667
(3, 10.0, 10.0): 0.666666666667
(3, 10.0, 100.0): 0.666666666667
(3, 100.0, 1.0): 0.666666666667
(3, 100.0, 10.0): 0.666666666667
(3, 100.0, 100.0): 0.666666666667
(4, 0.1, 1.0): 0.666666666667
(4, 0.1, 10.0): 0.666666666667
(4, 0.1, 100.0): 0.666666666667
(4, 1.0, 1.0): 0.666666666667
(4, 1.0, 10.0): 0.666666666667
(4, 1.0, 100.0): 0.666666666667
(4, 10.0, 1.0): 0.666666666667
(4, 10.0, 10.0): 0.666666666667
(4, 10.0, 100.0): 0.666666666667
(4, 100.0, 1.0): 0.666666666667
(4, 100.0, 10.0): 0.666666666667
(4, 100.0, 100.0): 0.666666666667
(5, 0.1, 1.0): 0.533333333333
(5, 0.1, 10.0): 0.533333333333
(5, 0.1, 100.0): 0.533333333333
(5, 1.0, 1.0): 0.533333333333
(5, 1.0, 10.0): 0.533333333333
(5, 1.0, 100.0): 0.533333333333
(5, 10.0, 1.0): 0.533333333333
(5, 10.0, 10.0): 0.533333333333
(5, 10.0, 100.0): 0.533333333333
(5, 100.0, 1.0): 0.533333333333
(5, 100.0, 10.0): 0.533333333333
(5, 100.0, 100.0): 0.533333333333
(6, 0.1, 1.0): 0.8
(6, 0.1, 10.0): 0.8
(6, 0.1, 100.0): 0.8
(6, 1.0, 1.0): 0.8
(6, 1.0, 10.0): 0.8
(6, 1.0, 100.0): 0.8
(6, 10.0, 1.0): 0.8
(6, 10.0, 10.0): 0.8
(6, 10.0, 100.0): 0.8
(6, 100.0, 1.0): 0.8
(6, 100.0, 10.0): 0.8
(6, 100.0, 100.0): 0.8
(7, 0.1, 1.0): 0.866666666667
(7, 0.1, 10.0): 0.866666666667
(7, 0.1, 100.0): 0.866666666667
(7, 1.0, 1.0): 0.866666666667
(7, 1.0, 10.0): 0.866666666667
(7, 1.0, 100.0): 0.866666666667
(7, 10.0, 1.0): 0.866666666667
(7, 10.0, 10.0): 0.866666666667
(7, 10.0, 100.0): 0.866666666667
(7, 100.0, 1.0): 0.866666666667
(7, 100.0, 10.0): 0.866666666667
(7, 100.0, 100.0): 0.866666666667
(8, 0.1, 1.0): 0.733333333333
(8, 0.1, 10.0): 0.733333333333
(8, 0.1, 100.0): 0.733333333333
(8, 1.0, 1.0): 0.733333333333
(8, 1.0, 10.0): 0.733333333333
(8, 1.0, 100.0): 0.733333333333
(8, 10.0, 1.0): 0.733333333333
(8, 10.0, 10.0): 0.733333333333
(8, 10.0, 100.0): 0.733333333333
(8, 100.0, 1.0): 0.733333333333
(8, 100.0, 10.0): 0.733333333333
(8, 100.0, 100.0): 0.733333333333
(9, 0.1, 1.0): 0.8
(9, 0.1, 10.0): 0.8
(9, 0.1, 100.0): 0.8
(9, 1.0, 1.0): 0.533333333333
(9, 1.0, 10.0): 0.8
(9, 1.0, 100.0): 0.8
(9, 10.0, 1.0): 0.6
(9, 10.0, 10.0): 0.8
(9, 10.0, 100.0): 0.8
(9, 100.0, 1.0): 0.533333333333
(9, 100.0, 10.0): 0.8
(9, 100.0, 100.0): 0.8

Accuracy mean :0.292877492877493
Std deviation :0.10200544273777892
Loss mean :0.7071225071225072
Std deviation :0.10200544273777895



