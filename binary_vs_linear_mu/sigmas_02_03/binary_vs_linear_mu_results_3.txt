Binary Muzzifier_2dim, number of iterations: 10

Parameters info
Tradeoffs parameter: [  0.1   1.   10.  100. ]
Gaussian kernel sigmas: [0.2   0.225 0.25  0.275 0.3  ]
Number of principal dimension considerated: 2
Dataset length: 150

Clusterization info
Minimum size of a cluster: in perc: 0.01, in int: 2
Type of mu: Binary Muzzifier
Fuzzifier: Linear
Cluster to label info
Force the number of cluster to be the number of different labels: False
Force the labels to be always represent by a cluster: False

Validation info
Conflict resolution: random


RESULTS

On TEST set

Accuracy on test set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 10.0, 0.225): 0.933333333333
(1, 100.0, 0.225): 0.933333333333
(2, 100.0, 0.275): 0.533333333333
(3, 10.0, 0.225): 0.866666666667
(4, 100.0, 0.3): 0.866666666667
(5, 100.0, 0.225): 0.733333333333
(6, 10.0, 0.3): 0.866666666667
(7, 1.0, 0.225): 0.933333333333
(8, 10.0, 0.25): 0.733333333333
(9, 10.0, 0.225): 0.866666666667

Loss on test set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 10.0, 0.225): 0.0666666666667
(1, 100.0, 0.225): 0.0666666666667
(2, 100.0, 0.275): 0.466666666667
(3, 10.0, 0.225): 0.133333333333
(4, 100.0, 0.3): 0.133333333333
(5, 100.0, 0.225): 0.266666666667
(6, 10.0, 0.3): 0.133333333333
(7, 1.0, 0.225): 0.0666666666667
(8, 10.0, 0.25): 0.266666666667
(9, 10.0, 0.225): 0.133333333333

Accuracy mean :0.8266666666666668
Std deviation :0.12000000000000002
Loss mean :0.17333333333333334
Std deviation :0.12000000000000001

On TRAINING set

Accuracy on training set for every iteration (n_of_the_iter, c, sigma):
(0, 10.0, 0.225): 0.874074074074
(1, 100.0, 0.225): 0.925925925926
(2, 100.0, 0.275): 0.755555555556
(3, 10.0, 0.225): 0.77037037037
(4, 100.0, 0.3): 0.8
(5, 100.0, 0.225): 0.844444444444
(6, 10.0, 0.3): 0.785185185185
(7, 1.0, 0.225): 0.925925925926
(8, 10.0, 0.25): 0.740740740741
(9, 10.0, 0.225): 0.874074074074
Loss on training set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 10.0, 0.225): 0.125925925926
(1, 100.0, 0.225): 0.0740740740741
(2, 100.0, 0.275): 0.244444444444
(3, 10.0, 0.225): 0.22962962963
(4, 100.0, 0.3): 0.2
(5, 100.0, 0.225): 0.155555555556
(6, 10.0, 0.3): 0.214814814815
(7, 1.0, 0.225): 0.0740740740741
(8, 10.0, 0.25): 0.259259259259
(9, 10.0, 0.225): 0.125925925926

Accuracy mean :0.8296296296296296
Std deviation :0.06516834799384526
Loss mean :0.17037037037037037
Std deviation :0.06516834799384524

On ALL the sets

Accuracy on all the set for every iteration, for every couple c,sigma (n_of_the_iter, c, sigma):
(0, 1.0, 0.2): 0.866666666667
(0, 1.0, 0.225): 0.466666666667
(0, 1.0, 0.25): 0.666666666667
(0, 1.0, 0.275): 0.866666666667
(0, 1.0, 0.3): 0.733333333333
(0, 10.0, 0.2): 0.866666666667
(0, 10.0, 0.225): 0.933333333333
(0, 10.0, 0.25): 0.6
(0, 10.0, 0.275): 0.866666666667
(0, 10.0, 0.3): 0.733333333333
(0, 100.0, 0.2): 0.866666666667
(0, 100.0, 0.225): 0.866666666667
(0, 100.0, 0.25): 0.666666666667
(0, 100.0, 0.275): 0.866666666667
(0, 100.0, 0.3): 0.733333333333
(1, 0.1, 0.25): 0.6
(1, 1.0, 0.2): 0.933333333333
(1, 1.0, 0.225): 0.933333333333
(1, 1.0, 0.25): 0.4
(1, 1.0, 0.275): 0.6
(1, 1.0, 0.3): 0.8
(1, 10.0, 0.2): 0.933333333333
(1, 10.0, 0.225): 0.933333333333
(1, 10.0, 0.25): 0.6
(1, 10.0, 0.275): 0.6
(1, 10.0, 0.3): 0.733333333333
(1, 100.0, 0.2): 0.933333333333
(1, 100.0, 0.225): 0.933333333333
(1, 100.0, 0.25): 0.6
(1, 100.0, 0.275): 0.6
(1, 100.0, 0.3): 0.733333333333
(2, 1.0, 0.2): 0.933333333333
(2, 1.0, 0.225): 0.933333333333
(2, 1.0, 0.25): 0.933333333333
(2, 1.0, 0.275): 1.0
(2, 1.0, 0.3): 0.933333333333
(2, 10.0, 0.2): 0.933333333333
(2, 10.0, 0.225): 0.2
(2, 10.0, 0.25): 0.333333333333
(2, 10.0, 0.275): 1.0
(2, 10.0, 0.3): 0.933333333333
(2, 100.0, 0.2): 0.933333333333
(2, 100.0, 0.225): 0.2
(2, 100.0, 0.25): 0.133333333333
(2, 100.0, 0.275): 1.0
(2, 100.0, 0.3): 0.933333333333
(3, 0.1, 0.275): 0.866666666667
(3, 0.1, 0.3): 0.866666666667
(3, 1.0, 0.2): 0.4
(3, 1.0, 0.225): 1.0
(3, 1.0, 0.25): 1.0
(3, 1.0, 0.275): 0.733333333333
(3, 1.0, 0.3): 0.733333333333
(3, 10.0, 0.2): 0.933333333333
(3, 10.0, 0.225): 1.0
(3, 10.0, 0.25): 1.0
(3, 10.0, 0.275): 0.733333333333
(3, 10.0, 0.3): 0.866666666667
(3, 100.0, 0.2): 0.466666666667
(3, 100.0, 0.225): 1.0
(3, 100.0, 0.25): 1.0
(3, 100.0, 0.275): 0.866666666667
(3, 100.0, 0.3): 0.866666666667
(4, 0.1, 0.275): 0.666666666667
(4, 1.0, 0.2): 0.8
(4, 1.0, 0.225): 0.8
(4, 1.0, 0.25): 0.2
(4, 1.0, 0.275): 0.666666666667
(4, 1.0, 0.3): 0.266666666667
(4, 10.0, 0.2): 0.8
(4, 10.0, 0.225): 0.8
(4, 10.0, 0.25): 0.133333333333
(4, 10.0, 0.275): 0.666666666667
(4, 10.0, 0.3): 0.266666666667
(4, 100.0, 0.2): 0.8
(4, 100.0, 0.225): 0.8
(4, 100.0, 0.25): 0.8
(4, 100.0, 0.275): 0.666666666667
(4, 100.0, 0.3): 0.866666666667
(5, 1.0, 0.2): 0.8
(5, 1.0, 0.225): 0.933333333333
(5, 1.0, 0.25): 0.8
(5, 1.0, 0.275): 0.8
(5, 1.0, 0.3): 0.6
(5, 10.0, 0.2): 0.8
(5, 10.0, 0.225): 0.933333333333
(5, 10.0, 0.25): 0.8
(5, 10.0, 0.275): 0.8
(5, 10.0, 0.3): 0.6
(5, 100.0, 0.2): 0.8
(5, 100.0, 0.225): 0.933333333333
(5, 100.0, 0.25): 0.8
(5, 100.0, 0.275): 0.8
(5, 100.0, 0.3): 0.6
(6, 1.0, 0.2): 0.466666666667
(6, 1.0, 0.225): 0.733333333333
(6, 1.0, 0.25): 0.733333333333
(6, 1.0, 0.275): 0.733333333333
(6, 1.0, 0.3): 0.933333333333
(6, 10.0, 0.2): 0.866666666667
(6, 10.0, 0.225): 0.733333333333
(6, 10.0, 0.25): 0.933333333333
(6, 10.0, 0.275): 0.733333333333
(6, 10.0, 0.3): 0.933333333333
(6, 100.0, 0.2): 0.933333333333
(6, 100.0, 0.225): 0.733333333333
(6, 100.0, 0.25): 0.733333333333
(6, 100.0, 0.275): 0.733333333333
(6, 100.0, 0.3): 0.933333333333
(7, 1.0, 0.2): 0.466666666667
(7, 1.0, 0.225): 0.866666666667
(7, 1.0, 0.25): 0.133333333333
(7, 1.0, 0.275): 0.466666666667
(7, 1.0, 0.3): 0.466666666667
(7, 10.0, 0.2): 0.466666666667
(7, 10.0, 0.225): 0.866666666667
(7, 10.0, 0.25): 0.133333333333
(7, 10.0, 0.275): 0.466666666667
(7, 10.0, 0.3): 0.466666666667
(7, 100.0, 0.2): 0.466666666667
(7, 100.0, 0.225): 0.866666666667
(7, 100.0, 0.25): 0.2
(7, 100.0, 0.275): 0.466666666667
(7, 100.0, 0.3): 0.466666666667
(8, 0.1, 0.225): 0.666666666667
(8, 1.0, 0.2): 0.666666666667
(8, 1.0, 0.225): 0.666666666667
(8, 1.0, 0.25): 1.0
(8, 1.0, 0.275): 0.866666666667
(8, 1.0, 0.3): 0.666666666667
(8, 10.0, 0.2): 0.666666666667
(8, 10.0, 0.225): 0.666666666667
(8, 10.0, 0.25): 1.0
(8, 10.0, 0.275): 0.866666666667
(8, 10.0, 0.3): 0.666666666667
(8, 100.0, 0.2): 0.733333333333
(8, 100.0, 0.225): 0.666666666667
(8, 100.0, 0.25): 1.0
(8, 100.0, 0.275): 0.666666666667
(8, 100.0, 0.3): 0.666666666667
(9, 1.0, 0.2): 0.733333333333
(9, 1.0, 0.225): 0.8
(9, 1.0, 0.25): 0.8
(9, 1.0, 0.275): 0.6
(9, 1.0, 0.3): 0.6
(9, 10.0, 0.2): 0.733333333333
(9, 10.0, 0.225): 0.8
(9, 10.0, 0.25): 0.8
(9, 10.0, 0.275): 0.6
(9, 10.0, 0.3): 0.6
(9, 100.0, 0.2): 0.733333333333
(9, 100.0, 0.225): 0.8
(9, 100.0, 0.25): 0.8
(9, 100.0, 0.275): 0.6
(9, 100.0, 0.3): 0.6

Loss on all the set for every iteration, for every couple c,sigma (n_of_the_iter, best_c, best_sigma):
(0, 1.0, 0.2): 0.133333333333
(0, 1.0, 0.225): 0.533333333333
(0, 1.0, 0.25): 0.333333333333
(0, 1.0, 0.275): 0.133333333333
(0, 1.0, 0.3): 0.266666666667
(0, 10.0, 0.2): 0.133333333333
(0, 10.0, 0.225): 0.0666666666667
(0, 10.0, 0.25): 0.4
(0, 10.0, 0.275): 0.133333333333
(0, 10.0, 0.3): 0.266666666667
(0, 100.0, 0.2): 0.133333333333
(0, 100.0, 0.225): 0.133333333333
(0, 100.0, 0.25): 0.333333333333
(0, 100.0, 0.275): 0.133333333333
(0, 100.0, 0.3): 0.266666666667
(1, 0.1, 0.25): 0.4
(1, 1.0, 0.2): 0.0666666666667
(1, 1.0, 0.225): 0.0666666666667
(1, 1.0, 0.25): 0.6
(1, 1.0, 0.275): 0.4
(1, 1.0, 0.3): 0.2
(1, 10.0, 0.2): 0.0666666666667
(1, 10.0, 0.225): 0.0666666666667
(1, 10.0, 0.25): 0.4
(1, 10.0, 0.275): 0.4
(1, 10.0, 0.3): 0.266666666667
(1, 100.0, 0.2): 0.0666666666667
(1, 100.0, 0.225): 0.0666666666667
(1, 100.0, 0.25): 0.4
(1, 100.0, 0.275): 0.4
(1, 100.0, 0.3): 0.266666666667
(2, 1.0, 0.2): 0.0666666666667
(2, 1.0, 0.225): 0.0666666666667
(2, 1.0, 0.25): 0.0666666666667
(2, 1.0, 0.275): 0.0
(2, 1.0, 0.3): 0.0666666666667
(2, 10.0, 0.2): 0.0666666666667
(2, 10.0, 0.225): 0.8
(2, 10.0, 0.25): 0.666666666667
(2, 10.0, 0.275): 0.0
(2, 10.0, 0.3): 0.0666666666667
(2, 100.0, 0.2): 0.0666666666667
(2, 100.0, 0.225): 0.8
(2, 100.0, 0.25): 0.866666666667
(2, 100.0, 0.275): 0.0
(2, 100.0, 0.3): 0.0666666666667
(3, 0.1, 0.275): 0.133333333333
(3, 0.1, 0.3): 0.133333333333
(3, 1.0, 0.2): 0.6
(3, 1.0, 0.225): 0.0
(3, 1.0, 0.25): 0.0
(3, 1.0, 0.275): 0.266666666667
(3, 1.0, 0.3): 0.266666666667
(3, 10.0, 0.2): 0.0666666666667
(3, 10.0, 0.225): 0.0
(3, 10.0, 0.25): 0.0
(3, 10.0, 0.275): 0.266666666667
(3, 10.0, 0.3): 0.133333333333
(3, 100.0, 0.2): 0.533333333333
(3, 100.0, 0.225): 0.0
(3, 100.0, 0.25): 0.0
(3, 100.0, 0.275): 0.133333333333
(3, 100.0, 0.3): 0.133333333333
(4, 0.1, 0.275): 0.333333333333
(4, 1.0, 0.2): 0.2
(4, 1.0, 0.225): 0.2
(4, 1.0, 0.25): 0.8
(4, 1.0, 0.275): 0.333333333333
(4, 1.0, 0.3): 0.733333333333
(4, 10.0, 0.2): 0.2
(4, 10.0, 0.225): 0.2
(4, 10.0, 0.25): 0.866666666667
(4, 10.0, 0.275): 0.333333333333
(4, 10.0, 0.3): 0.733333333333
(4, 100.0, 0.2): 0.2
(4, 100.0, 0.225): 0.2
(4, 100.0, 0.25): 0.2
(4, 100.0, 0.275): 0.333333333333
(4, 100.0, 0.3): 0.133333333333
(5, 1.0, 0.2): 0.2
(5, 1.0, 0.225): 0.0666666666667
(5, 1.0, 0.25): 0.2
(5, 1.0, 0.275): 0.2
(5, 1.0, 0.3): 0.4
(5, 10.0, 0.2): 0.2
(5, 10.0, 0.225): 0.0666666666667
(5, 10.0, 0.25): 0.2
(5, 10.0, 0.275): 0.2
(5, 10.0, 0.3): 0.4
(5, 100.0, 0.2): 0.2
(5, 100.0, 0.225): 0.0666666666667
(5, 100.0, 0.25): 0.2
(5, 100.0, 0.275): 0.2
(5, 100.0, 0.3): 0.4
(6, 1.0, 0.2): 0.533333333333
(6, 1.0, 0.225): 0.266666666667
(6, 1.0, 0.25): 0.266666666667
(6, 1.0, 0.275): 0.266666666667
(6, 1.0, 0.3): 0.0666666666667
(6, 10.0, 0.2): 0.133333333333
(6, 10.0, 0.225): 0.266666666667
(6, 10.0, 0.25): 0.0666666666667
(6, 10.0, 0.275): 0.266666666667
(6, 10.0, 0.3): 0.0666666666667
(6, 100.0, 0.2): 0.0666666666667
(6, 100.0, 0.225): 0.266666666667
(6, 100.0, 0.25): 0.266666666667
(6, 100.0, 0.275): 0.266666666667
(6, 100.0, 0.3): 0.0666666666667
(7, 1.0, 0.2): 0.533333333333
(7, 1.0, 0.225): 0.133333333333
(7, 1.0, 0.25): 0.866666666667
(7, 1.0, 0.275): 0.533333333333
(7, 1.0, 0.3): 0.533333333333
(7, 10.0, 0.2): 0.533333333333
(7, 10.0, 0.225): 0.133333333333
(7, 10.0, 0.25): 0.866666666667
(7, 10.0, 0.275): 0.533333333333
(7, 10.0, 0.3): 0.533333333333
(7, 100.0, 0.2): 0.533333333333
(7, 100.0, 0.225): 0.133333333333
(7, 100.0, 0.25): 0.8
(7, 100.0, 0.275): 0.533333333333
(7, 100.0, 0.3): 0.533333333333
(8, 0.1, 0.225): 0.333333333333
(8, 1.0, 0.2): 0.333333333333
(8, 1.0, 0.225): 0.333333333333
(8, 1.0, 0.25): 0.0
(8, 1.0, 0.275): 0.133333333333
(8, 1.0, 0.3): 0.333333333333
(8, 10.0, 0.2): 0.333333333333
(8, 10.0, 0.225): 0.333333333333
(8, 10.0, 0.25): 0.0
(8, 10.0, 0.275): 0.133333333333
(8, 10.0, 0.3): 0.333333333333
(8, 100.0, 0.2): 0.266666666667
(8, 100.0, 0.225): 0.333333333333
(8, 100.0, 0.25): 0.0
(8, 100.0, 0.275): 0.333333333333
(8, 100.0, 0.3): 0.333333333333
(9, 1.0, 0.2): 0.266666666667
(9, 1.0, 0.225): 0.2
(9, 1.0, 0.25): 0.2
(9, 1.0, 0.275): 0.4
(9, 1.0, 0.3): 0.4
(9, 10.0, 0.2): 0.266666666667
(9, 10.0, 0.225): 0.2
(9, 10.0, 0.25): 0.2
(9, 10.0, 0.275): 0.4
(9, 10.0, 0.3): 0.4
(9, 100.0, 0.2): 0.266666666667
(9, 100.0, 0.225): 0.2
(9, 100.0, 0.25): 0.2
(9, 100.0, 0.275): 0.4
(9, 100.0, 0.3): 0.4

Accuracy mean :0.727741935483871
Std deviation :0.210267600615633
Loss mean :0.27225806451612905
Std deviation :0.21026760061563296



Linear Muzzifier_2dim, number of iterations: 10

Parameters info
Tradeoffs parameter: [  0.1   1.   10.  100. ]
Gaussian kernel sigmas: [0.2   0.225 0.25  0.275 0.3  ]
Number of principal dimension considerated: 2
Dataset length: 150

Clusterization info
Minimum size of a cluster: in perc: 0.01, in int: 2
Type of mu: Linear Muzzifier
Fuzzifier: Linear
Cluster to label info
Force the number of cluster to be the number of different labels: False
Force the labels to be always represent by a cluster: False

Validation info
Conflict resolution: random


RESULTS

On TEST set

Accuracy on test set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 10.0, 0.225): 0.866666666667
(1, 1.0, 0.2): 0.933333333333
(2, 1.0, 0.25): 0.733333333333
(3, 100.0, 0.2): 0.733333333333
(4, 1.0, 0.2): 0.733333333333
(5, 1.0, 0.225): 0.866666666667
(6, 10.0, 0.275): 0.866666666667
(7, 10.0, 0.275): 0.8
(8, 1.0, 0.3): 0.666666666667
(9, 100.0, 0.275): 0.666666666667

Loss on test set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 10.0, 0.225): 0.133333333333
(1, 1.0, 0.2): 0.0666666666667
(2, 1.0, 0.25): 0.266666666667
(3, 100.0, 0.2): 0.266666666667
(4, 1.0, 0.2): 0.266666666667
(5, 1.0, 0.225): 0.133333333333
(6, 10.0, 0.275): 0.133333333333
(7, 10.0, 0.275): 0.2
(8, 1.0, 0.3): 0.333333333333
(9, 100.0, 0.275): 0.333333333333

Accuracy mean :0.7866666666666666
Std deviation :0.08844332774281069
Loss mean :0.21333333333333332
Std deviation :0.08844332774281065

On TRAINING set

Accuracy on training set for every iteration (n_of_the_iter, c, sigma):
(0, 10.0, 0.225): 0.881481481481
(1, 1.0, 0.2): 0.903703703704
(2, 1.0, 0.25): 0.644444444444
(3, 100.0, 0.2): 0.874074074074
(4, 1.0, 0.2): 0.896296296296
(5, 1.0, 0.225): 0.918518518519
(6, 10.0, 0.275): 0.844444444444
(7, 10.0, 0.275): 0.814814814815
(8, 1.0, 0.3): 0.674074074074
(9, 100.0, 0.275): 0.77037037037
Loss on training set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 10.0, 0.225): 0.118518518519
(1, 1.0, 0.2): 0.0962962962963
(2, 1.0, 0.25): 0.355555555556
(3, 100.0, 0.2): 0.125925925926
(4, 1.0, 0.2): 0.103703703704
(5, 1.0, 0.225): 0.0814814814815
(6, 10.0, 0.275): 0.155555555556
(7, 10.0, 0.275): 0.185185185185
(8, 1.0, 0.3): 0.325925925926
(9, 100.0, 0.275): 0.22962962963

Accuracy mean :0.8222222222222222
Std deviation :0.09186379850623701
Loss mean :0.17777777777777776
Std deviation :0.09186379850623702

On ALL the sets

Accuracy on all the set for every iteration, for every couple c,sigma (n_of_the_iter, c, sigma):
(0, 1.0, 0.2): 0.8
(0, 1.0, 0.225): 0.8
(0, 1.0, 0.25): 0.666666666667
(0, 1.0, 0.275): 0.733333333333
(0, 1.0, 0.3): 0.8
(0, 10.0, 0.2): 0.266666666667
(0, 10.0, 0.225): 0.866666666667
(0, 10.0, 0.25): 0.6
(0, 10.0, 0.275): 0.733333333333
(0, 10.0, 0.3): 0.733333333333
(0, 100.0, 0.2): 0.266666666667
(0, 100.0, 0.225): 0.666666666667
(0, 100.0, 0.25): 0.6
(0, 100.0, 0.275): 0.666666666667
(0, 100.0, 0.3): 0.6
(1, 1.0, 0.2): 0.933333333333
(1, 1.0, 0.225): 0.2
(1, 1.0, 0.25): 0.866666666667
(1, 1.0, 0.275): 0.4
(1, 1.0, 0.3): 0.733333333333
(1, 10.0, 0.2): 0.866666666667
(1, 10.0, 0.225): 0.733333333333
(1, 10.0, 0.25): 0.733333333333
(1, 10.0, 0.275): 0.4
(1, 10.0, 0.3): 0.8
(1, 100.0, 0.2): 0.8
(1, 100.0, 0.225): 0.733333333333
(1, 100.0, 0.25): 0.8
(1, 100.0, 0.275): 0.4
(1, 100.0, 0.3): 0.8
(2, 1.0, 0.2): 0.866666666667
(2, 1.0, 0.225): 0.8
(2, 1.0, 0.25): 1.0
(2, 1.0, 0.275): 0.333333333333
(2, 1.0, 0.3): 0.666666666667
(2, 10.0, 0.2): 0.866666666667
(2, 10.0, 0.225): 0.733333333333
(2, 10.0, 0.25): 0.866666666667
(2, 10.0, 0.275): 0.666666666667
(2, 10.0, 0.3): 0.666666666667
(2, 100.0, 0.2): 0.866666666667
(2, 100.0, 0.225): 0.8
(2, 100.0, 0.25): 0.866666666667
(2, 100.0, 0.275): 0.666666666667
(2, 100.0, 0.3): 0.466666666667
(3, 0.1, 0.275): 0.866666666667
(3, 1.0, 0.2): 0.866666666667
(3, 1.0, 0.225): 0.733333333333
(3, 1.0, 0.25): 0.666666666667
(3, 1.0, 0.275): 0.866666666667
(3, 1.0, 0.3): 0.866666666667
(3, 10.0, 0.2): 0.866666666667
(3, 10.0, 0.225): 0.8
(3, 10.0, 0.25): 0.8
(3, 10.0, 0.275): 0.866666666667
(3, 10.0, 0.3): 0.866666666667
(3, 100.0, 0.2): 1.0
(3, 100.0, 0.225): 0.733333333333
(3, 100.0, 0.25): 0.733333333333
(3, 100.0, 0.275): 0.866666666667
(3, 100.0, 0.3): 0.866666666667
(4, 0.1, 0.225): 0.4
(4, 1.0, 0.2): 1.0
(4, 1.0, 0.225): 0.4
(4, 1.0, 0.25): 0.4
(4, 1.0, 0.275): 0.4
(4, 1.0, 0.3): 0.133333333333
(4, 10.0, 0.2): 0.133333333333
(4, 10.0, 0.225): 0.4
(4, 10.0, 0.25): 0.133333333333
(4, 10.0, 0.275): 0.4
(4, 10.0, 0.3): 0.4
(4, 100.0, 0.2): 1.0
(4, 100.0, 0.225): 0.4
(4, 100.0, 0.25): 0.133333333333
(4, 100.0, 0.275): 0.4
(4, 100.0, 0.3): 0.4
(5, 1.0, 0.2): 1.0
(5, 1.0, 0.225): 1.0
(5, 1.0, 0.25): 0.933333333333
(5, 1.0, 0.275): 0.666666666667
(5, 1.0, 0.3): 0.666666666667
(5, 10.0, 0.2): 0.8
(5, 10.0, 0.225): 0.8
(5, 10.0, 0.25): 0.666666666667
(5, 10.0, 0.275): 0.666666666667
(5, 10.0, 0.3): 0.666666666667
(5, 100.0, 0.2): 0.733333333333
(5, 100.0, 0.225): 0.733333333333
(5, 100.0, 0.25): 0.933333333333
(5, 100.0, 0.275): 0.666666666667
(5, 100.0, 0.3): 0.666666666667
(6, 1.0, 0.2): 0.733333333333
(6, 1.0, 0.225): 0.733333333333
(6, 1.0, 0.25): 0.8
(6, 1.0, 0.275): 0.733333333333
(6, 1.0, 0.3): 0.6
(6, 10.0, 0.2): 0.666666666667
(6, 10.0, 0.225): 0.733333333333
(6, 10.0, 0.25): 0.8
(6, 10.0, 0.275): 0.866666666667
(6, 10.0, 0.3): 0.666666666667
(6, 100.0, 0.2): 0.733333333333
(6, 100.0, 0.225): 0.733333333333
(6, 100.0, 0.25): 0.533333333333
(6, 100.0, 0.275): 0.666666666667
(6, 100.0, 0.3): 0.666666666667
(7, 0.1, 0.25): 0.866666666667
(7, 0.1, 0.3): 0.8
(7, 1.0, 0.2): 0.866666666667
(7, 1.0, 0.225): 0.933333333333
(7, 1.0, 0.25): 0.933333333333
(7, 1.0, 0.275): 0.933333333333
(7, 1.0, 0.3): 0.8
(7, 10.0, 0.2): 0.866666666667
(7, 10.0, 0.225): 0.933333333333
(7, 10.0, 0.25): 0.866666666667
(7, 10.0, 0.275): 0.933333333333
(7, 10.0, 0.3): 0.6
(7, 100.0, 0.2): 0.866666666667
(7, 100.0, 0.225): 0.866666666667
(7, 100.0, 0.25): 0.866666666667
(7, 100.0, 0.275): 0.866666666667
(7, 100.0, 0.3): 0.8
(8, 1.0, 0.2): 0.666666666667
(8, 1.0, 0.225): 0.933333333333
(8, 1.0, 0.25): 0.866666666667
(8, 1.0, 0.275): 0.866666666667
(8, 1.0, 0.3): 0.933333333333
(8, 10.0, 0.2): 0.533333333333
(8, 10.0, 0.225): 0.866666666667
(8, 10.0, 0.25): 0.866666666667
(8, 10.0, 0.275): 0.866666666667
(8, 10.0, 0.3): 0.933333333333
(8, 100.0, 0.2): 0.6
(8, 100.0, 0.225): 0.866666666667
(8, 100.0, 0.25): 0.866666666667
(8, 100.0, 0.275): 0.866666666667
(8, 100.0, 0.3): 0.733333333333
(9, 1.0, 0.2): 0.8
(9, 1.0, 0.225): 0.2
(9, 1.0, 0.25): 0.8
(9, 1.0, 0.275): 0.733333333333
(9, 1.0, 0.3): 0.733333333333
(9, 10.0, 0.2): 0.8
(9, 10.0, 0.225): 0.8
(9, 10.0, 0.25): 0.866666666667
(9, 10.0, 0.275): 0.8
(9, 10.0, 0.3): 0.8
(9, 100.0, 0.2): 0.8
(9, 100.0, 0.225): 0.2
(9, 100.0, 0.25): 0.8
(9, 100.0, 0.275): 0.866666666667
(9, 100.0, 0.3): 0.8

Loss on all the set for every iteration, for every couple c,sigma (n_of_the_iter, best_c, best_sigma):
(0, 1.0, 0.2): 0.2
(0, 1.0, 0.225): 0.2
(0, 1.0, 0.25): 0.333333333333
(0, 1.0, 0.275): 0.266666666667
(0, 1.0, 0.3): 0.2
(0, 10.0, 0.2): 0.733333333333
(0, 10.0, 0.225): 0.133333333333
(0, 10.0, 0.25): 0.4
(0, 10.0, 0.275): 0.266666666667
(0, 10.0, 0.3): 0.266666666667
(0, 100.0, 0.2): 0.733333333333
(0, 100.0, 0.225): 0.333333333333
(0, 100.0, 0.25): 0.4
(0, 100.0, 0.275): 0.333333333333
(0, 100.0, 0.3): 0.4
(1, 1.0, 0.2): 0.0666666666667
(1, 1.0, 0.225): 0.8
(1, 1.0, 0.25): 0.133333333333
(1, 1.0, 0.275): 0.6
(1, 1.0, 0.3): 0.266666666667
(1, 10.0, 0.2): 0.133333333333
(1, 10.0, 0.225): 0.266666666667
(1, 10.0, 0.25): 0.266666666667
(1, 10.0, 0.275): 0.6
(1, 10.0, 0.3): 0.2
(1, 100.0, 0.2): 0.2
(1, 100.0, 0.225): 0.266666666667
(1, 100.0, 0.25): 0.2
(1, 100.0, 0.275): 0.6
(1, 100.0, 0.3): 0.2
(2, 1.0, 0.2): 0.133333333333
(2, 1.0, 0.225): 0.2
(2, 1.0, 0.25): 0.0
(2, 1.0, 0.275): 0.666666666667
(2, 1.0, 0.3): 0.333333333333
(2, 10.0, 0.2): 0.133333333333
(2, 10.0, 0.225): 0.266666666667
(2, 10.0, 0.25): 0.133333333333
(2, 10.0, 0.275): 0.333333333333
(2, 10.0, 0.3): 0.333333333333
(2, 100.0, 0.2): 0.133333333333
(2, 100.0, 0.225): 0.2
(2, 100.0, 0.25): 0.133333333333
(2, 100.0, 0.275): 0.333333333333
(2, 100.0, 0.3): 0.533333333333
(3, 0.1, 0.275): 0.133333333333
(3, 1.0, 0.2): 0.133333333333
(3, 1.0, 0.225): 0.266666666667
(3, 1.0, 0.25): 0.333333333333
(3, 1.0, 0.275): 0.133333333333
(3, 1.0, 0.3): 0.133333333333
(3, 10.0, 0.2): 0.133333333333
(3, 10.0, 0.225): 0.2
(3, 10.0, 0.25): 0.2
(3, 10.0, 0.275): 0.133333333333
(3, 10.0, 0.3): 0.133333333333
(3, 100.0, 0.2): 0.0
(3, 100.0, 0.225): 0.266666666667
(3, 100.0, 0.25): 0.266666666667
(3, 100.0, 0.275): 0.133333333333
(3, 100.0, 0.3): 0.133333333333
(4, 0.1, 0.225): 0.6
(4, 1.0, 0.2): 0.0
(4, 1.0, 0.225): 0.6
(4, 1.0, 0.25): 0.6
(4, 1.0, 0.275): 0.6
(4, 1.0, 0.3): 0.866666666667
(4, 10.0, 0.2): 0.866666666667
(4, 10.0, 0.225): 0.6
(4, 10.0, 0.25): 0.866666666667
(4, 10.0, 0.275): 0.6
(4, 10.0, 0.3): 0.6
(4, 100.0, 0.2): 0.0
(4, 100.0, 0.225): 0.6
(4, 100.0, 0.25): 0.866666666667
(4, 100.0, 0.275): 0.6
(4, 100.0, 0.3): 0.6
(5, 1.0, 0.2): 0.0
(5, 1.0, 0.225): 0.0
(5, 1.0, 0.25): 0.0666666666667
(5, 1.0, 0.275): 0.333333333333
(5, 1.0, 0.3): 0.333333333333
(5, 10.0, 0.2): 0.2
(5, 10.0, 0.225): 0.2
(5, 10.0, 0.25): 0.333333333333
(5, 10.0, 0.275): 0.333333333333
(5, 10.0, 0.3): 0.333333333333
(5, 100.0, 0.2): 0.266666666667
(5, 100.0, 0.225): 0.266666666667
(5, 100.0, 0.25): 0.0666666666667
(5, 100.0, 0.275): 0.333333333333
(5, 100.0, 0.3): 0.333333333333
(6, 1.0, 0.2): 0.266666666667
(6, 1.0, 0.225): 0.266666666667
(6, 1.0, 0.25): 0.2
(6, 1.0, 0.275): 0.266666666667
(6, 1.0, 0.3): 0.4
(6, 10.0, 0.2): 0.333333333333
(6, 10.0, 0.225): 0.266666666667
(6, 10.0, 0.25): 0.2
(6, 10.0, 0.275): 0.133333333333
(6, 10.0, 0.3): 0.333333333333
(6, 100.0, 0.2): 0.266666666667
(6, 100.0, 0.225): 0.266666666667
(6, 100.0, 0.25): 0.466666666667
(6, 100.0, 0.275): 0.333333333333
(6, 100.0, 0.3): 0.333333333333
(7, 0.1, 0.25): 0.133333333333
(7, 0.1, 0.3): 0.2
(7, 1.0, 0.2): 0.133333333333
(7, 1.0, 0.225): 0.0666666666667
(7, 1.0, 0.25): 0.0666666666667
(7, 1.0, 0.275): 0.0666666666667
(7, 1.0, 0.3): 0.2
(7, 10.0, 0.2): 0.133333333333
(7, 10.0, 0.225): 0.0666666666667
(7, 10.0, 0.25): 0.133333333333
(7, 10.0, 0.275): 0.0666666666667
(7, 10.0, 0.3): 0.4
(7, 100.0, 0.2): 0.133333333333
(7, 100.0, 0.225): 0.133333333333
(7, 100.0, 0.25): 0.133333333333
(7, 100.0, 0.275): 0.133333333333
(7, 100.0, 0.3): 0.2
(8, 1.0, 0.2): 0.333333333333
(8, 1.0, 0.225): 0.0666666666667
(8, 1.0, 0.25): 0.133333333333
(8, 1.0, 0.275): 0.133333333333
(8, 1.0, 0.3): 0.0666666666667
(8, 10.0, 0.2): 0.466666666667
(8, 10.0, 0.225): 0.133333333333
(8, 10.0, 0.25): 0.133333333333
(8, 10.0, 0.275): 0.133333333333
(8, 10.0, 0.3): 0.0666666666667
(8, 100.0, 0.2): 0.4
(8, 100.0, 0.225): 0.133333333333
(8, 100.0, 0.25): 0.133333333333
(8, 100.0, 0.275): 0.133333333333
(8, 100.0, 0.3): 0.266666666667
(9, 1.0, 0.2): 0.2
(9, 1.0, 0.225): 0.8
(9, 1.0, 0.25): 0.2
(9, 1.0, 0.275): 0.266666666667
(9, 1.0, 0.3): 0.266666666667
(9, 10.0, 0.2): 0.2
(9, 10.0, 0.225): 0.2
(9, 10.0, 0.25): 0.133333333333
(9, 10.0, 0.275): 0.2
(9, 10.0, 0.3): 0.2
(9, 100.0, 0.2): 0.2
(9, 100.0, 0.225): 0.8
(9, 100.0, 0.25): 0.2
(9, 100.0, 0.275): 0.133333333333
(9, 100.0, 0.3): 0.2

Accuracy mean :0.71991341991342
Std deviation :0.20192148691058856
Loss mean :0.2800865800865801
Std deviation :0.20192148691058853



Binary Muzzifier_3dim, number of iterations: 10

Parameters info
Tradeoffs parameter: [  0.1   1.   10.  100. ]
Gaussian kernel sigmas: [0.2   0.225 0.25  0.275 0.3  ]
Number of principal dimension considerated: 3
Dataset length: 150

Clusterization info
Minimum size of a cluster: in perc: 0.01, in int: 2
Type of mu: Binary Muzzifier
Fuzzifier: Linear
Cluster to label info
Force the number of cluster to be the number of different labels: False
Force the labels to be always represent by a cluster: False

Validation info
Conflict resolution: random


RESULTS

On TEST set

Accuracy on test set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 10.0, 0.275): 0.6
(1, 10.0, 0.25): 0.733333333333
(2, 10.0, 0.2): 0.866666666667
(3, 100.0, 0.275): 0.533333333333
(4, 100.0, 0.225): 0.933333333333
(5, 1.0, 0.225): 0.933333333333
(6, 10.0, 0.275): 0.6
(7, 1.0, 0.225): 0.733333333333
(8, 100.0, 0.25): 0.733333333333
(9, 1.0, 0.275): 0.666666666667

Loss on test set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 10.0, 0.275): 0.4
(1, 10.0, 0.25): 0.266666666667
(2, 10.0, 0.2): 0.133333333333
(3, 100.0, 0.275): 0.466666666667
(4, 100.0, 0.225): 0.0666666666667
(5, 1.0, 0.225): 0.0666666666667
(6, 10.0, 0.275): 0.4
(7, 1.0, 0.225): 0.266666666667
(8, 100.0, 0.25): 0.266666666667
(9, 1.0, 0.275): 0.333333333333

Accuracy mean :0.7333333333333333
Std deviation :0.13333333333333336
Loss mean :0.26666666666666666
Std deviation :0.13333333333333336

On TRAINING set

Accuracy on training set for every iteration (n_of_the_iter, c, sigma):
(0, 10.0, 0.275): 0.740740740741
(1, 10.0, 0.25): 0.874074074074
(2, 10.0, 0.2): 0.896296296296
(3, 100.0, 0.275): 0.681481481481
(4, 100.0, 0.225): 0.844444444444
(5, 1.0, 0.225): 0.940740740741
(6, 10.0, 0.275): 0.733333333333
(7, 1.0, 0.225): 0.651851851852
(8, 100.0, 0.25): 0.659259259259
(9, 1.0, 0.275): 0.711111111111
Loss on training set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 10.0, 0.275): 0.259259259259
(1, 10.0, 0.25): 0.125925925926
(2, 10.0, 0.2): 0.103703703704
(3, 100.0, 0.275): 0.318518518519
(4, 100.0, 0.225): 0.155555555556
(5, 1.0, 0.225): 0.0592592592593
(6, 10.0, 0.275): 0.266666666667
(7, 1.0, 0.225): 0.348148148148
(8, 100.0, 0.25): 0.340740740741
(9, 1.0, 0.275): 0.288888888889

Accuracy mean :0.7733333333333333
Std deviation :0.10054447111678314
Loss mean :0.22666666666666666
Std deviation :0.10054447111678311

On ALL the sets

Accuracy on all the set for every iteration, for every couple c,sigma (n_of_the_iter, c, sigma):
(0, 1.0, 0.225): 0.8
(0, 1.0, 0.25): 0.866666666667
(0, 1.0, 0.275): 1.0
(0, 1.0, 0.3): 0.866666666667
(0, 10.0, 0.225): 0.8
(0, 10.0, 0.25): 0.866666666667
(0, 10.0, 0.275): 1.0
(0, 10.0, 0.3): 0.866666666667
(0, 100.0, 0.225): 0.866666666667
(0, 100.0, 0.25): 0.866666666667
(0, 100.0, 0.275): 1.0
(0, 100.0, 0.3): 0.866666666667
(1, 0.1, 0.275): 0.6
(1, 0.1, 0.3): 0.6
(1, 1.0, 0.225): 0.866666666667
(1, 1.0, 0.25): 0.933333333333
(1, 1.0, 0.275): 0.6
(1, 1.0, 0.3): 0.6
(1, 10.0, 0.2): 0.866666666667
(1, 10.0, 0.225): 0.866666666667
(1, 10.0, 0.25): 0.933333333333
(1, 10.0, 0.275): 0.6
(1, 10.0, 0.3): 0.6
(1, 100.0, 0.2): 0.866666666667
(1, 100.0, 0.225): 0.4
(1, 100.0, 0.25): 0.933333333333
(1, 100.0, 0.275): 0.6
(1, 100.0, 0.3): 0.6
(2, 1.0, 0.2): 0.866666666667
(2, 1.0, 0.225): 0.8
(2, 1.0, 0.25): 0.8
(2, 1.0, 0.275): 0.8
(2, 1.0, 0.3): 0.866666666667
(2, 10.0, 0.2): 0.866666666667
(2, 10.0, 0.225): 0.8
(2, 10.0, 0.25): 0.8
(2, 10.0, 0.275): 0.8
(2, 10.0, 0.3): 0.866666666667
(2, 100.0, 0.2): 0.866666666667
(2, 100.0, 0.225): 0.8
(2, 100.0, 0.25): 0.8
(2, 100.0, 0.275): 0.8
(2, 100.0, 0.3): 0.866666666667
(3, 1.0, 0.2): 0.866666666667
(3, 1.0, 0.225): 0.866666666667
(3, 1.0, 0.25): 0.2
(3, 1.0, 0.275): 0.333333333333
(3, 1.0, 0.3): 0.333333333333
(3, 10.0, 0.2): 0.866666666667
(3, 10.0, 0.225): 0.866666666667
(3, 10.0, 0.25): 0.333333333333
(3, 10.0, 0.275): 1.0
(3, 10.0, 0.3): 0.333333333333
(3, 100.0, 0.2): 0.866666666667
(3, 100.0, 0.225): 0.866666666667
(3, 100.0, 0.25): 0.333333333333
(3, 100.0, 0.275): 1.0
(3, 100.0, 0.3): 0.333333333333
(4, 0.1, 0.275): 0.666666666667
(4, 1.0, 0.2): 0.8
(4, 1.0, 0.225): 1.0
(4, 1.0, 0.25): 0.8
(4, 1.0, 0.275): 0.666666666667
(4, 1.0, 0.3): 0.666666666667
(4, 10.0, 0.225): 0.933333333333
(4, 10.0, 0.25): 0.8
(4, 10.0, 0.275): 0.666666666667
(4, 10.0, 0.3): 0.8
(4, 100.0, 0.225): 1.0
(4, 100.0, 0.25): 0.8
(4, 100.0, 0.275): 0.666666666667
(4, 100.0, 0.3): 0.8
(5, 0.1, 0.3): 0.533333333333
(5, 1.0, 0.2): 0.8
(5, 1.0, 0.225): 0.933333333333
(5, 1.0, 0.25): 0.666666666667
(5, 1.0, 0.275): 0.666666666667
(5, 1.0, 0.3): 0.533333333333
(5, 10.0, 0.2): 0.8
(5, 10.0, 0.225): 0.933333333333
(5, 10.0, 0.25): 0.666666666667
(5, 10.0, 0.275): 0.8
(5, 10.0, 0.3): 0.533333333333
(5, 100.0, 0.2): 0.8
(5, 100.0, 0.225): 0.933333333333
(5, 100.0, 0.25): 0.666666666667
(5, 100.0, 0.275): 0.666666666667
(5, 100.0, 0.3): 0.533333333333
(6, 1.0, 0.2): 0.866666666667
(6, 1.0, 0.225): 0.933333333333
(6, 1.0, 0.25): 0.733333333333
(6, 1.0, 0.275): 0.933333333333
(6, 1.0, 0.3): 0.666666666667
(6, 10.0, 0.2): 0.866666666667
(6, 10.0, 0.225): 0.933333333333
(6, 10.0, 0.25): 0.733333333333
(6, 10.0, 0.275): 0.933333333333
(6, 10.0, 0.3): 0.666666666667
(6, 100.0, 0.2): 0.866666666667
(6, 100.0, 0.225): 0.933333333333
(6, 100.0, 0.25): 0.733333333333
(6, 100.0, 0.275): 0.933333333333
(6, 100.0, 0.3): 0.666666666667
(7, 0.1, 0.25): 0.466666666667
(7, 0.1, 0.3): 0.0666666666667
(7, 1.0, 0.2): 0.533333333333
(7, 1.0, 0.225): 1.0
(7, 1.0, 0.25): 0.466666666667
(7, 1.0, 0.275): 1.0
(7, 1.0, 0.3): 0.0666666666667
(7, 10.0, 0.2): 0.533333333333
(7, 10.0, 0.225): 1.0
(7, 10.0, 0.25): 0.466666666667
(7, 10.0, 0.275): 0.466666666667
(7, 10.0, 0.3): 0.0666666666667
(7, 100.0, 0.2): 0.333333333333
(7, 100.0, 0.225): 1.0
(7, 100.0, 0.25): 0.466666666667
(7, 100.0, 0.275): 0.466666666667
(7, 100.0, 0.3): 0.666666666667
(8, 1.0, 0.2): 0.133333333333
(8, 1.0, 0.225): 0.133333333333
(8, 1.0, 0.25): 1.0
(8, 1.0, 0.275): 1.0
(8, 1.0, 0.3): 0.733333333333
(8, 10.0, 0.2): 0.133333333333
(8, 10.0, 0.225): 0.133333333333
(8, 10.0, 0.25): 1.0
(8, 10.0, 0.275): 1.0
(8, 10.0, 0.3): 0.733333333333
(8, 100.0, 0.2): 0.133333333333
(8, 100.0, 0.225): 0.133333333333
(8, 100.0, 0.25): 1.0
(8, 100.0, 0.275): 1.0
(8, 100.0, 0.3): 0.733333333333
(9, 1.0, 0.225): 0.866666666667
(9, 1.0, 0.25): 0.2
(9, 1.0, 0.275): 0.933333333333
(9, 1.0, 0.3): 0.866666666667
(9, 10.0, 0.225): 0.866666666667
(9, 10.0, 0.25): 0.2
(9, 10.0, 0.275): 0.933333333333
(9, 10.0, 0.3): 0.866666666667
(9, 100.0, 0.225): 0.866666666667
(9, 100.0, 0.25): 0.2
(9, 100.0, 0.275): 0.933333333333
(9, 100.0, 0.3): 0.866666666667

Loss on all the set for every iteration, for every couple c,sigma (n_of_the_iter, best_c, best_sigma):
(0, 1.0, 0.225): 0.2
(0, 1.0, 0.25): 0.133333333333
(0, 1.0, 0.275): 0.0
(0, 1.0, 0.3): 0.133333333333
(0, 10.0, 0.225): 0.2
(0, 10.0, 0.25): 0.133333333333
(0, 10.0, 0.275): 0.0
(0, 10.0, 0.3): 0.133333333333
(0, 100.0, 0.225): 0.133333333333
(0, 100.0, 0.25): 0.133333333333
(0, 100.0, 0.275): 0.0
(0, 100.0, 0.3): 0.133333333333
(1, 0.1, 0.275): 0.4
(1, 0.1, 0.3): 0.4
(1, 1.0, 0.225): 0.133333333333
(1, 1.0, 0.25): 0.0666666666667
(1, 1.0, 0.275): 0.4
(1, 1.0, 0.3): 0.4
(1, 10.0, 0.2): 0.133333333333
(1, 10.0, 0.225): 0.133333333333
(1, 10.0, 0.25): 0.0666666666667
(1, 10.0, 0.275): 0.4
(1, 10.0, 0.3): 0.4
(1, 100.0, 0.2): 0.133333333333
(1, 100.0, 0.225): 0.6
(1, 100.0, 0.25): 0.0666666666667
(1, 100.0, 0.275): 0.4
(1, 100.0, 0.3): 0.4
(2, 1.0, 0.2): 0.133333333333
(2, 1.0, 0.225): 0.2
(2, 1.0, 0.25): 0.2
(2, 1.0, 0.275): 0.2
(2, 1.0, 0.3): 0.133333333333
(2, 10.0, 0.2): 0.133333333333
(2, 10.0, 0.225): 0.2
(2, 10.0, 0.25): 0.2
(2, 10.0, 0.275): 0.2
(2, 10.0, 0.3): 0.133333333333
(2, 100.0, 0.2): 0.133333333333
(2, 100.0, 0.225): 0.2
(2, 100.0, 0.25): 0.2
(2, 100.0, 0.275): 0.2
(2, 100.0, 0.3): 0.133333333333
(3, 1.0, 0.2): 0.133333333333
(3, 1.0, 0.225): 0.133333333333
(3, 1.0, 0.25): 0.8
(3, 1.0, 0.275): 0.666666666667
(3, 1.0, 0.3): 0.666666666667
(3, 10.0, 0.2): 0.133333333333
(3, 10.0, 0.225): 0.133333333333
(3, 10.0, 0.25): 0.666666666667
(3, 10.0, 0.275): 0.0
(3, 10.0, 0.3): 0.666666666667
(3, 100.0, 0.2): 0.133333333333
(3, 100.0, 0.225): 0.133333333333
(3, 100.0, 0.25): 0.666666666667
(3, 100.0, 0.275): 0.0
(3, 100.0, 0.3): 0.666666666667
(4, 0.1, 0.275): 0.333333333333
(4, 1.0, 0.2): 0.2
(4, 1.0, 0.225): 0.0
(4, 1.0, 0.25): 0.2
(4, 1.0, 0.275): 0.333333333333
(4, 1.0, 0.3): 0.333333333333
(4, 10.0, 0.225): 0.0666666666667
(4, 10.0, 0.25): 0.2
(4, 10.0, 0.275): 0.333333333333
(4, 10.0, 0.3): 0.2
(4, 100.0, 0.225): 0.0
(4, 100.0, 0.25): 0.2
(4, 100.0, 0.275): 0.333333333333
(4, 100.0, 0.3): 0.2
(5, 0.1, 0.3): 0.466666666667
(5, 1.0, 0.2): 0.2
(5, 1.0, 0.225): 0.0666666666667
(5, 1.0, 0.25): 0.333333333333
(5, 1.0, 0.275): 0.333333333333
(5, 1.0, 0.3): 0.466666666667
(5, 10.0, 0.2): 0.2
(5, 10.0, 0.225): 0.0666666666667
(5, 10.0, 0.25): 0.333333333333
(5, 10.0, 0.275): 0.2
(5, 10.0, 0.3): 0.466666666667
(5, 100.0, 0.2): 0.2
(5, 100.0, 0.225): 0.0666666666667
(5, 100.0, 0.25): 0.333333333333
(5, 100.0, 0.275): 0.333333333333
(5, 100.0, 0.3): 0.466666666667
(6, 1.0, 0.2): 0.133333333333
(6, 1.0, 0.225): 0.0666666666667
(6, 1.0, 0.25): 0.266666666667
(6, 1.0, 0.275): 0.0666666666667
(6, 1.0, 0.3): 0.333333333333
(6, 10.0, 0.2): 0.133333333333
(6, 10.0, 0.225): 0.0666666666667
(6, 10.0, 0.25): 0.266666666667
(6, 10.0, 0.275): 0.0666666666667
(6, 10.0, 0.3): 0.333333333333
(6, 100.0, 0.2): 0.133333333333
(6, 100.0, 0.225): 0.0666666666667
(6, 100.0, 0.25): 0.266666666667
(6, 100.0, 0.275): 0.0666666666667
(6, 100.0, 0.3): 0.333333333333
(7, 0.1, 0.25): 0.533333333333
(7, 0.1, 0.3): 0.933333333333
(7, 1.0, 0.2): 0.466666666667
(7, 1.0, 0.225): 0.0
(7, 1.0, 0.25): 0.533333333333
(7, 1.0, 0.275): 0.0
(7, 1.0, 0.3): 0.933333333333
(7, 10.0, 0.2): 0.466666666667
(7, 10.0, 0.225): 0.0
(7, 10.0, 0.25): 0.533333333333
(7, 10.0, 0.275): 0.533333333333
(7, 10.0, 0.3): 0.933333333333
(7, 100.0, 0.2): 0.666666666667
(7, 100.0, 0.225): 0.0
(7, 100.0, 0.25): 0.533333333333
(7, 100.0, 0.275): 0.533333333333
(7, 100.0, 0.3): 0.333333333333
(8, 1.0, 0.2): 0.866666666667
(8, 1.0, 0.225): 0.866666666667
(8, 1.0, 0.25): 0.0
(8, 1.0, 0.275): 0.0
(8, 1.0, 0.3): 0.266666666667
(8, 10.0, 0.2): 0.866666666667
(8, 10.0, 0.225): 0.866666666667
(8, 10.0, 0.25): 0.0
(8, 10.0, 0.275): 0.0
(8, 10.0, 0.3): 0.266666666667
(8, 100.0, 0.2): 0.866666666667
(8, 100.0, 0.225): 0.866666666667
(8, 100.0, 0.25): 0.0
(8, 100.0, 0.275): 0.0
(8, 100.0, 0.3): 0.266666666667
(9, 1.0, 0.225): 0.133333333333
(9, 1.0, 0.25): 0.8
(9, 1.0, 0.275): 0.0666666666667
(9, 1.0, 0.3): 0.133333333333
(9, 10.0, 0.225): 0.133333333333
(9, 10.0, 0.25): 0.8
(9, 10.0, 0.275): 0.0666666666667
(9, 10.0, 0.3): 0.133333333333
(9, 100.0, 0.225): 0.133333333333
(9, 100.0, 0.25): 0.8
(9, 100.0, 0.275): 0.0666666666667
(9, 100.0, 0.3): 0.133333333333

Accuracy mean :0.7179138321995465
Std deviation :0.2502990534498215
Loss mean :0.28208616780045354
Std deviation :0.2502990534498215



Linear Muzzifier_3dim, number of iterations: 10

Parameters info
Tradeoffs parameter: [  0.1   1.   10.  100. ]
Gaussian kernel sigmas: [0.2   0.225 0.25  0.275 0.3  ]
Number of principal dimension considerated: 3
Dataset length: 150

Clusterization info
Minimum size of a cluster: in perc: 0.01, in int: 2
Type of mu: Linear Muzzifier
Fuzzifier: Linear
Cluster to label info
Force the number of cluster to be the number of different labels: False
Force the labels to be always represent by a cluster: False

Validation info
Conflict resolution: random


RESULTS

On TEST set

Accuracy on test set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 1.0, 0.225): 0.933333333333
(1, 1.0, 0.225): 0.533333333333
(2, 100.0, 0.225): 0.933333333333
(3, 10.0, 0.225): 0.733333333333
(4, 1.0, 0.275): 0.6
(5, 100.0, 0.2): 0.866666666667
(6, 1.0, 0.25): 0.866666666667
(7, 10.0, 0.225): 0.866666666667
(8, 10.0, 0.225): 0.866666666667
(9, 100.0, 0.225): 0.8

Loss on test set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 1.0, 0.225): 0.0666666666667
(1, 1.0, 0.225): 0.466666666667
(2, 100.0, 0.225): 0.0666666666667
(3, 10.0, 0.225): 0.266666666667
(4, 1.0, 0.275): 0.4
(5, 100.0, 0.2): 0.133333333333
(6, 1.0, 0.25): 0.133333333333
(7, 10.0, 0.225): 0.133333333333
(8, 10.0, 0.225): 0.133333333333
(9, 100.0, 0.225): 0.2

Accuracy mean :0.8
Std deviation :0.12995725793078622
Loss mean :0.2
Std deviation :0.1299572579307862

On TRAINING set

Accuracy on training set for every iteration (n_of_the_iter, c, sigma):
(0, 1.0, 0.225): 0.866666666667
(1, 1.0, 0.225): 0.674074074074
(2, 100.0, 0.225): 0.896296296296
(3, 10.0, 0.225): 0.666666666667
(4, 1.0, 0.275): 0.740740740741
(5, 100.0, 0.2): 0.881481481481
(6, 1.0, 0.25): 0.948148148148
(7, 10.0, 0.225): 0.948148148148
(8, 10.0, 0.225): 0.933333333333
(9, 100.0, 0.225): 0.866666666667
Loss on training set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 1.0, 0.225): 0.133333333333
(1, 1.0, 0.225): 0.325925925926
(2, 100.0, 0.225): 0.103703703704
(3, 10.0, 0.225): 0.333333333333
(4, 1.0, 0.275): 0.259259259259
(5, 100.0, 0.2): 0.118518518519
(6, 1.0, 0.25): 0.0518518518519
(7, 10.0, 0.225): 0.0518518518519
(8, 10.0, 0.225): 0.0666666666667
(9, 100.0, 0.225): 0.133333333333

Accuracy mean :0.8422222222222222
Std deviation :0.1028563263407398
Loss mean :0.15777777777777774
Std deviation :0.10285632634073977

On ALL the sets

Accuracy on all the set for every iteration, for every couple c,sigma (n_of_the_iter, c, sigma):
(0, 0.1, 0.3): 0.933333333333
(0, 1.0, 0.2): 0.866666666667
(0, 1.0, 0.225): 0.933333333333
(0, 1.0, 0.25): 0.933333333333
(0, 1.0, 0.275): 0.8
(0, 1.0, 0.3): 0.933333333333
(0, 10.0, 0.2): 0.933333333333
(0, 10.0, 0.225): 0.866666666667
(0, 10.0, 0.25): 0.8
(0, 10.0, 0.275): 0.8
(0, 10.0, 0.3): 0.866666666667
(0, 100.0, 0.2): 0.933333333333
(0, 100.0, 0.225): 0.866666666667
(0, 100.0, 0.25): 0.933333333333
(0, 100.0, 0.275): 0.733333333333
(0, 100.0, 0.3): 0.533333333333
(1, 1.0, 0.2): 0.933333333333
(1, 1.0, 0.225): 1.0
(1, 1.0, 0.275): 0.666666666667
(1, 1.0, 0.3): 0.333333333333
(1, 10.0, 0.2): 0.933333333333
(1, 10.0, 0.225): 1.0
(1, 10.0, 0.25): 0.333333333333
(1, 10.0, 0.275): 0.666666666667
(1, 10.0, 0.3): 0.666666666667
(1, 100.0, 0.2): 0.933333333333
(1, 100.0, 0.225): 0.933333333333
(1, 100.0, 0.25): 0.333333333333
(1, 100.0, 0.275): 0.666666666667
(1, 100.0, 0.3): 0.333333333333
(2, 0.1, 0.275): 0.6
(2, 1.0, 0.225): 0.733333333333
(2, 1.0, 0.25): 0.6
(2, 1.0, 0.275): 0.6
(2, 1.0, 0.3): 0.6
(2, 10.0, 0.2): 0.6
(2, 10.0, 0.225): 0.8
(2, 10.0, 0.25): 0.533333333333
(2, 10.0, 0.275): 0.6
(2, 10.0, 0.3): 0.6
(2, 100.0, 0.225): 0.8
(2, 100.0, 0.25): 0.666666666667
(2, 100.0, 0.275): 0.533333333333
(2, 100.0, 0.3): 0.6
(3, 0.1, 0.225): 0.866666666667
(3, 1.0, 0.2): 0.933333333333
(3, 1.0, 0.225): 0.866666666667
(3, 1.0, 0.25): 0.8
(3, 1.0, 0.275): 0.666666666667
(3, 1.0, 0.3): 0.666666666667
(3, 10.0, 0.2): 0.866666666667
(3, 10.0, 0.225): 1.0
(3, 10.0, 0.25): 0.8
(3, 10.0, 0.275): 0.666666666667
(3, 10.0, 0.3): 0.666666666667
(3, 100.0, 0.2): 0.866666666667
(3, 100.0, 0.225): 0.8
(3, 100.0, 0.25): 0.733333333333
(3, 100.0, 0.275): 0.2
(3, 100.0, 0.3): 0.733333333333
(4, 1.0, 0.2): 0.866666666667
(4, 1.0, 0.225): 0.866666666667
(4, 1.0, 0.25): 0.733333333333
(4, 1.0, 0.275): 0.866666666667
(4, 1.0, 0.3): 0.266666666667
(4, 10.0, 0.2): 0.866666666667
(4, 10.0, 0.225): 0.866666666667
(4, 10.0, 0.25): 0.733333333333
(4, 10.0, 0.275): 0.866666666667
(4, 10.0, 0.3): 0.733333333333
(4, 100.0, 0.2): 0.866666666667
(4, 100.0, 0.225): 0.866666666667
(4, 100.0, 0.25): 0.733333333333
(4, 100.0, 0.275): 0.866666666667
(4, 100.0, 0.3): 0.8
(5, 0.1, 0.25): 0.133333333333
(5, 1.0, 0.2): 0.933333333333
(5, 1.0, 0.225): 0.133333333333
(5, 1.0, 0.25): 0.933333333333
(5, 1.0, 0.275): 0.866666666667
(5, 1.0, 0.3): 0.866666666667
(5, 10.0, 0.2): 0.933333333333
(5, 10.0, 0.225): 0.266666666667
(5, 10.0, 0.25): 0.866666666667
(5, 10.0, 0.275): 0.866666666667
(5, 10.0, 0.3): 0.933333333333
(5, 100.0, 0.2): 0.933333333333
(5, 100.0, 0.225): 0.4
(5, 100.0, 0.25): 0.133333333333
(5, 100.0, 0.275): 0.866666666667
(5, 100.0, 0.3): 0.933333333333
(6, 1.0, 0.2): 0.866666666667
(6, 1.0, 0.225): 0.466666666667
(6, 1.0, 0.25): 1.0
(6, 1.0, 0.275): 0.6
(6, 1.0, 0.3): 0.666666666667
(6, 10.0, 0.2): 0.866666666667
(6, 10.0, 0.225): 0.466666666667
(6, 10.0, 0.25): 0.466666666667
(6, 10.0, 0.275): 0.6
(6, 10.0, 0.3): 0.666666666667
(6, 100.0, 0.2): 0.866666666667
(6, 100.0, 0.225): 0.466666666667
(6, 100.0, 0.25): 0.466666666667
(6, 100.0, 0.275): 0.533333333333
(6, 100.0, 0.3): 0.8
(7, 0.1, 0.275): 0.666666666667
(7, 0.1, 0.3): 0.666666666667
(7, 1.0, 0.2): 0.866666666667
(7, 1.0, 0.225): 0.933333333333
(7, 1.0, 0.25): 0.866666666667
(7, 1.0, 0.275): 0.666666666667
(7, 1.0, 0.3): 0.666666666667
(7, 10.0, 0.2): 0.933333333333
(7, 10.0, 0.225): 0.933333333333
(7, 10.0, 0.25): 0.866666666667
(7, 10.0, 0.275): 0.933333333333
(7, 10.0, 0.3): 0.666666666667
(7, 100.0, 0.2): 0.933333333333
(7, 100.0, 0.225): 0.933333333333
(7, 100.0, 0.25): 0.866666666667
(7, 100.0, 0.275): 0.933333333333
(7, 100.0, 0.3): 0.666666666667
(8, 1.0, 0.2): 0.666666666667
(8, 1.0, 0.225): 0.866666666667
(8, 1.0, 0.25): 0.866666666667
(8, 1.0, 0.275): 0.2
(8, 1.0, 0.3): 0.666666666667
(8, 10.0, 0.2): 0.2
(8, 10.0, 0.225): 0.933333333333
(8, 10.0, 0.25): 0.933333333333
(8, 10.0, 0.275): 0.2
(8, 10.0, 0.3): 0.666666666667
(8, 100.0, 0.2): 0.666666666667
(8, 100.0, 0.225): 0.866666666667
(8, 100.0, 0.25): 0.8
(8, 100.0, 0.275): 0.2
(8, 100.0, 0.3): 0.733333333333
(9, 0.1, 0.3): 0.466666666667
(9, 1.0, 0.2): 0.266666666667
(9, 1.0, 0.25): 0.2
(9, 1.0, 0.275): 0.533333333333
(9, 1.0, 0.3): 0.466666666667
(9, 10.0, 0.2): 0.266666666667
(9, 10.0, 0.25): 0.333333333333
(9, 10.0, 0.275): 0.466666666667
(9, 10.0, 0.3): 0.466666666667
(9, 100.0, 0.2): 0.266666666667
(9, 100.0, 0.225): 0.866666666667
(9, 100.0, 0.25): 0.266666666667
(9, 100.0, 0.275): 0.466666666667
(9, 100.0, 0.3): 0.466666666667

Loss on all the set for every iteration, for every couple c,sigma (n_of_the_iter, best_c, best_sigma):
(0, 0.1, 0.3): 0.0666666666667
(0, 1.0, 0.2): 0.133333333333
(0, 1.0, 0.225): 0.0666666666667
(0, 1.0, 0.25): 0.0666666666667
(0, 1.0, 0.275): 0.2
(0, 1.0, 0.3): 0.0666666666667
(0, 10.0, 0.2): 0.0666666666667
(0, 10.0, 0.225): 0.133333333333
(0, 10.0, 0.25): 0.2
(0, 10.0, 0.275): 0.2
(0, 10.0, 0.3): 0.133333333333
(0, 100.0, 0.2): 0.0666666666667
(0, 100.0, 0.225): 0.133333333333
(0, 100.0, 0.25): 0.0666666666667
(0, 100.0, 0.275): 0.266666666667
(0, 100.0, 0.3): 0.466666666667
(1, 1.0, 0.2): 0.0666666666667
(1, 1.0, 0.225): 0.0
(1, 1.0, 0.275): 0.333333333333
(1, 1.0, 0.3): 0.666666666667
(1, 10.0, 0.2): 0.0666666666667
(1, 10.0, 0.225): 0.0
(1, 10.0, 0.25): 0.666666666667
(1, 10.0, 0.275): 0.333333333333
(1, 10.0, 0.3): 0.333333333333
(1, 100.0, 0.2): 0.0666666666667
(1, 100.0, 0.225): 0.0666666666667
(1, 100.0, 0.25): 0.666666666667
(1, 100.0, 0.275): 0.333333333333
(1, 100.0, 0.3): 0.666666666667
(2, 0.1, 0.275): 0.4
(2, 1.0, 0.225): 0.266666666667
(2, 1.0, 0.25): 0.4
(2, 1.0, 0.275): 0.4
(2, 1.0, 0.3): 0.4
(2, 10.0, 0.2): 0.4
(2, 10.0, 0.225): 0.2
(2, 10.0, 0.25): 0.466666666667
(2, 10.0, 0.275): 0.4
(2, 10.0, 0.3): 0.4
(2, 100.0, 0.225): 0.2
(2, 100.0, 0.25): 0.333333333333
(2, 100.0, 0.275): 0.466666666667
(2, 100.0, 0.3): 0.4
(3, 0.1, 0.225): 0.133333333333
(3, 1.0, 0.2): 0.0666666666667
(3, 1.0, 0.225): 0.133333333333
(3, 1.0, 0.25): 0.2
(3, 1.0, 0.275): 0.333333333333
(3, 1.0, 0.3): 0.333333333333
(3, 10.0, 0.2): 0.133333333333
(3, 10.0, 0.225): 0.0
(3, 10.0, 0.25): 0.2
(3, 10.0, 0.275): 0.333333333333
(3, 10.0, 0.3): 0.333333333333
(3, 100.0, 0.2): 0.133333333333
(3, 100.0, 0.225): 0.2
(3, 100.0, 0.25): 0.266666666667
(3, 100.0, 0.275): 0.8
(3, 100.0, 0.3): 0.266666666667
(4, 1.0, 0.2): 0.133333333333
(4, 1.0, 0.225): 0.133333333333
(4, 1.0, 0.25): 0.266666666667
(4, 1.0, 0.275): 0.133333333333
(4, 1.0, 0.3): 0.733333333333
(4, 10.0, 0.2): 0.133333333333
(4, 10.0, 0.225): 0.133333333333
(4, 10.0, 0.25): 0.266666666667
(4, 10.0, 0.275): 0.133333333333
(4, 10.0, 0.3): 0.266666666667
(4, 100.0, 0.2): 0.133333333333
(4, 100.0, 0.225): 0.133333333333
(4, 100.0, 0.25): 0.266666666667
(4, 100.0, 0.275): 0.133333333333
(4, 100.0, 0.3): 0.2
(5, 0.1, 0.25): 0.866666666667
(5, 1.0, 0.2): 0.0666666666667
(5, 1.0, 0.225): 0.866666666667
(5, 1.0, 0.25): 0.0666666666667
(5, 1.0, 0.275): 0.133333333333
(5, 1.0, 0.3): 0.133333333333
(5, 10.0, 0.2): 0.0666666666667
(5, 10.0, 0.225): 0.733333333333
(5, 10.0, 0.25): 0.133333333333
(5, 10.0, 0.275): 0.133333333333
(5, 10.0, 0.3): 0.0666666666667
(5, 100.0, 0.2): 0.0666666666667
(5, 100.0, 0.225): 0.6
(5, 100.0, 0.25): 0.866666666667
(5, 100.0, 0.275): 0.133333333333
(5, 100.0, 0.3): 0.0666666666667
(6, 1.0, 0.2): 0.133333333333
(6, 1.0, 0.225): 0.533333333333
(6, 1.0, 0.25): 0.0
(6, 1.0, 0.275): 0.4
(6, 1.0, 0.3): 0.333333333333
(6, 10.0, 0.2): 0.133333333333
(6, 10.0, 0.225): 0.533333333333
(6, 10.0, 0.25): 0.533333333333
(6, 10.0, 0.275): 0.4
(6, 10.0, 0.3): 0.333333333333
(6, 100.0, 0.2): 0.133333333333
(6, 100.0, 0.225): 0.533333333333
(6, 100.0, 0.25): 0.533333333333
(6, 100.0, 0.275): 0.466666666667
(6, 100.0, 0.3): 0.2
(7, 0.1, 0.275): 0.333333333333
(7, 0.1, 0.3): 0.333333333333
(7, 1.0, 0.2): 0.133333333333
(7, 1.0, 0.225): 0.0666666666667
(7, 1.0, 0.25): 0.133333333333
(7, 1.0, 0.275): 0.333333333333
(7, 1.0, 0.3): 0.333333333333
(7, 10.0, 0.2): 0.0666666666667
(7, 10.0, 0.225): 0.0666666666667
(7, 10.0, 0.25): 0.133333333333
(7, 10.0, 0.275): 0.0666666666667
(7, 10.0, 0.3): 0.333333333333
(7, 100.0, 0.2): 0.0666666666667
(7, 100.0, 0.225): 0.0666666666667
(7, 100.0, 0.25): 0.133333333333
(7, 100.0, 0.275): 0.0666666666667
(7, 100.0, 0.3): 0.333333333333
(8, 1.0, 0.2): 0.333333333333
(8, 1.0, 0.225): 0.133333333333
(8, 1.0, 0.25): 0.133333333333
(8, 1.0, 0.275): 0.8
(8, 1.0, 0.3): 0.333333333333
(8, 10.0, 0.2): 0.8
(8, 10.0, 0.225): 0.0666666666667
(8, 10.0, 0.25): 0.0666666666667
(8, 10.0, 0.275): 0.8
(8, 10.0, 0.3): 0.333333333333
(8, 100.0, 0.2): 0.333333333333
(8, 100.0, 0.225): 0.133333333333
(8, 100.0, 0.25): 0.2
(8, 100.0, 0.275): 0.8
(8, 100.0, 0.3): 0.266666666667
(9, 0.1, 0.3): 0.533333333333
(9, 1.0, 0.2): 0.733333333333
(9, 1.0, 0.25): 0.8
(9, 1.0, 0.275): 0.466666666667
(9, 1.0, 0.3): 0.533333333333
(9, 10.0, 0.2): 0.733333333333
(9, 10.0, 0.25): 0.666666666667
(9, 10.0, 0.275): 0.533333333333
(9, 10.0, 0.3): 0.533333333333
(9, 100.0, 0.2): 0.733333333333
(9, 100.0, 0.225): 0.133333333333
(9, 100.0, 0.25): 0.733333333333
(9, 100.0, 0.275): 0.533333333333
(9, 100.0, 0.3): 0.533333333333

Accuracy mean :0.6991228070175439
Std deviation :0.23055829039380396
Loss mean :0.30087719298245613
Std deviation :0.23055829039380396



Binary Muzzifier_4dim, number of iterations: 10

Parameters info
Tradeoffs parameter: [  0.1   1.   10.  100. ]
Gaussian kernel sigmas: [0.2   0.225 0.25  0.275 0.3  ]
Number of principal dimension considerated: 4
Dataset length: 150

Clusterization info
Minimum size of a cluster: in perc: 0.01, in int: 2
Type of mu: Binary Muzzifier
Fuzzifier: Linear
Cluster to label info
Force the number of cluster to be the number of different labels: False
Force the labels to be always represent by a cluster: False

Validation info
Conflict resolution: random


RESULTS

On TEST set

Accuracy on test set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 100.0, 0.3): 0.6
(1, 100.0, 0.225): 0.866666666667
(2, 1.0, 0.225): 0.2
(3, 1.0, 0.225): 0.2
(4, 10.0, 0.3): 0.466666666667
(5, 1.0, 0.25): 0.866666666667
(6, 1.0, 0.25): 0.933333333333
(7, 1.0, 0.275): 0.466666666667
(8, 10.0, 0.225): 0.733333333333
(9, 1.0, 0.225): 0.8

Loss on test set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 100.0, 0.3): 0.4
(1, 100.0, 0.225): 0.133333333333
(2, 1.0, 0.225): 0.8
(3, 1.0, 0.225): 0.8
(4, 10.0, 0.3): 0.533333333333
(5, 1.0, 0.25): 0.133333333333
(6, 1.0, 0.25): 0.0666666666667
(7, 1.0, 0.275): 0.533333333333
(8, 10.0, 0.225): 0.266666666667
(9, 1.0, 0.225): 0.2

Accuracy mean :0.6133333333333334
Std deviation :0.25785439474418287
Loss mean :0.38666666666666666
Std deviation :0.2578543947441829

On TRAINING set

Accuracy on training set for every iteration (n_of_the_iter, c, sigma):
(0, 100.0, 0.3): 0.674074074074
(1, 100.0, 0.225): 0.844444444444
(2, 1.0, 0.225): 0.348148148148
(3, 1.0, 0.225): 0.348148148148
(4, 10.0, 0.3): 0.688888888889
(5, 1.0, 0.25): 0.718518518519
(6, 1.0, 0.25): 0.918518518519
(7, 1.0, 0.275): 0.688888888889
(8, 10.0, 0.225): 0.859259259259
(9, 1.0, 0.225): 0.622222222222
Loss on training set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 100.0, 0.3): 0.325925925926
(1, 100.0, 0.225): 0.155555555556
(2, 1.0, 0.225): 0.651851851852
(3, 1.0, 0.225): 0.651851851852
(4, 10.0, 0.3): 0.311111111111
(5, 1.0, 0.25): 0.281481481481
(6, 1.0, 0.25): 0.0814814814815
(7, 1.0, 0.275): 0.311111111111
(8, 10.0, 0.225): 0.140740740741
(9, 1.0, 0.225): 0.377777777778

Accuracy mean :0.6711111111111111
Std deviation :0.18453812881801507
Loss mean :0.3288888888888889
Std deviation :0.1845381288180151

On ALL the sets

Accuracy on all the set for every iteration, for every couple c,sigma (n_of_the_iter, c, sigma):
(0, 1.0, 0.2): 0.2
(0, 1.0, 0.225): 0.4
(0, 1.0, 0.25): 0.4
(0, 1.0, 0.275): 0.933333333333
(0, 1.0, 0.3): 0.933333333333
(0, 10.0, 0.2): 0.2
(0, 10.0, 0.225): 0.4
(0, 10.0, 0.25): 0.4
(0, 10.0, 0.275): 0.933333333333
(0, 10.0, 0.3): 0.933333333333
(0, 100.0, 0.2): 0.0666666666667
(0, 100.0, 0.225): 0.4
(0, 100.0, 0.25): 0.4
(0, 100.0, 0.275): 0.933333333333
(0, 100.0, 0.3): 0.933333333333
(1, 0.1, 0.25): 0.6
(1, 0.1, 0.3): 0.6
(1, 1.0, 0.2): 0.6
(1, 1.0, 0.225): 0.866666666667
(1, 1.0, 0.25): 0.6
(1, 1.0, 0.275): 0.6
(1, 1.0, 0.3): 0.6
(1, 10.0, 0.2): 0.6
(1, 10.0, 0.225): 0.866666666667
(1, 10.0, 0.25): 0.6
(1, 10.0, 0.275): 0.6
(1, 10.0, 0.3): 0.6
(1, 100.0, 0.2): 0.6
(1, 100.0, 0.225): 0.866666666667
(1, 100.0, 0.25): 0.6
(1, 100.0, 0.275): 0.6
(1, 100.0, 0.3): 0.6
(2, 0.1, 0.3): 0.6
(2, 1.0, 0.2): 0.6
(2, 1.0, 0.225): 0.733333333333
(2, 1.0, 0.25): 0.333333333333
(2, 1.0, 0.275): 0.466666666667
(2, 1.0, 0.3): 0.6
(2, 10.0, 0.2): 0.333333333333
(2, 10.0, 0.225): 0.666666666667
(2, 10.0, 0.25): 0.333333333333
(2, 10.0, 0.275): 0.6
(2, 10.0, 0.3): 0.6
(2, 100.0, 0.2): 0.533333333333
(2, 100.0, 0.225): 0.733333333333
(2, 100.0, 0.275): 0.466666666667
(2, 100.0, 0.3): 0.6
(3, 0.1, 0.3): 0.6
(3, 1.0, 0.2): 0.266666666667
(3, 1.0, 0.225): 0.666666666667
(3, 1.0, 0.25): 0.6
(3, 1.0, 0.275): 0.6
(3, 1.0, 0.3): 0.6
(3, 10.0, 0.2): 0.266666666667
(3, 10.0, 0.225): 0.666666666667
(3, 10.0, 0.25): 0.6
(3, 10.0, 0.275): 0.6
(3, 10.0, 0.3): 0.6
(3, 100.0, 0.2): 0.333333333333
(3, 100.0, 0.225): 0.666666666667
(3, 100.0, 0.25): 0.6
(3, 100.0, 0.275): 0.6
(3, 100.0, 0.3): 0.6
(4, 0.1, 0.275): 0.866666666667
(4, 0.1, 0.3): 0.866666666667
(4, 1.0, 0.2): 0.8
(4, 1.0, 0.225): 0.8
(4, 1.0, 0.25): 0.866666666667
(4, 1.0, 0.275): 0.866666666667
(4, 1.0, 0.3): 0.866666666667
(4, 10.0, 0.2): 0.733333333333
(4, 10.0, 0.225): 0.8
(4, 10.0, 0.25): 0.866666666667
(4, 10.0, 0.275): 0.866666666667
(4, 10.0, 0.3): 0.866666666667
(4, 100.0, 0.2): 0.733333333333
(4, 100.0, 0.225): 0.8
(4, 100.0, 0.25): 0.866666666667
(4, 100.0, 0.275): 0.866666666667
(4, 100.0, 0.3): 0.866666666667
(5, 0.1, 0.275): 0.533333333333
(5, 0.1, 0.3): 0.533333333333
(5, 1.0, 0.2): 0.133333333333
(5, 1.0, 0.225): 0.533333333333
(5, 1.0, 0.25): 0.733333333333
(5, 1.0, 0.275): 0.533333333333
(5, 1.0, 0.3): 0.533333333333
(5, 10.0, 0.2): 0.2
(5, 10.0, 0.225): 0.533333333333
(5, 10.0, 0.25): 0.733333333333
(5, 10.0, 0.275): 0.533333333333
(5, 10.0, 0.3): 0.533333333333
(5, 100.0, 0.2): 0.2
(5, 100.0, 0.225): 0.533333333333
(5, 100.0, 0.25): 0.733333333333
(5, 100.0, 0.275): 0.533333333333
(5, 100.0, 0.3): 0.533333333333
(6, 0.1, 0.275): 0.6
(6, 0.1, 0.3): 0.6
(6, 1.0, 0.2): 0.0666666666667
(6, 1.0, 0.225): 0.4
(6, 1.0, 0.25): 0.933333333333
(6, 1.0, 0.275): 0.6
(6, 1.0, 0.3): 0.6
(6, 10.0, 0.2): 0.0666666666667
(6, 10.0, 0.225): 0.8
(6, 10.0, 0.25): 0.933333333333
(6, 10.0, 0.275): 0.6
(6, 10.0, 0.3): 0.6
(6, 100.0, 0.2): 0.533333333333
(6, 100.0, 0.225): 0.8
(6, 100.0, 0.25): 0.933333333333
(6, 100.0, 0.275): 0.6
(6, 100.0, 0.3): 0.6
(7, 0.1, 0.25): 0.333333333333
(7, 0.1, 0.275): 0.866666666667
(7, 0.1, 0.3): 0.8
(7, 1.0, 0.2): 0.133333333333
(7, 1.0, 0.225): 0.466666666667
(7, 1.0, 0.25): 0.466666666667
(7, 1.0, 0.275): 0.866666666667
(7, 1.0, 0.3): 0.8
(7, 10.0, 0.2): 0.266666666667
(7, 10.0, 0.225): 0.466666666667
(7, 10.0, 0.25): 0.333333333333
(7, 10.0, 0.275): 0.866666666667
(7, 10.0, 0.3): 0.8
(7, 100.0, 0.2): 0.133333333333
(7, 100.0, 0.225): 0.466666666667
(7, 100.0, 0.25): 0.333333333333
(7, 100.0, 0.275): 0.866666666667
(7, 100.0, 0.3): 0.8
(8, 0.1, 0.25): 0.6
(8, 0.1, 0.3): 0.6
(8, 1.0, 0.2): 0.666666666667
(8, 1.0, 0.225): 0.8
(8, 1.0, 0.25): 0.6
(8, 1.0, 0.275): 0.466666666667
(8, 1.0, 0.3): 0.6
(8, 10.0, 0.2): 0.666666666667
(8, 10.0, 0.225): 0.8
(8, 10.0, 0.25): 0.6
(8, 10.0, 0.275): 0.4
(8, 10.0, 0.3): 0.6
(8, 100.0, 0.2): 0.266666666667
(8, 100.0, 0.225): 0.8
(8, 100.0, 0.25): 0.6
(8, 100.0, 0.275): 0.4
(8, 100.0, 0.3): 0.6
(9, 0.1, 0.275): 0.533333333333
(9, 0.1, 0.3): 0.533333333333
(9, 1.0, 0.2): 0.466666666667
(9, 1.0, 0.225): 0.733333333333
(9, 1.0, 0.275): 0.533333333333
(9, 1.0, 0.3): 0.533333333333
(9, 10.0, 0.2): 0.6
(9, 10.0, 0.225): 0.733333333333
(9, 10.0, 0.275): 0.533333333333
(9, 10.0, 0.3): 0.533333333333
(9, 100.0, 0.2): 0.466666666667
(9, 100.0, 0.225): 0.733333333333
(9, 100.0, 0.275): 0.533333333333
(9, 100.0, 0.3): 0.533333333333

Loss on all the set for every iteration, for every couple c,sigma (n_of_the_iter, best_c, best_sigma):
(0, 1.0, 0.2): 0.8
(0, 1.0, 0.225): 0.6
(0, 1.0, 0.25): 0.6
(0, 1.0, 0.275): 0.0666666666667
(0, 1.0, 0.3): 0.0666666666667
(0, 10.0, 0.2): 0.8
(0, 10.0, 0.225): 0.6
(0, 10.0, 0.25): 0.6
(0, 10.0, 0.275): 0.0666666666667
(0, 10.0, 0.3): 0.0666666666667
(0, 100.0, 0.2): 0.933333333333
(0, 100.0, 0.225): 0.6
(0, 100.0, 0.25): 0.6
(0, 100.0, 0.275): 0.0666666666667
(0, 100.0, 0.3): 0.0666666666667
(1, 0.1, 0.25): 0.4
(1, 0.1, 0.3): 0.4
(1, 1.0, 0.2): 0.4
(1, 1.0, 0.225): 0.133333333333
(1, 1.0, 0.25): 0.4
(1, 1.0, 0.275): 0.4
(1, 1.0, 0.3): 0.4
(1, 10.0, 0.2): 0.4
(1, 10.0, 0.225): 0.133333333333
(1, 10.0, 0.25): 0.4
(1, 10.0, 0.275): 0.4
(1, 10.0, 0.3): 0.4
(1, 100.0, 0.2): 0.4
(1, 100.0, 0.225): 0.133333333333
(1, 100.0, 0.25): 0.4
(1, 100.0, 0.275): 0.4
(1, 100.0, 0.3): 0.4
(2, 0.1, 0.3): 0.4
(2, 1.0, 0.2): 0.4
(2, 1.0, 0.225): 0.266666666667
(2, 1.0, 0.25): 0.666666666667
(2, 1.0, 0.275): 0.533333333333
(2, 1.0, 0.3): 0.4
(2, 10.0, 0.2): 0.666666666667
(2, 10.0, 0.225): 0.333333333333
(2, 10.0, 0.25): 0.666666666667
(2, 10.0, 0.275): 0.4
(2, 10.0, 0.3): 0.4
(2, 100.0, 0.2): 0.466666666667
(2, 100.0, 0.225): 0.266666666667
(2, 100.0, 0.275): 0.533333333333
(2, 100.0, 0.3): 0.4
(3, 0.1, 0.3): 0.4
(3, 1.0, 0.2): 0.733333333333
(3, 1.0, 0.225): 0.333333333333
(3, 1.0, 0.25): 0.4
(3, 1.0, 0.275): 0.4
(3, 1.0, 0.3): 0.4
(3, 10.0, 0.2): 0.733333333333
(3, 10.0, 0.225): 0.333333333333
(3, 10.0, 0.25): 0.4
(3, 10.0, 0.275): 0.4
(3, 10.0, 0.3): 0.4
(3, 100.0, 0.2): 0.666666666667
(3, 100.0, 0.225): 0.333333333333
(3, 100.0, 0.25): 0.4
(3, 100.0, 0.275): 0.4
(3, 100.0, 0.3): 0.4
(4, 0.1, 0.275): 0.133333333333
(4, 0.1, 0.3): 0.133333333333
(4, 1.0, 0.2): 0.2
(4, 1.0, 0.225): 0.2
(4, 1.0, 0.25): 0.133333333333
(4, 1.0, 0.275): 0.133333333333
(4, 1.0, 0.3): 0.133333333333
(4, 10.0, 0.2): 0.266666666667
(4, 10.0, 0.225): 0.2
(4, 10.0, 0.25): 0.133333333333
(4, 10.0, 0.275): 0.133333333333
(4, 10.0, 0.3): 0.133333333333
(4, 100.0, 0.2): 0.266666666667
(4, 100.0, 0.225): 0.2
(4, 100.0, 0.25): 0.133333333333
(4, 100.0, 0.275): 0.133333333333
(4, 100.0, 0.3): 0.133333333333
(5, 0.1, 0.275): 0.466666666667
(5, 0.1, 0.3): 0.466666666667
(5, 1.0, 0.2): 0.866666666667
(5, 1.0, 0.225): 0.466666666667
(5, 1.0, 0.25): 0.266666666667
(5, 1.0, 0.275): 0.466666666667
(5, 1.0, 0.3): 0.466666666667
(5, 10.0, 0.2): 0.8
(5, 10.0, 0.225): 0.466666666667
(5, 10.0, 0.25): 0.266666666667
(5, 10.0, 0.275): 0.466666666667
(5, 10.0, 0.3): 0.466666666667
(5, 100.0, 0.2): 0.8
(5, 100.0, 0.225): 0.466666666667
(5, 100.0, 0.25): 0.266666666667
(5, 100.0, 0.275): 0.466666666667
(5, 100.0, 0.3): 0.466666666667
(6, 0.1, 0.275): 0.4
(6, 0.1, 0.3): 0.4
(6, 1.0, 0.2): 0.933333333333
(6, 1.0, 0.225): 0.6
(6, 1.0, 0.25): 0.0666666666667
(6, 1.0, 0.275): 0.4
(6, 1.0, 0.3): 0.4
(6, 10.0, 0.2): 0.933333333333
(6, 10.0, 0.225): 0.2
(6, 10.0, 0.25): 0.0666666666667
(6, 10.0, 0.275): 0.4
(6, 10.0, 0.3): 0.4
(6, 100.0, 0.2): 0.466666666667
(6, 100.0, 0.225): 0.2
(6, 100.0, 0.25): 0.0666666666667
(6, 100.0, 0.275): 0.4
(6, 100.0, 0.3): 0.4
(7, 0.1, 0.25): 0.666666666667
(7, 0.1, 0.275): 0.133333333333
(7, 0.1, 0.3): 0.2
(7, 1.0, 0.2): 0.866666666667
(7, 1.0, 0.225): 0.533333333333
(7, 1.0, 0.25): 0.533333333333
(7, 1.0, 0.275): 0.133333333333
(7, 1.0, 0.3): 0.2
(7, 10.0, 0.2): 0.733333333333
(7, 10.0, 0.225): 0.533333333333
(7, 10.0, 0.25): 0.666666666667
(7, 10.0, 0.275): 0.133333333333
(7, 10.0, 0.3): 0.2
(7, 100.0, 0.2): 0.866666666667
(7, 100.0, 0.225): 0.533333333333
(7, 100.0, 0.25): 0.666666666667
(7, 100.0, 0.275): 0.133333333333
(7, 100.0, 0.3): 0.2
(8, 0.1, 0.25): 0.4
(8, 0.1, 0.3): 0.4
(8, 1.0, 0.2): 0.333333333333
(8, 1.0, 0.225): 0.2
(8, 1.0, 0.25): 0.4
(8, 1.0, 0.275): 0.533333333333
(8, 1.0, 0.3): 0.4
(8, 10.0, 0.2): 0.333333333333
(8, 10.0, 0.225): 0.2
(8, 10.0, 0.25): 0.4
(8, 10.0, 0.275): 0.6
(8, 10.0, 0.3): 0.4
(8, 100.0, 0.2): 0.733333333333
(8, 100.0, 0.225): 0.2
(8, 100.0, 0.25): 0.4
(8, 100.0, 0.275): 0.6
(8, 100.0, 0.3): 0.4
(9, 0.1, 0.275): 0.466666666667
(9, 0.1, 0.3): 0.466666666667
(9, 1.0, 0.2): 0.533333333333
(9, 1.0, 0.225): 0.266666666667
(9, 1.0, 0.275): 0.466666666667
(9, 1.0, 0.3): 0.466666666667
(9, 10.0, 0.2): 0.4
(9, 10.0, 0.225): 0.266666666667
(9, 10.0, 0.275): 0.466666666667
(9, 10.0, 0.3): 0.466666666667
(9, 100.0, 0.2): 0.533333333333
(9, 100.0, 0.225): 0.266666666667
(9, 100.0, 0.275): 0.466666666667
(9, 100.0, 0.3): 0.466666666667

Accuracy mean :0.5995910020449897
Std deviation :0.20284236982125167
Loss mean :0.4004089979550102
Std deviation :0.20284236982125167



Linear Muzzifier_4dim, number of iterations: 10

Parameters info
Tradeoffs parameter: [  0.1   1.   10.  100. ]
Gaussian kernel sigmas: [0.2   0.225 0.25  0.275 0.3  ]
Number of principal dimension considerated: 4
Dataset length: 150

Clusterization info
Minimum size of a cluster: in perc: 0.01, in int: 2
Type of mu: Linear Muzzifier
Fuzzifier: Linear
Cluster to label info
Force the number of cluster to be the number of different labels: False
Force the labels to be always represent by a cluster: False

Validation info
Conflict resolution: random


RESULTS

On TEST set

Accuracy on test set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 100.0, 0.275): 0.6
(1, 0.1, 0.275): 0.666666666667
(2, 0.1, 0.275): 0.933333333333
(3, 1.0, 0.25): 0.733333333333
(4, 100.0, 0.25): 0.6
(5, 1.0, 0.25): 0.866666666667
(6, 100.0, 0.225): 0.933333333333
(7, 10.0, 0.3): 0.666666666667
(8, 100.0, 0.225): 0.866666666667
(9, 100.0, 0.25): 0.6

Loss on test set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 100.0, 0.275): 0.4
(1, 0.1, 0.275): 0.333333333333
(2, 0.1, 0.275): 0.0666666666667
(3, 1.0, 0.25): 0.266666666667
(4, 100.0, 0.25): 0.4
(5, 1.0, 0.25): 0.133333333333
(6, 100.0, 0.225): 0.0666666666667
(7, 10.0, 0.3): 0.333333333333
(8, 100.0, 0.225): 0.133333333333
(9, 100.0, 0.25): 0.4

Accuracy mean :0.7466666666666666
Std deviation :0.13266499161421602
Loss mean :0.2533333333333333
Std deviation :0.132664991614216

On TRAINING set

Accuracy on training set for every iteration (n_of_the_iter, c, sigma):
(0, 100.0, 0.275): 0.674074074074
(1, 0.1, 0.275): 0.666666666667
(2, 0.1, 0.275): 0.881481481481
(3, 1.0, 0.25): 0.666666666667
(4, 100.0, 0.25): 0.674074074074
(5, 1.0, 0.25): 0.925925925926
(6, 100.0, 0.225): 0.837037037037
(7, 10.0, 0.3): 0.666666666667
(8, 100.0, 0.225): 0.844444444444
(9, 100.0, 0.25): 0.674074074074
Loss on training set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 100.0, 0.275): 0.325925925926
(1, 0.1, 0.275): 0.333333333333
(2, 0.1, 0.275): 0.118518518519
(3, 1.0, 0.25): 0.333333333333
(4, 100.0, 0.25): 0.325925925926
(5, 1.0, 0.25): 0.0740740740741
(6, 100.0, 0.225): 0.162962962963
(7, 10.0, 0.3): 0.333333333333
(8, 100.0, 0.225): 0.155555555556
(9, 100.0, 0.25): 0.325925925926

Accuracy mean :0.7511111111111111
Std deviation :0.1014138731266657
Loss mean :0.24888888888888888
Std deviation :0.10141387312666567

On ALL the sets

Accuracy on all the set for every iteration, for every couple c,sigma (n_of_the_iter, c, sigma):
(0, 0.1, 0.25): 0.733333333333
(0, 0.1, 0.275): 0.733333333333
(0, 0.1, 0.3): 0.733333333333
(0, 1.0, 0.225): 0.733333333333
(0, 1.0, 0.25): 0.333333333333
(0, 1.0, 0.275): 0.733333333333
(0, 1.0, 0.3): 0.733333333333
(0, 10.0, 0.225): 0.733333333333
(0, 10.0, 0.25): 0.333333333333
(0, 10.0, 0.275): 0.733333333333
(0, 10.0, 0.3): 0.733333333333
(0, 100.0, 0.225): 0.733333333333
(0, 100.0, 0.25): 0.333333333333
(0, 100.0, 0.275): 0.733333333333
(0, 100.0, 0.3): 0.733333333333
(1, 0.1, 0.275): 0.866666666667
(1, 1.0, 0.225): 0.666666666667
(1, 1.0, 0.25): 0.866666666667
(1, 1.0, 0.275): 0.866666666667
(1, 1.0, 0.3): 0.666666666667
(1, 10.0, 0.225): 0.8
(1, 10.0, 0.25): 0.8
(1, 10.0, 0.275): 0.866666666667
(1, 10.0, 0.3): 0.533333333333
(1, 100.0, 0.225): 0.8
(1, 100.0, 0.25): 0.8
(1, 100.0, 0.275): 0.8
(1, 100.0, 0.3): 0.533333333333
(2, 0.1, 0.225): 0.533333333333
(2, 0.1, 0.275): 0.866666666667
(2, 0.1, 0.3): 0.533333333333
(2, 1.0, 0.2): 0.333333333333
(2, 1.0, 0.225): 0.533333333333
(2, 1.0, 0.25): 0.866666666667
(2, 1.0, 0.275): 0.866666666667
(2, 1.0, 0.3): 0.533333333333
(2, 10.0, 0.2): 0.266666666667
(2, 10.0, 0.225): 0.533333333333
(2, 10.0, 0.25): 0.8
(2, 10.0, 0.275): 0.8
(2, 10.0, 0.3): 0.533333333333
(2, 100.0, 0.2): 0.266666666667
(2, 100.0, 0.225): 0.533333333333
(2, 100.0, 0.25): 0.8
(2, 100.0, 0.275): 0.733333333333
(2, 100.0, 0.3): 0.533333333333
(3, 0.1, 0.3): 0.666666666667
(3, 1.0, 0.2): 0.666666666667
(3, 1.0, 0.225): 0.733333333333
(3, 1.0, 0.25): 0.933333333333
(3, 1.0, 0.275): 0.866666666667
(3, 1.0, 0.3): 0.666666666667
(3, 10.0, 0.2): 0.666666666667
(3, 10.0, 0.225): 0.8
(3, 10.0, 0.25): 0.866666666667
(3, 10.0, 0.275): 0.8
(3, 10.0, 0.3): 0.666666666667
(3, 100.0, 0.2): 0.666666666667
(3, 100.0, 0.225): 0.8
(3, 100.0, 0.25): 0.866666666667
(3, 100.0, 0.275): 0.666666666667
(3, 100.0, 0.3): 0.666666666667
(4, 0.1, 0.275): 0.666666666667
(4, 0.1, 0.3): 0.666666666667
(4, 1.0, 0.225): 0.733333333333
(4, 1.0, 0.25): 0.8
(4, 1.0, 0.275): 0.666666666667
(4, 1.0, 0.3): 0.666666666667
(4, 10.0, 0.225): 0.733333333333
(4, 10.0, 0.25): 0.733333333333
(4, 10.0, 0.275): 0.666666666667
(4, 10.0, 0.3): 0.666666666667
(4, 100.0, 0.225): 0.733333333333
(4, 100.0, 0.25): 0.866666666667
(4, 100.0, 0.275): 0.666666666667
(4, 100.0, 0.3): 0.666666666667
(5, 0.1, 0.3): 0.533333333333
(5, 1.0, 0.2): 0.533333333333
(5, 1.0, 0.225): 0.333333333333
(5, 1.0, 0.25): 0.866666666667
(5, 1.0, 0.275): 0.533333333333
(5, 1.0, 0.3): 0.533333333333
(5, 10.0, 0.2): 0.533333333333
(5, 10.0, 0.225): 0.333333333333
(5, 10.0, 0.25): 0.8
(5, 10.0, 0.275): 0.533333333333
(5, 10.0, 0.3): 0.533333333333
(5, 100.0, 0.2): 0.533333333333
(5, 100.0, 0.225): 0.333333333333
(5, 100.0, 0.25): 0.733333333333
(5, 100.0, 0.275): 0.533333333333
(5, 100.0, 0.3): 0.533333333333
(6, 0.1, 0.25): 0.6
(6, 0.1, 0.3): 0.6
(6, 1.0, 0.2): 0.666666666667
(6, 1.0, 0.225): 1.0
(6, 1.0, 0.25): 0.6
(6, 1.0, 0.275): 0.6
(6, 1.0, 0.3): 0.6
(6, 10.0, 0.2): 0.666666666667
(6, 10.0, 0.225): 1.0
(6, 10.0, 0.25): 0.6
(6, 10.0, 0.275): 0.6
(6, 10.0, 0.3): 0.6
(6, 100.0, 0.2): 0.666666666667
(6, 100.0, 0.225): 1.0
(6, 100.0, 0.25): 0.6
(6, 100.0, 0.275): 0.6
(6, 100.0, 0.3): 0.6
(7, 0.1, 0.25): 0.533333333333
(7, 0.1, 0.275): 0.533333333333
(7, 0.1, 0.3): 0.266666666667
(7, 1.0, 0.2): 0.333333333333
(7, 1.0, 0.225): 0.266666666667
(7, 1.0, 0.25): 0.533333333333
(7, 1.0, 0.275): 0.533333333333
(7, 1.0, 0.3): 0.533333333333
(7, 10.0, 0.2): 0.2
(7, 10.0, 0.225): 0.2
(7, 10.0, 0.25): 0.533333333333
(7, 10.0, 0.275): 0.533333333333
(7, 10.0, 0.3): 0.533333333333
(7, 100.0, 0.2): 0.133333333333
(7, 100.0, 0.225): 0.466666666667
(7, 100.0, 0.25): 0.533333333333
(7, 100.0, 0.275): 0.533333333333
(7, 100.0, 0.3): 0.266666666667
(8, 0.1, 0.3): 0.666666666667
(8, 1.0, 0.225): 0.8
(8, 1.0, 0.25): 0.666666666667
(8, 1.0, 0.275): 0.666666666667
(8, 1.0, 0.3): 0.666666666667
(8, 10.0, 0.2): 0.6
(8, 10.0, 0.225): 0.8
(8, 10.0, 0.25): 0.666666666667
(8, 10.0, 0.275): 0.8
(8, 10.0, 0.3): 0.666666666667
(8, 100.0, 0.225): 0.8
(8, 100.0, 0.25): 0.666666666667
(8, 100.0, 0.275): 0.666666666667
(8, 100.0, 0.3): 0.666666666667
(9, 0.1, 0.275): 0.266666666667
(9, 1.0, 0.2): 0.733333333333
(9, 1.0, 0.225): 0.8
(9, 1.0, 0.25): 0.933333333333
(9, 1.0, 0.275): 0.733333333333
(9, 1.0, 0.3): 0.266666666667
(9, 10.0, 0.2): 0.733333333333
(9, 10.0, 0.225): 0.8
(9, 10.0, 0.25): 1.0
(9, 10.0, 0.275): 0.733333333333
(9, 10.0, 0.3): 0.266666666667
(9, 100.0, 0.2): 0.733333333333
(9, 100.0, 0.225): 0.8
(9, 100.0, 0.25): 1.0
(9, 100.0, 0.275): 0.733333333333
(9, 100.0, 0.3): 0.266666666667

Loss on all the set for every iteration, for every couple c,sigma (n_of_the_iter, best_c, best_sigma):
(0, 0.1, 0.25): 0.266666666667
(0, 0.1, 0.275): 0.266666666667
(0, 0.1, 0.3): 0.266666666667
(0, 1.0, 0.225): 0.266666666667
(0, 1.0, 0.25): 0.666666666667
(0, 1.0, 0.275): 0.266666666667
(0, 1.0, 0.3): 0.266666666667
(0, 10.0, 0.225): 0.266666666667
(0, 10.0, 0.25): 0.666666666667
(0, 10.0, 0.275): 0.266666666667
(0, 10.0, 0.3): 0.266666666667
(0, 100.0, 0.225): 0.266666666667
(0, 100.0, 0.25): 0.666666666667
(0, 100.0, 0.275): 0.266666666667
(0, 100.0, 0.3): 0.266666666667
(1, 0.1, 0.275): 0.133333333333
(1, 1.0, 0.225): 0.333333333333
(1, 1.0, 0.25): 0.133333333333
(1, 1.0, 0.275): 0.133333333333
(1, 1.0, 0.3): 0.333333333333
(1, 10.0, 0.225): 0.2
(1, 10.0, 0.25): 0.2
(1, 10.0, 0.275): 0.133333333333
(1, 10.0, 0.3): 0.466666666667
(1, 100.0, 0.225): 0.2
(1, 100.0, 0.25): 0.2
(1, 100.0, 0.275): 0.2
(1, 100.0, 0.3): 0.466666666667
(2, 0.1, 0.225): 0.466666666667
(2, 0.1, 0.275): 0.133333333333
(2, 0.1, 0.3): 0.466666666667
(2, 1.0, 0.2): 0.666666666667
(2, 1.0, 0.225): 0.466666666667
(2, 1.0, 0.25): 0.133333333333
(2, 1.0, 0.275): 0.133333333333
(2, 1.0, 0.3): 0.466666666667
(2, 10.0, 0.2): 0.733333333333
(2, 10.0, 0.225): 0.466666666667
(2, 10.0, 0.25): 0.2
(2, 10.0, 0.275): 0.2
(2, 10.0, 0.3): 0.466666666667
(2, 100.0, 0.2): 0.733333333333
(2, 100.0, 0.225): 0.466666666667
(2, 100.0, 0.25): 0.2
(2, 100.0, 0.275): 0.266666666667
(2, 100.0, 0.3): 0.466666666667
(3, 0.1, 0.3): 0.333333333333
(3, 1.0, 0.2): 0.333333333333
(3, 1.0, 0.225): 0.266666666667
(3, 1.0, 0.25): 0.0666666666667
(3, 1.0, 0.275): 0.133333333333
(3, 1.0, 0.3): 0.333333333333
(3, 10.0, 0.2): 0.333333333333
(3, 10.0, 0.225): 0.2
(3, 10.0, 0.25): 0.133333333333
(3, 10.0, 0.275): 0.2
(3, 10.0, 0.3): 0.333333333333
(3, 100.0, 0.2): 0.333333333333
(3, 100.0, 0.225): 0.2
(3, 100.0, 0.25): 0.133333333333
(3, 100.0, 0.275): 0.333333333333
(3, 100.0, 0.3): 0.333333333333
(4, 0.1, 0.275): 0.333333333333
(4, 0.1, 0.3): 0.333333333333
(4, 1.0, 0.225): 0.266666666667
(4, 1.0, 0.25): 0.2
(4, 1.0, 0.275): 0.333333333333
(4, 1.0, 0.3): 0.333333333333
(4, 10.0, 0.225): 0.266666666667
(4, 10.0, 0.25): 0.266666666667
(4, 10.0, 0.275): 0.333333333333
(4, 10.0, 0.3): 0.333333333333
(4, 100.0, 0.225): 0.266666666667
(4, 100.0, 0.25): 0.133333333333
(4, 100.0, 0.275): 0.333333333333
(4, 100.0, 0.3): 0.333333333333
(5, 0.1, 0.3): 0.466666666667
(5, 1.0, 0.2): 0.466666666667
(5, 1.0, 0.225): 0.666666666667
(5, 1.0, 0.25): 0.133333333333
(5, 1.0, 0.275): 0.466666666667
(5, 1.0, 0.3): 0.466666666667
(5, 10.0, 0.2): 0.466666666667
(5, 10.0, 0.225): 0.666666666667
(5, 10.0, 0.25): 0.2
(5, 10.0, 0.275): 0.466666666667
(5, 10.0, 0.3): 0.466666666667
(5, 100.0, 0.2): 0.466666666667
(5, 100.0, 0.225): 0.666666666667
(5, 100.0, 0.25): 0.266666666667
(5, 100.0, 0.275): 0.466666666667
(5, 100.0, 0.3): 0.466666666667
(6, 0.1, 0.25): 0.4
(6, 0.1, 0.3): 0.4
(6, 1.0, 0.2): 0.333333333333
(6, 1.0, 0.225): 0.0
(6, 1.0, 0.25): 0.4
(6, 1.0, 0.275): 0.4
(6, 1.0, 0.3): 0.4
(6, 10.0, 0.2): 0.333333333333
(6, 10.0, 0.225): 0.0
(6, 10.0, 0.25): 0.4
(6, 10.0, 0.275): 0.4
(6, 10.0, 0.3): 0.4
(6, 100.0, 0.2): 0.333333333333
(6, 100.0, 0.225): 0.0
(6, 100.0, 0.25): 0.4
(6, 100.0, 0.275): 0.4
(6, 100.0, 0.3): 0.4
(7, 0.1, 0.25): 0.466666666667
(7, 0.1, 0.275): 0.466666666667
(7, 0.1, 0.3): 0.733333333333
(7, 1.0, 0.2): 0.666666666667
(7, 1.0, 0.225): 0.733333333333
(7, 1.0, 0.25): 0.466666666667
(7, 1.0, 0.275): 0.466666666667
(7, 1.0, 0.3): 0.466666666667
(7, 10.0, 0.2): 0.8
(7, 10.0, 0.225): 0.8
(7, 10.0, 0.25): 0.466666666667
(7, 10.0, 0.275): 0.466666666667
(7, 10.0, 0.3): 0.466666666667
(7, 100.0, 0.2): 0.866666666667
(7, 100.0, 0.225): 0.533333333333
(7, 100.0, 0.25): 0.466666666667
(7, 100.0, 0.275): 0.466666666667
(7, 100.0, 0.3): 0.733333333333
(8, 0.1, 0.3): 0.333333333333
(8, 1.0, 0.225): 0.2
(8, 1.0, 0.25): 0.333333333333
(8, 1.0, 0.275): 0.333333333333
(8, 1.0, 0.3): 0.333333333333
(8, 10.0, 0.2): 0.4
(8, 10.0, 0.225): 0.2
(8, 10.0, 0.25): 0.333333333333
(8, 10.0, 0.275): 0.2
(8, 10.0, 0.3): 0.333333333333
(8, 100.0, 0.225): 0.2
(8, 100.0, 0.25): 0.333333333333
(8, 100.0, 0.275): 0.333333333333
(8, 100.0, 0.3): 0.333333333333
(9, 0.1, 0.275): 0.733333333333
(9, 1.0, 0.2): 0.266666666667
(9, 1.0, 0.225): 0.2
(9, 1.0, 0.25): 0.0666666666667
(9, 1.0, 0.275): 0.266666666667
(9, 1.0, 0.3): 0.733333333333
(9, 10.0, 0.2): 0.266666666667
(9, 10.0, 0.225): 0.2
(9, 10.0, 0.25): 0.0
(9, 10.0, 0.275): 0.266666666667
(9, 10.0, 0.3): 0.733333333333
(9, 100.0, 0.2): 0.266666666667
(9, 100.0, 0.225): 0.2
(9, 100.0, 0.25): 0.0
(9, 100.0, 0.275): 0.266666666667
(9, 100.0, 0.3): 0.733333333333

Accuracy mean :0.6424628450106157
Std deviation :0.18248157533217818
Loss mean :0.35753715498938426
Std deviation :0.18248157533217815



