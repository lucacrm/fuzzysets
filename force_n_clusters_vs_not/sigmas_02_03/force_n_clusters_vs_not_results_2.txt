Force_True_2dim, number of iterations: 10

Parameters info
Tradeoffs parameter: [1.e-02 1.e-01 1.e+00 1.e+01 1.e+02]
Gaussian kernel sigmas: [0.2   0.225 0.25  0.275 0.3  ]
Number of principal dimension considerated: 2
Dataset length: 150

Clusterization info
Minimum size of a cluster: in perc: 0.01, in int: 2
Type of mu: Binary Muzzifier
Fuzzifier: Linear
Cluster to label info
Force the number of cluster to be the number of different labels: True
Force the labels to be always represent by a cluster: True

Validation info
Conflict resolution: random


RESULTS

On TEST set

Accuracy on test set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 100.0, 0.3): 0.733333333333
(1, 10.0, 0.275): 0.4
(2, 100.0, 0.225): 0.733333333333
(3, 10.0, 0.225): 0.866666666667
(4, 10.0, 0.2): 0.933333333333
(5, 100.0, 0.25): 0.733333333333
(6, 10.0, 0.25): 0.733333333333
(7, 10.0, 0.225): 0.866666666667
(8, 100.0, 0.2): 0.666666666667
(9, 100.0, 0.2): 0.8

Loss on test set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 100.0, 0.3): 0.266666666667
(1, 10.0, 0.275): 0.6
(2, 100.0, 0.225): 0.266666666667
(3, 10.0, 0.225): 0.133333333333
(4, 10.0, 0.2): 0.0666666666667
(5, 100.0, 0.25): 0.266666666667
(6, 10.0, 0.25): 0.266666666667
(7, 10.0, 0.225): 0.133333333333
(8, 100.0, 0.2): 0.333333333333
(9, 100.0, 0.2): 0.2

Accuracy mean :0.7466666666666668
Std deviation :0.139204086785474
Loss mean :0.25333333333333335
Std deviation :0.139204086785474

On TRAINING set

Accuracy on training set for every iteration (n_of_the_iter, c, sigma):
(0, 100.0, 0.3): 0.740740740741
(1, 10.0, 0.275): 0.711111111111
(2, 100.0, 0.225): 0.851851851852
(3, 10.0, 0.225): 0.844444444444
(4, 10.0, 0.2): 0.837037037037
(5, 100.0, 0.25): 0.777777777778
(6, 10.0, 0.25): 0.711111111111
(7, 10.0, 0.225): 0.874074074074
(8, 100.0, 0.2): 0.674074074074
(9, 100.0, 0.2): 0.814814814815
Loss on training set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 100.0, 0.3): 0.259259259259
(1, 10.0, 0.275): 0.288888888889
(2, 100.0, 0.225): 0.148148148148
(3, 10.0, 0.225): 0.155555555556
(4, 10.0, 0.2): 0.162962962963
(5, 100.0, 0.25): 0.222222222222
(6, 10.0, 0.25): 0.288888888889
(7, 10.0, 0.225): 0.125925925926
(8, 100.0, 0.2): 0.325925925926
(9, 100.0, 0.2): 0.185185185185

Accuracy mean :0.7837037037037037
Std deviation :0.06689672239926303
Loss mean :0.2162962962962963
Std deviation :0.06689672239926303

On ALL the sets

Accuracy on all the set for every iteration, for every couple c,sigma (n_of_the_iter, c, sigma):
(0, 0.1, 0.3): 1.0
(0, 1.0, 0.2): 0.733333333333
(0, 1.0, 0.225): 0.4
(0, 1.0, 0.25): 0.466666666667
(0, 1.0, 0.275): 0.866666666667
(0, 1.0, 0.3): 1.0
(0, 10.0, 0.2): 0.733333333333
(0, 10.0, 0.225): 0.866666666667
(0, 10.0, 0.25): 0.466666666667
(0, 10.0, 0.275): 0.866666666667
(0, 10.0, 0.3): 1.0
(0, 100.0, 0.2): 0.733333333333
(0, 100.0, 0.225): 0.4
(0, 100.0, 0.25): 0.466666666667
(0, 100.0, 0.275): 0.866666666667
(0, 100.0, 0.3): 1.0
(1, 0.1, 0.275): 0.866666666667
(1, 1.0, 0.2): 0.8
(1, 1.0, 0.225): 0.8
(1, 1.0, 0.25): 0.8
(1, 1.0, 0.275): 0.866666666667
(1, 10.0, 0.2): 0.8
(1, 10.0, 0.225): 0.8
(1, 10.0, 0.25): 0.8
(1, 10.0, 0.275): 0.866666666667
(1, 100.0, 0.2): 0.8
(1, 100.0, 0.25): 0.8
(1, 100.0, 0.275): 0.8
(2, 1.0, 0.225): 0.8
(2, 1.0, 0.25): 0.666666666667
(2, 10.0, 0.225): 0.8
(2, 10.0, 0.25): 0.666666666667
(2, 100.0, 0.225): 0.8
(2, 100.0, 0.25): 0.666666666667
(3, 1.0, 0.2): 0.733333333333
(3, 1.0, 0.225): 0.8
(3, 1.0, 0.25): 0.533333333333
(3, 10.0, 0.2): 0.8
(3, 10.0, 0.225): 0.8
(3, 10.0, 0.25): 0.8
(3, 100.0, 0.2): 0.8
(3, 100.0, 0.225): 0.8
(3, 100.0, 0.25): 0.533333333333
(4, 1.0, 0.2): 0.8
(4, 1.0, 0.225): 0.666666666667
(4, 1.0, 0.25): 0.733333333333
(4, 1.0, 0.275): 0.666666666667
(4, 1.0, 0.3): 0.666666666667
(4, 10.0, 0.2): 0.8
(4, 10.0, 0.225): 0.666666666667
(4, 10.0, 0.25): 0.733333333333
(4, 10.0, 0.275): 0.666666666667
(4, 100.0, 0.2): 0.733333333333
(4, 100.0, 0.225): 0.733333333333
(4, 100.0, 0.25): 0.666666666667
(4, 100.0, 0.275): 0.666666666667
(5, 1.0, 0.2): 0.533333333333
(5, 1.0, 0.225): 0.733333333333
(5, 1.0, 0.25): 0.8
(5, 1.0, 0.275): 0.733333333333
(5, 1.0, 0.3): 0.8
(5, 10.0, 0.2): 0.533333333333
(5, 10.0, 0.225): 0.733333333333
(5, 10.0, 0.25): 0.8
(5, 10.0, 0.275): 0.8
(5, 10.0, 0.3): 0.8
(5, 100.0, 0.2): 0.6
(5, 100.0, 0.225): 0.8
(5, 100.0, 0.25): 0.866666666667
(5, 100.0, 0.275): 0.666666666667
(5, 100.0, 0.3): 0.8
(6, 1.0, 0.2): 0.866666666667
(6, 1.0, 0.225): 0.866666666667
(6, 1.0, 0.25): 0.866666666667
(6, 1.0, 0.275): 0.866666666667
(6, 1.0, 0.3): 0.266666666667
(6, 10.0, 0.2): 0.866666666667
(6, 10.0, 0.225): 0.866666666667
(6, 10.0, 0.25): 0.866666666667
(6, 10.0, 0.275): 0.866666666667
(6, 10.0, 0.3): 0.266666666667
(6, 100.0, 0.2): 0.866666666667
(6, 100.0, 0.225): 0.866666666667
(6, 100.0, 0.25): 0.866666666667
(6, 100.0, 0.275): 0.866666666667
(7, 1.0, 0.225): 0.933333333333
(7, 1.0, 0.275): 0.866666666667
(7, 10.0, 0.225): 0.933333333333
(7, 10.0, 0.275): 0.8
(7, 100.0, 0.2): 0.4
(7, 100.0, 0.225): 0.933333333333
(7, 100.0, 0.25): 0.866666666667
(7, 100.0, 0.275): 0.866666666667
(8, 1.0, 0.225): 0.533333333333
(8, 1.0, 0.25): 0.8
(8, 1.0, 0.275): 0.8
(8, 1.0, 0.3): 0.466666666667
(8, 10.0, 0.225): 0.6
(8, 10.0, 0.25): 0.8
(8, 10.0, 0.275): 0.8
(8, 10.0, 0.3): 0.466666666667
(8, 100.0, 0.2): 0.933333333333
(8, 100.0, 0.225): 0.533333333333
(8, 100.0, 0.275): 0.466666666667
(8, 100.0, 0.3): 0.466666666667
(9, 1.0, 0.2): 0.866666666667
(9, 1.0, 0.225): 0.666666666667
(9, 1.0, 0.25): 0.666666666667
(9, 1.0, 0.275): 0.6
(9, 1.0, 0.3): 0.733333333333
(9, 10.0, 0.2): 0.866666666667
(9, 10.0, 0.225): 0.666666666667
(9, 10.0, 0.25): 0.666666666667
(9, 10.0, 0.275): 0.6
(9, 10.0, 0.3): 0.733333333333
(9, 100.0, 0.2): 0.866666666667
(9, 100.0, 0.225): 0.666666666667
(9, 100.0, 0.25): 0.733333333333
(9, 100.0, 0.275): 0.6
(9, 100.0, 0.3): 0.733333333333

Loss on all the set for every iteration, for every couple c,sigma (n_of_the_iter, best_c, best_sigma):
(0, 0.1, 0.3): 0.0
(0, 1.0, 0.2): 0.266666666667
(0, 1.0, 0.225): 0.6
(0, 1.0, 0.25): 0.533333333333
(0, 1.0, 0.275): 0.133333333333
(0, 1.0, 0.3): 0.0
(0, 10.0, 0.2): 0.266666666667
(0, 10.0, 0.225): 0.133333333333
(0, 10.0, 0.25): 0.533333333333
(0, 10.0, 0.275): 0.133333333333
(0, 10.0, 0.3): 0.0
(0, 100.0, 0.2): 0.266666666667
(0, 100.0, 0.225): 0.6
(0, 100.0, 0.25): 0.533333333333
(0, 100.0, 0.275): 0.133333333333
(0, 100.0, 0.3): 0.0
(1, 0.1, 0.275): 0.133333333333
(1, 1.0, 0.2): 0.2
(1, 1.0, 0.225): 0.2
(1, 1.0, 0.25): 0.2
(1, 1.0, 0.275): 0.133333333333
(1, 10.0, 0.2): 0.2
(1, 10.0, 0.225): 0.2
(1, 10.0, 0.25): 0.2
(1, 10.0, 0.275): 0.133333333333
(1, 100.0, 0.2): 0.2
(1, 100.0, 0.25): 0.2
(1, 100.0, 0.275): 0.2
(2, 1.0, 0.225): 0.2
(2, 1.0, 0.25): 0.333333333333
(2, 10.0, 0.225): 0.2
(2, 10.0, 0.25): 0.333333333333
(2, 100.0, 0.225): 0.2
(2, 100.0, 0.25): 0.333333333333
(3, 1.0, 0.2): 0.266666666667
(3, 1.0, 0.225): 0.2
(3, 1.0, 0.25): 0.466666666667
(3, 10.0, 0.2): 0.2
(3, 10.0, 0.225): 0.2
(3, 10.0, 0.25): 0.2
(3, 100.0, 0.2): 0.2
(3, 100.0, 0.225): 0.2
(3, 100.0, 0.25): 0.466666666667
(4, 1.0, 0.2): 0.2
(4, 1.0, 0.225): 0.333333333333
(4, 1.0, 0.25): 0.266666666667
(4, 1.0, 0.275): 0.333333333333
(4, 1.0, 0.3): 0.333333333333
(4, 10.0, 0.2): 0.2
(4, 10.0, 0.225): 0.333333333333
(4, 10.0, 0.25): 0.266666666667
(4, 10.0, 0.275): 0.333333333333
(4, 100.0, 0.2): 0.266666666667
(4, 100.0, 0.225): 0.266666666667
(4, 100.0, 0.25): 0.333333333333
(4, 100.0, 0.275): 0.333333333333
(5, 1.0, 0.2): 0.466666666667
(5, 1.0, 0.225): 0.266666666667
(5, 1.0, 0.25): 0.2
(5, 1.0, 0.275): 0.266666666667
(5, 1.0, 0.3): 0.2
(5, 10.0, 0.2): 0.466666666667
(5, 10.0, 0.225): 0.266666666667
(5, 10.0, 0.25): 0.2
(5, 10.0, 0.275): 0.2
(5, 10.0, 0.3): 0.2
(5, 100.0, 0.2): 0.4
(5, 100.0, 0.225): 0.2
(5, 100.0, 0.25): 0.133333333333
(5, 100.0, 0.275): 0.333333333333
(5, 100.0, 0.3): 0.2
(6, 1.0, 0.2): 0.133333333333
(6, 1.0, 0.225): 0.133333333333
(6, 1.0, 0.25): 0.133333333333
(6, 1.0, 0.275): 0.133333333333
(6, 1.0, 0.3): 0.733333333333
(6, 10.0, 0.2): 0.133333333333
(6, 10.0, 0.225): 0.133333333333
(6, 10.0, 0.25): 0.133333333333
(6, 10.0, 0.275): 0.133333333333
(6, 10.0, 0.3): 0.733333333333
(6, 100.0, 0.2): 0.133333333333
(6, 100.0, 0.225): 0.133333333333
(6, 100.0, 0.25): 0.133333333333
(6, 100.0, 0.275): 0.133333333333
(7, 1.0, 0.225): 0.0666666666667
(7, 1.0, 0.275): 0.133333333333
(7, 10.0, 0.225): 0.0666666666667
(7, 10.0, 0.275): 0.2
(7, 100.0, 0.2): 0.6
(7, 100.0, 0.225): 0.0666666666667
(7, 100.0, 0.25): 0.133333333333
(7, 100.0, 0.275): 0.133333333333
(8, 1.0, 0.225): 0.466666666667
(8, 1.0, 0.25): 0.2
(8, 1.0, 0.275): 0.2
(8, 1.0, 0.3): 0.533333333333
(8, 10.0, 0.225): 0.4
(8, 10.0, 0.25): 0.2
(8, 10.0, 0.275): 0.2
(8, 10.0, 0.3): 0.533333333333
(8, 100.0, 0.2): 0.0666666666667
(8, 100.0, 0.225): 0.466666666667
(8, 100.0, 0.275): 0.533333333333
(8, 100.0, 0.3): 0.533333333333
(9, 1.0, 0.2): 0.133333333333
(9, 1.0, 0.225): 0.333333333333
(9, 1.0, 0.25): 0.333333333333
(9, 1.0, 0.275): 0.4
(9, 1.0, 0.3): 0.266666666667
(9, 10.0, 0.2): 0.133333333333
(9, 10.0, 0.225): 0.333333333333
(9, 10.0, 0.25): 0.333333333333
(9, 10.0, 0.275): 0.4
(9, 10.0, 0.3): 0.266666666667
(9, 100.0, 0.2): 0.133333333333
(9, 100.0, 0.225): 0.333333333333
(9, 100.0, 0.25): 0.266666666667
(9, 100.0, 0.275): 0.4
(9, 100.0, 0.3): 0.266666666667

Accuracy mean :0.7394444444444445
Std deviation :0.15030729839438034
Loss mean :0.26055555555555554
Std deviation :0.1503072983943803



Force_False_2dim, number of iterations: 10

Parameters info
Tradeoffs parameter: [1.e-02 1.e-01 1.e+00 1.e+01 1.e+02]
Gaussian kernel sigmas: [0.2   0.225 0.25  0.275 0.3  ]
Number of principal dimension considerated: 2
Dataset length: 150

Clusterization info
Minimum size of a cluster: in perc: 0.01, in int: 2
Type of mu: Binary Muzzifier
Fuzzifier: Linear
Cluster to label info
Force the number of cluster to be the number of different labels: False
Force the labels to be always represent by a cluster: False

Validation info
Conflict resolution: random


RESULTS

On TEST set

Accuracy on test set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 10.0, 0.2): 0.333333333333
(1, 10.0, 0.2): 1.0
(2, 100.0, 0.2): 0.8
(3, 1.0, 0.225): 0.8
(4, 1.0, 0.2): 0.933333333333
(5, 1.0, 0.225): 0.8
(6, 10.0, 0.225): 0.866666666667
(7, 1.0, 0.25): 0.866666666667
(8, 10.0, 0.225): 0.733333333333
(9, 1.0, 0.275): 0.666666666667

Loss on test set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 10.0, 0.2): 0.666666666667
(1, 10.0, 0.2): 0.0
(2, 100.0, 0.2): 0.2
(3, 1.0, 0.225): 0.2
(4, 1.0, 0.2): 0.0666666666667
(5, 1.0, 0.225): 0.2
(6, 10.0, 0.225): 0.133333333333
(7, 1.0, 0.25): 0.133333333333
(8, 10.0, 0.225): 0.266666666667
(9, 1.0, 0.275): 0.333333333333

Accuracy mean :0.7799999999999999
Std deviation :0.17397317800933187
Loss mean :0.22000000000000003
Std deviation :0.17397317800933185

On TRAINING set

Accuracy on training set for every iteration (n_of_the_iter, c, sigma):
(0, 10.0, 0.2): 0.42962962963
(1, 10.0, 0.2): 0.866666666667
(2, 100.0, 0.2): 0.874074074074
(3, 1.0, 0.225): 0.807407407407
(4, 1.0, 0.2): 0.859259259259
(5, 1.0, 0.225): 0.925925925926
(6, 10.0, 0.225): 0.866666666667
(7, 1.0, 0.25): 0.82962962963
(8, 10.0, 0.225): 0.777777777778
(9, 1.0, 0.275): 0.666666666667
Loss on training set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 10.0, 0.2): 0.57037037037
(1, 10.0, 0.2): 0.133333333333
(2, 100.0, 0.2): 0.125925925926
(3, 1.0, 0.225): 0.192592592593
(4, 1.0, 0.2): 0.140740740741
(5, 1.0, 0.225): 0.0740740740741
(6, 10.0, 0.225): 0.133333333333
(7, 1.0, 0.25): 0.17037037037
(8, 10.0, 0.225): 0.222222222222
(9, 1.0, 0.275): 0.333333333333

Accuracy mean :0.7903703703703704
Std deviation :0.13754859473003897
Loss mean :0.20962962962962967
Std deviation :0.137548594730039

On ALL the sets

Accuracy on all the set for every iteration, for every couple c,sigma (n_of_the_iter, c, sigma):
(0, 0.1, 0.3): 0.733333333333
(0, 1.0, 0.2): 0.8
(0, 1.0, 0.225): 0.733333333333
(0, 1.0, 0.25): 0.666666666667
(0, 1.0, 0.275): 0.533333333333
(0, 1.0, 0.3): 0.733333333333
(0, 10.0, 0.2): 0.8
(0, 10.0, 0.225): 0.6
(0, 10.0, 0.25): 0.666666666667
(0, 10.0, 0.275): 0.533333333333
(0, 10.0, 0.3): 0.733333333333
(0, 100.0, 0.2): 0.8
(0, 100.0, 0.225): 0.6
(0, 100.0, 0.25): 0.666666666667
(0, 100.0, 0.275): 0.533333333333
(0, 100.0, 0.3): 0.733333333333
(1, 1.0, 0.2): 0.8
(1, 1.0, 0.225): 0.533333333333
(1, 1.0, 0.25): 0.466666666667
(1, 1.0, 0.275): 0.533333333333
(1, 1.0, 0.3): 0.533333333333
(1, 10.0, 0.2): 0.8
(1, 10.0, 0.225): 0.533333333333
(1, 10.0, 0.25): 0.466666666667
(1, 10.0, 0.275): 0.533333333333
(1, 10.0, 0.3): 0.533333333333
(1, 100.0, 0.2): 0.8
(1, 100.0, 0.225): 0.533333333333
(1, 100.0, 0.25): 0.466666666667
(1, 100.0, 0.275): 0.533333333333
(1, 100.0, 0.3): 0.533333333333
(2, 1.0, 0.2): 0.466666666667
(2, 1.0, 0.225): 0.933333333333
(2, 1.0, 0.25): 0.8
(2, 1.0, 0.275): 0.8
(2, 1.0, 0.3): 0.733333333333
(2, 10.0, 0.2): 0.8
(2, 10.0, 0.225): 0.933333333333
(2, 10.0, 0.25): 0.8
(2, 10.0, 0.275): 0.8
(2, 10.0, 0.3): 0.8
(2, 100.0, 0.2): 1.0
(2, 100.0, 0.225): 0.4
(2, 100.0, 0.25): 0.866666666667
(2, 100.0, 0.275): 0.8
(2, 100.0, 0.3): 0.733333333333
(3, 1.0, 0.2): 0.933333333333
(3, 1.0, 0.225): 1.0
(3, 1.0, 0.25): 0.8
(3, 1.0, 0.275): 0.666666666667
(3, 1.0, 0.3): 0.666666666667
(3, 10.0, 0.2): 0.933333333333
(3, 10.0, 0.225): 1.0
(3, 10.0, 0.25): 0.8
(3, 10.0, 0.275): 0.666666666667
(3, 10.0, 0.3): 0.666666666667
(3, 100.0, 0.2): 0.933333333333
(3, 100.0, 0.225): 1.0
(3, 100.0, 0.25): 0.8
(3, 100.0, 0.275): 0.666666666667
(3, 100.0, 0.3): 0.666666666667
(4, 0.1, 0.275): 0.8
(4, 0.1, 0.3): 0.8
(4, 1.0, 0.2): 0.866666666667
(4, 1.0, 0.225): 0.733333333333
(4, 1.0, 0.25): 0.733333333333
(4, 1.0, 0.275): 0.8
(4, 1.0, 0.3): 0.666666666667
(4, 10.0, 0.2): 0.666666666667
(4, 10.0, 0.225): 0.733333333333
(4, 10.0, 0.25): 0.733333333333
(4, 10.0, 0.275): 0.8
(4, 10.0, 0.3): 0.666666666667
(4, 100.0, 0.2): 0.666666666667
(4, 100.0, 0.225): 0.733333333333
(4, 100.0, 0.25): 0.8
(4, 100.0, 0.275): 0.8
(4, 100.0, 0.3): 0.666666666667
(5, 0.1, 0.25): 0.6
(5, 0.1, 0.275): 0.6
(5, 0.1, 0.3): 0.866666666667
(5, 1.0, 0.2): 0.933333333333
(5, 1.0, 0.225): 0.933333333333
(5, 1.0, 0.25): 0.6
(5, 1.0, 0.275): 0.8
(5, 1.0, 0.3): 0.266666666667
(5, 10.0, 0.2): 0.866666666667
(5, 10.0, 0.225): 0.866666666667
(5, 10.0, 0.25): 0.6
(5, 10.0, 0.275): 0.8
(5, 10.0, 0.3): 0.6
(5, 100.0, 0.2): 0.866666666667
(5, 100.0, 0.225): 0.933333333333
(5, 100.0, 0.25): 0.6
(5, 100.0, 0.275): 0.6
(5, 100.0, 0.3): 0.266666666667
(6, 1.0, 0.2): 0.8
(6, 1.0, 0.225): 0.866666666667
(6, 1.0, 0.25): 0.666666666667
(6, 1.0, 0.275): 0.6
(6, 1.0, 0.3): 0.666666666667
(6, 10.0, 0.2): 0.866666666667
(6, 10.0, 0.225): 0.866666666667
(6, 10.0, 0.25): 0.666666666667
(6, 10.0, 0.275): 0.6
(6, 10.0, 0.3): 0.666666666667
(6, 100.0, 0.2): 0.866666666667
(6, 100.0, 0.225): 0.866666666667
(6, 100.0, 0.25): 0.666666666667
(6, 100.0, 0.275): 0.6
(6, 100.0, 0.3): 0.666666666667
(7, 1.0, 0.2): 0.8
(7, 1.0, 0.225): 0.866666666667
(7, 1.0, 0.25): 0.933333333333
(7, 1.0, 0.275): 0.933333333333
(7, 1.0, 0.3): 0.733333333333
(7, 10.0, 0.2): 0.8
(7, 10.0, 0.225): 0.866666666667
(7, 10.0, 0.25): 0.933333333333
(7, 10.0, 0.275): 0.733333333333
(7, 10.0, 0.3): 0.733333333333
(7, 100.0, 0.2): 0.8
(7, 100.0, 0.225): 0.866666666667
(7, 100.0, 0.25): 0.933333333333
(7, 100.0, 0.275): 0.733333333333
(7, 100.0, 0.3): 0.733333333333
(8, 1.0, 0.2): 0.733333333333
(8, 1.0, 0.225): 0.866666666667
(8, 1.0, 0.25): 0.2
(8, 1.0, 0.3): 0.8
(8, 10.0, 0.2): 0.8
(8, 10.0, 0.225): 0.933333333333
(8, 10.0, 0.25): 0.733333333333
(8, 10.0, 0.275): 0.8
(8, 10.0, 0.3): 0.8
(8, 100.0, 0.2): 0.8
(8, 100.0, 0.225): 0.933333333333
(8, 100.0, 0.25): 0.2
(8, 100.0, 0.275): 0.8
(8, 100.0, 0.3): 0.8
(9, 1.0, 0.2): 0.2
(9, 1.0, 0.225): 0.733333333333
(9, 1.0, 0.25): 0.8
(9, 1.0, 0.275): 0.866666666667
(9, 1.0, 0.3): 0.533333333333
(9, 10.0, 0.2): 0.2
(9, 10.0, 0.225): 0.733333333333
(9, 10.0, 0.25): 0.8
(9, 10.0, 0.275): 0.733333333333
(9, 10.0, 0.3): 0.533333333333
(9, 100.0, 0.2): 0.2
(9, 100.0, 0.225): 0.4
(9, 100.0, 0.25): 0.8
(9, 100.0, 0.275): 0.733333333333
(9, 100.0, 0.3): 0.533333333333

Loss on all the set for every iteration, for every couple c,sigma (n_of_the_iter, best_c, best_sigma):
(0, 0.1, 0.3): 0.266666666667
(0, 1.0, 0.2): 0.2
(0, 1.0, 0.225): 0.266666666667
(0, 1.0, 0.25): 0.333333333333
(0, 1.0, 0.275): 0.466666666667
(0, 1.0, 0.3): 0.266666666667
(0, 10.0, 0.2): 0.2
(0, 10.0, 0.225): 0.4
(0, 10.0, 0.25): 0.333333333333
(0, 10.0, 0.275): 0.466666666667
(0, 10.0, 0.3): 0.266666666667
(0, 100.0, 0.2): 0.2
(0, 100.0, 0.225): 0.4
(0, 100.0, 0.25): 0.333333333333
(0, 100.0, 0.275): 0.466666666667
(0, 100.0, 0.3): 0.266666666667
(1, 1.0, 0.2): 0.2
(1, 1.0, 0.225): 0.466666666667
(1, 1.0, 0.25): 0.533333333333
(1, 1.0, 0.275): 0.466666666667
(1, 1.0, 0.3): 0.466666666667
(1, 10.0, 0.2): 0.2
(1, 10.0, 0.225): 0.466666666667
(1, 10.0, 0.25): 0.533333333333
(1, 10.0, 0.275): 0.466666666667
(1, 10.0, 0.3): 0.466666666667
(1, 100.0, 0.2): 0.2
(1, 100.0, 0.225): 0.466666666667
(1, 100.0, 0.25): 0.533333333333
(1, 100.0, 0.275): 0.466666666667
(1, 100.0, 0.3): 0.466666666667
(2, 1.0, 0.2): 0.533333333333
(2, 1.0, 0.225): 0.0666666666667
(2, 1.0, 0.25): 0.2
(2, 1.0, 0.275): 0.2
(2, 1.0, 0.3): 0.266666666667
(2, 10.0, 0.2): 0.2
(2, 10.0, 0.225): 0.0666666666667
(2, 10.0, 0.25): 0.2
(2, 10.0, 0.275): 0.2
(2, 10.0, 0.3): 0.2
(2, 100.0, 0.2): 0.0
(2, 100.0, 0.225): 0.6
(2, 100.0, 0.25): 0.133333333333
(2, 100.0, 0.275): 0.2
(2, 100.0, 0.3): 0.266666666667
(3, 1.0, 0.2): 0.0666666666667
(3, 1.0, 0.225): 0.0
(3, 1.0, 0.25): 0.2
(3, 1.0, 0.275): 0.333333333333
(3, 1.0, 0.3): 0.333333333333
(3, 10.0, 0.2): 0.0666666666667
(3, 10.0, 0.225): 0.0
(3, 10.0, 0.25): 0.2
(3, 10.0, 0.275): 0.333333333333
(3, 10.0, 0.3): 0.333333333333
(3, 100.0, 0.2): 0.0666666666667
(3, 100.0, 0.225): 0.0
(3, 100.0, 0.25): 0.2
(3, 100.0, 0.275): 0.333333333333
(3, 100.0, 0.3): 0.333333333333
(4, 0.1, 0.275): 0.2
(4, 0.1, 0.3): 0.2
(4, 1.0, 0.2): 0.133333333333
(4, 1.0, 0.225): 0.266666666667
(4, 1.0, 0.25): 0.266666666667
(4, 1.0, 0.275): 0.2
(4, 1.0, 0.3): 0.333333333333
(4, 10.0, 0.2): 0.333333333333
(4, 10.0, 0.225): 0.266666666667
(4, 10.0, 0.25): 0.266666666667
(4, 10.0, 0.275): 0.2
(4, 10.0, 0.3): 0.333333333333
(4, 100.0, 0.2): 0.333333333333
(4, 100.0, 0.225): 0.266666666667
(4, 100.0, 0.25): 0.2
(4, 100.0, 0.275): 0.2
(4, 100.0, 0.3): 0.333333333333
(5, 0.1, 0.25): 0.4
(5, 0.1, 0.275): 0.4
(5, 0.1, 0.3): 0.133333333333
(5, 1.0, 0.2): 0.0666666666667
(5, 1.0, 0.225): 0.0666666666667
(5, 1.0, 0.25): 0.4
(5, 1.0, 0.275): 0.2
(5, 1.0, 0.3): 0.733333333333
(5, 10.0, 0.2): 0.133333333333
(5, 10.0, 0.225): 0.133333333333
(5, 10.0, 0.25): 0.4
(5, 10.0, 0.275): 0.2
(5, 10.0, 0.3): 0.4
(5, 100.0, 0.2): 0.133333333333
(5, 100.0, 0.225): 0.0666666666667
(5, 100.0, 0.25): 0.4
(5, 100.0, 0.275): 0.4
(5, 100.0, 0.3): 0.733333333333
(6, 1.0, 0.2): 0.2
(6, 1.0, 0.225): 0.133333333333
(6, 1.0, 0.25): 0.333333333333
(6, 1.0, 0.275): 0.4
(6, 1.0, 0.3): 0.333333333333
(6, 10.0, 0.2): 0.133333333333
(6, 10.0, 0.225): 0.133333333333
(6, 10.0, 0.25): 0.333333333333
(6, 10.0, 0.275): 0.4
(6, 10.0, 0.3): 0.333333333333
(6, 100.0, 0.2): 0.133333333333
(6, 100.0, 0.225): 0.133333333333
(6, 100.0, 0.25): 0.333333333333
(6, 100.0, 0.275): 0.4
(6, 100.0, 0.3): 0.333333333333
(7, 1.0, 0.2): 0.2
(7, 1.0, 0.225): 0.133333333333
(7, 1.0, 0.25): 0.0666666666667
(7, 1.0, 0.275): 0.0666666666667
(7, 1.0, 0.3): 0.266666666667
(7, 10.0, 0.2): 0.2
(7, 10.0, 0.225): 0.133333333333
(7, 10.0, 0.25): 0.0666666666667
(7, 10.0, 0.275): 0.266666666667
(7, 10.0, 0.3): 0.266666666667
(7, 100.0, 0.2): 0.2
(7, 100.0, 0.225): 0.133333333333
(7, 100.0, 0.25): 0.0666666666667
(7, 100.0, 0.275): 0.266666666667
(7, 100.0, 0.3): 0.266666666667
(8, 1.0, 0.2): 0.266666666667
(8, 1.0, 0.225): 0.133333333333
(8, 1.0, 0.25): 0.8
(8, 1.0, 0.3): 0.2
(8, 10.0, 0.2): 0.2
(8, 10.0, 0.225): 0.0666666666667
(8, 10.0, 0.25): 0.266666666667
(8, 10.0, 0.275): 0.2
(8, 10.0, 0.3): 0.2
(8, 100.0, 0.2): 0.2
(8, 100.0, 0.225): 0.0666666666667
(8, 100.0, 0.25): 0.8
(8, 100.0, 0.275): 0.2
(8, 100.0, 0.3): 0.2
(9, 1.0, 0.2): 0.8
(9, 1.0, 0.225): 0.266666666667
(9, 1.0, 0.25): 0.2
(9, 1.0, 0.275): 0.133333333333
(9, 1.0, 0.3): 0.466666666667
(9, 10.0, 0.2): 0.8
(9, 10.0, 0.225): 0.266666666667
(9, 10.0, 0.25): 0.2
(9, 10.0, 0.275): 0.266666666667
(9, 10.0, 0.3): 0.466666666667
(9, 100.0, 0.2): 0.8
(9, 100.0, 0.225): 0.6
(9, 100.0, 0.25): 0.2
(9, 100.0, 0.275): 0.266666666667
(9, 100.0, 0.3): 0.466666666667

Accuracy mean :0.7156989247311828
Std deviation :0.17069580049634359
Loss mean :0.2843010752688172
Std deviation :0.17069580049634359



Force_True_3dim, number of iterations: 10

Parameters info
Tradeoffs parameter: [1.e-02 1.e-01 1.e+00 1.e+01 1.e+02]
Gaussian kernel sigmas: [0.2   0.225 0.25  0.275 0.3  ]
Number of principal dimension considerated: 3
Dataset length: 150

Clusterization info
Minimum size of a cluster: in perc: 0.01, in int: 2
Type of mu: Binary Muzzifier
Fuzzifier: Linear
Cluster to label info
Force the number of cluster to be the number of different labels: True
Force the labels to be always represent by a cluster: True

Validation info
Conflict resolution: random


RESULTS

On TEST set

Accuracy on test set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 10.0, 0.25): 0.933333333333
(1, 10.0, 0.2): 0.8
(2, 1.0, 0.2): 0.733333333333
(3, 1.0, 0.225): 0.933333333333
(4, 10.0, 0.275): 0.866666666667
(5, 1.0, 0.2): 0.933333333333
(6, 10.0, 0.25): 0.866666666667
(7, 100.0, 0.3): 0.933333333333
(8, 1.0, 0.2): 0.866666666667
(9, 10.0, 0.225): 0.8

Loss on test set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 10.0, 0.25): 0.0666666666667
(1, 10.0, 0.2): 0.2
(2, 1.0, 0.2): 0.266666666667
(3, 1.0, 0.225): 0.0666666666667
(4, 10.0, 0.275): 0.133333333333
(5, 1.0, 0.2): 0.0666666666667
(6, 10.0, 0.25): 0.133333333333
(7, 100.0, 0.3): 0.0666666666667
(8, 1.0, 0.2): 0.133333333333
(9, 10.0, 0.225): 0.2

Accuracy mean :0.8666666666666668
Std deviation :0.06666666666666668
Loss mean :0.13333333333333336
Std deviation :0.06666666666666667

On TRAINING set

Accuracy on training set for every iteration (n_of_the_iter, c, sigma):
(0, 10.0, 0.25): 0.837037037037
(1, 10.0, 0.2): 0.8
(2, 1.0, 0.2): 0.851851851852
(3, 1.0, 0.225): 0.851851851852
(4, 10.0, 0.275): 0.955555555556
(5, 1.0, 0.2): 0.807407407407
(6, 10.0, 0.25): 0.918518518519
(7, 100.0, 0.3): 0.925925925926
(8, 1.0, 0.2): 0.859259259259
(9, 10.0, 0.225): 0.881481481481
Loss on training set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 10.0, 0.25): 0.162962962963
(1, 10.0, 0.2): 0.2
(2, 1.0, 0.2): 0.148148148148
(3, 1.0, 0.225): 0.148148148148
(4, 10.0, 0.275): 0.0444444444444
(5, 1.0, 0.2): 0.192592592593
(6, 10.0, 0.25): 0.0814814814815
(7, 100.0, 0.3): 0.0740740740741
(8, 1.0, 0.2): 0.140740740741
(9, 10.0, 0.225): 0.118518518519

Accuracy mean :0.8688888888888888
Std deviation :0.04857926646539139
Loss mean :0.13111111111111112
Std deviation :0.04857926646539139

On ALL the sets

Accuracy on all the set for every iteration, for every couple c,sigma (n_of_the_iter, c, sigma):
(0, 1.0, 0.2): 0.8
(0, 1.0, 0.225): 0.8
(0, 1.0, 0.25): 0.733333333333
(0, 1.0, 0.3): 0.733333333333
(0, 10.0, 0.2): 0.733333333333
(0, 10.0, 0.225): 0.8
(0, 10.0, 0.25): 0.933333333333
(0, 10.0, 0.3): 0.733333333333
(0, 100.0, 0.2): 0.733333333333
(0, 100.0, 0.225): 0.8
(0, 100.0, 0.25): 0.733333333333
(0, 100.0, 0.3): 0.733333333333
(1, 1.0, 0.2): 0.866666666667
(1, 1.0, 0.225): 0.866666666667
(1, 1.0, 0.25): 0.8
(1, 1.0, 0.275): 0.733333333333
(1, 10.0, 0.2): 0.866666666667
(1, 10.0, 0.225): 0.866666666667
(1, 10.0, 0.25): 0.8
(1, 10.0, 0.275): 0.733333333333
(1, 100.0, 0.225): 0.866666666667
(1, 100.0, 0.25): 0.8
(1, 100.0, 0.275): 0.733333333333
(2, 1.0, 0.2): 1.0
(2, 1.0, 0.225): 0.933333333333
(2, 1.0, 0.25): 0.866666666667
(2, 1.0, 0.275): 0.866666666667
(2, 1.0, 0.3): 0.866666666667
(2, 10.0, 0.2): 1.0
(2, 10.0, 0.225): 0.933333333333
(2, 10.0, 0.25): 0.866666666667
(2, 10.0, 0.275): 0.866666666667
(2, 100.0, 0.2): 0.933333333333
(2, 100.0, 0.225): 0.933333333333
(2, 100.0, 0.25): 0.866666666667
(2, 100.0, 0.275): 0.866666666667
(2, 100.0, 0.3): 0.866666666667
(3, 1.0, 0.2): 0.933333333333
(3, 1.0, 0.225): 0.933333333333
(3, 1.0, 0.25): 0.866666666667
(3, 1.0, 0.275): 0.733333333333
(3, 1.0, 0.3): 0.733333333333
(3, 10.0, 0.2): 0.933333333333
(3, 10.0, 0.225): 0.933333333333
(3, 10.0, 0.25): 0.866666666667
(3, 10.0, 0.275): 0.733333333333
(3, 10.0, 0.3): 0.733333333333
(3, 100.0, 0.2): 0.933333333333
(3, 100.0, 0.225): 0.933333333333
(3, 100.0, 0.25): 0.866666666667
(3, 100.0, 0.275): 0.733333333333
(3, 100.0, 0.3): 0.733333333333
(4, 1.0, 0.2): 0.866666666667
(4, 1.0, 0.225): 0.866666666667
(4, 1.0, 0.275): 0.933333333333
(4, 10.0, 0.2): 0.866666666667
(4, 10.0, 0.225): 0.866666666667
(4, 10.0, 0.275): 0.933333333333
(4, 100.0, 0.2): 0.866666666667
(4, 100.0, 0.225): 0.866666666667
(4, 100.0, 0.275): 0.933333333333
(5, 1.0, 0.2): 0.8
(5, 1.0, 0.225): 0.733333333333
(5, 1.0, 0.25): 0.666666666667
(5, 1.0, 0.275): 0.666666666667
(5, 1.0, 0.3): 0.666666666667
(5, 10.0, 0.2): 0.733333333333
(5, 10.0, 0.225): 0.733333333333
(5, 10.0, 0.25): 0.666666666667
(5, 10.0, 0.3): 0.666666666667
(5, 100.0, 0.2): 0.666666666667
(5, 100.0, 0.225): 0.733333333333
(5, 100.0, 0.275): 0.666666666667
(5, 100.0, 0.3): 0.666666666667
(6, 1.0, 0.2): 0.8
(6, 1.0, 0.225): 1.0
(6, 1.0, 0.25): 1.0
(6, 1.0, 0.275): 0.933333333333
(6, 1.0, 0.3): 0.8
(6, 10.0, 0.2): 0.8
(6, 10.0, 0.225): 1.0
(6, 10.0, 0.25): 1.0
(6, 10.0, 0.275): 0.933333333333
(6, 10.0, 0.3): 0.8
(6, 100.0, 0.2): 0.8
(6, 100.0, 0.225): 1.0
(6, 100.0, 0.25): 1.0
(6, 100.0, 0.275): 0.933333333333
(6, 100.0, 0.3): 0.8
(7, 1.0, 0.225): 0.933333333333
(7, 1.0, 0.25): 0.933333333333
(7, 1.0, 0.275): 1.0
(7, 1.0, 0.3): 1.0
(7, 10.0, 0.225): 0.933333333333
(7, 10.0, 0.25): 0.933333333333
(7, 10.0, 0.275): 1.0
(7, 10.0, 0.3): 1.0
(7, 100.0, 0.225): 0.866666666667
(7, 100.0, 0.25): 0.933333333333
(7, 100.0, 0.275): 1.0
(7, 100.0, 0.3): 1.0
(8, 1.0, 0.2): 0.933333333333
(8, 1.0, 0.225): 0.866666666667
(8, 1.0, 0.3): 0.8
(8, 10.0, 0.2): 0.866666666667
(8, 10.0, 0.25): 0.866666666667
(8, 10.0, 0.3): 0.8
(8, 100.0, 0.2): 0.866666666667
(8, 100.0, 0.225): 0.866666666667
(8, 100.0, 0.3): 0.8
(9, 0.1, 0.3): 0.866666666667
(9, 1.0, 0.225): 0.866666666667
(9, 1.0, 0.25): 0.6
(9, 1.0, 0.275): 0.6
(9, 1.0, 0.3): 0.866666666667
(9, 10.0, 0.2): 0.933333333333
(9, 10.0, 0.225): 0.933333333333
(9, 10.0, 0.25): 0.6
(9, 10.0, 0.275): 0.6
(9, 10.0, 0.3): 0.866666666667
(9, 100.0, 0.225): 0.933333333333
(9, 100.0, 0.25): 0.6
(9, 100.0, 0.275): 0.6
(9, 100.0, 0.3): 0.866666666667

Loss on all the set for every iteration, for every couple c,sigma (n_of_the_iter, best_c, best_sigma):
(0, 1.0, 0.2): 0.2
(0, 1.0, 0.225): 0.2
(0, 1.0, 0.25): 0.266666666667
(0, 1.0, 0.3): 0.266666666667
(0, 10.0, 0.2): 0.266666666667
(0, 10.0, 0.225): 0.2
(0, 10.0, 0.25): 0.0666666666667
(0, 10.0, 0.3): 0.266666666667
(0, 100.0, 0.2): 0.266666666667
(0, 100.0, 0.225): 0.2
(0, 100.0, 0.25): 0.266666666667
(0, 100.0, 0.3): 0.266666666667
(1, 1.0, 0.2): 0.133333333333
(1, 1.0, 0.225): 0.133333333333
(1, 1.0, 0.25): 0.2
(1, 1.0, 0.275): 0.266666666667
(1, 10.0, 0.2): 0.133333333333
(1, 10.0, 0.225): 0.133333333333
(1, 10.0, 0.25): 0.2
(1, 10.0, 0.275): 0.266666666667
(1, 100.0, 0.225): 0.133333333333
(1, 100.0, 0.25): 0.2
(1, 100.0, 0.275): 0.266666666667
(2, 1.0, 0.2): 0.0
(2, 1.0, 0.225): 0.0666666666667
(2, 1.0, 0.25): 0.133333333333
(2, 1.0, 0.275): 0.133333333333
(2, 1.0, 0.3): 0.133333333333
(2, 10.0, 0.2): 0.0
(2, 10.0, 0.225): 0.0666666666667
(2, 10.0, 0.25): 0.133333333333
(2, 10.0, 0.275): 0.133333333333
(2, 100.0, 0.2): 0.0666666666667
(2, 100.0, 0.225): 0.0666666666667
(2, 100.0, 0.25): 0.133333333333
(2, 100.0, 0.275): 0.133333333333
(2, 100.0, 0.3): 0.133333333333
(3, 1.0, 0.2): 0.0666666666667
(3, 1.0, 0.225): 0.0666666666667
(3, 1.0, 0.25): 0.133333333333
(3, 1.0, 0.275): 0.266666666667
(3, 1.0, 0.3): 0.266666666667
(3, 10.0, 0.2): 0.0666666666667
(3, 10.0, 0.225): 0.0666666666667
(3, 10.0, 0.25): 0.133333333333
(3, 10.0, 0.275): 0.266666666667
(3, 10.0, 0.3): 0.266666666667
(3, 100.0, 0.2): 0.0666666666667
(3, 100.0, 0.225): 0.0666666666667
(3, 100.0, 0.25): 0.133333333333
(3, 100.0, 0.275): 0.266666666667
(3, 100.0, 0.3): 0.266666666667
(4, 1.0, 0.2): 0.133333333333
(4, 1.0, 0.225): 0.133333333333
(4, 1.0, 0.275): 0.0666666666667
(4, 10.0, 0.2): 0.133333333333
(4, 10.0, 0.225): 0.133333333333
(4, 10.0, 0.275): 0.0666666666667
(4, 100.0, 0.2): 0.133333333333
(4, 100.0, 0.225): 0.133333333333
(4, 100.0, 0.275): 0.0666666666667
(5, 1.0, 0.2): 0.2
(5, 1.0, 0.225): 0.266666666667
(5, 1.0, 0.25): 0.333333333333
(5, 1.0, 0.275): 0.333333333333
(5, 1.0, 0.3): 0.333333333333
(5, 10.0, 0.2): 0.266666666667
(5, 10.0, 0.225): 0.266666666667
(5, 10.0, 0.25): 0.333333333333
(5, 10.0, 0.3): 0.333333333333
(5, 100.0, 0.2): 0.333333333333
(5, 100.0, 0.225): 0.266666666667
(5, 100.0, 0.275): 0.333333333333
(5, 100.0, 0.3): 0.333333333333
(6, 1.0, 0.2): 0.2
(6, 1.0, 0.225): 0.0
(6, 1.0, 0.25): 0.0
(6, 1.0, 0.275): 0.0666666666667
(6, 1.0, 0.3): 0.2
(6, 10.0, 0.2): 0.2
(6, 10.0, 0.225): 0.0
(6, 10.0, 0.25): 0.0
(6, 10.0, 0.275): 0.0666666666667
(6, 10.0, 0.3): 0.2
(6, 100.0, 0.2): 0.2
(6, 100.0, 0.225): 0.0
(6, 100.0, 0.25): 0.0
(6, 100.0, 0.275): 0.0666666666667
(6, 100.0, 0.3): 0.2
(7, 1.0, 0.225): 0.0666666666667
(7, 1.0, 0.25): 0.0666666666667
(7, 1.0, 0.275): 0.0
(7, 1.0, 0.3): 0.0
(7, 10.0, 0.225): 0.0666666666667
(7, 10.0, 0.25): 0.0666666666667
(7, 10.0, 0.275): 0.0
(7, 10.0, 0.3): 0.0
(7, 100.0, 0.225): 0.133333333333
(7, 100.0, 0.25): 0.0666666666667
(7, 100.0, 0.275): 0.0
(7, 100.0, 0.3): 0.0
(8, 1.0, 0.2): 0.0666666666667
(8, 1.0, 0.225): 0.133333333333
(8, 1.0, 0.3): 0.2
(8, 10.0, 0.2): 0.133333333333
(8, 10.0, 0.25): 0.133333333333
(8, 10.0, 0.3): 0.2
(8, 100.0, 0.2): 0.133333333333
(8, 100.0, 0.225): 0.133333333333
(8, 100.0, 0.3): 0.2
(9, 0.1, 0.3): 0.133333333333
(9, 1.0, 0.225): 0.133333333333
(9, 1.0, 0.25): 0.4
(9, 1.0, 0.275): 0.4
(9, 1.0, 0.3): 0.133333333333
(9, 10.0, 0.2): 0.0666666666667
(9, 10.0, 0.225): 0.0666666666667
(9, 10.0, 0.25): 0.4
(9, 10.0, 0.275): 0.4
(9, 10.0, 0.3): 0.133333333333
(9, 100.0, 0.225): 0.0666666666667
(9, 100.0, 0.25): 0.4
(9, 100.0, 0.275): 0.4
(9, 100.0, 0.3): 0.133333333333

Accuracy mean :0.839247311827957
Std deviation :0.10809928291109064
Loss mean :0.160752688172043
Std deviation :0.10809928291109062



Force_False_3dim, number of iterations: 10

Parameters info
Tradeoffs parameter: [1.e-02 1.e-01 1.e+00 1.e+01 1.e+02]
Gaussian kernel sigmas: [0.2   0.225 0.25  0.275 0.3  ]
Number of principal dimension considerated: 3
Dataset length: 150

Clusterization info
Minimum size of a cluster: in perc: 0.01, in int: 2
Type of mu: Binary Muzzifier
Fuzzifier: Linear
Cluster to label info
Force the number of cluster to be the number of different labels: False
Force the labels to be always represent by a cluster: False

Validation info
Conflict resolution: random


RESULTS

On TEST set

Accuracy on test set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 10.0, 0.25): 0.933333333333
(1, 100.0, 0.225): 0.866666666667
(2, 1.0, 0.225): 1.0
(3, 10.0, 0.225): 0.866666666667
(4, 10.0, 0.225): 0.733333333333
(5, 10.0, 0.2): 1.0
(6, 10.0, 0.275): 0.533333333333
(7, 100.0, 0.225): 0.866666666667
(8, 1.0, 0.225): 0.866666666667
(9, 10.0, 0.225): 0.8

Loss on test set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 10.0, 0.25): 0.0666666666667
(1, 100.0, 0.225): 0.133333333333
(2, 1.0, 0.225): 0.0
(3, 10.0, 0.225): 0.133333333333
(4, 10.0, 0.225): 0.266666666667
(5, 10.0, 0.2): 0.0
(6, 10.0, 0.275): 0.466666666667
(7, 100.0, 0.225): 0.133333333333
(8, 1.0, 0.225): 0.133333333333
(9, 10.0, 0.225): 0.2

Accuracy mean :0.8466666666666669
Std deviation :0.13012814197295425
Loss mean :0.15333333333333332
Std deviation :0.13012814197295425

On TRAINING set

Accuracy on training set for every iteration (n_of_the_iter, c, sigma):
(0, 10.0, 0.25): 0.851851851852
(1, 100.0, 0.225): 0.866666666667
(2, 1.0, 0.225): 0.918518518519
(3, 10.0, 0.225): 0.940740740741
(4, 10.0, 0.225): 0.866666666667
(5, 10.0, 0.2): 0.903703703704
(6, 10.0, 0.275): 0.681481481481
(7, 100.0, 0.225): 0.859259259259
(8, 1.0, 0.225): 0.851851851852
(9, 10.0, 0.225): 0.925925925926
Loss on training set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 10.0, 0.25): 0.148148148148
(1, 100.0, 0.225): 0.133333333333
(2, 1.0, 0.225): 0.0814814814815
(3, 10.0, 0.225): 0.0592592592593
(4, 10.0, 0.225): 0.133333333333
(5, 10.0, 0.2): 0.0962962962963
(6, 10.0, 0.275): 0.318518518519
(7, 100.0, 0.225): 0.140740740741
(8, 1.0, 0.225): 0.148148148148
(9, 10.0, 0.225): 0.0740740740741

Accuracy mean :0.8666666666666666
Std deviation :0.06917106684402223
Loss mean :0.13333333333333336
Std deviation :0.06917106684402223

On ALL the sets

Accuracy on all the set for every iteration, for every couple c,sigma (n_of_the_iter, c, sigma):
(0, 1.0, 0.2): 0.733333333333
(0, 1.0, 0.225): 0.866666666667
(0, 1.0, 0.25): 0.733333333333
(0, 1.0, 0.275): 0.6
(0, 1.0, 0.3): 0.733333333333
(0, 10.0, 0.2): 0.733333333333
(0, 10.0, 0.225): 0.866666666667
(0, 10.0, 0.25): 0.933333333333
(0, 10.0, 0.275): 0.6
(0, 10.0, 0.3): 0.733333333333
(0, 100.0, 0.2): 0.666666666667
(0, 100.0, 0.225): 0.866666666667
(0, 100.0, 0.25): 0.733333333333
(0, 100.0, 0.275): 0.6
(0, 100.0, 0.3): 0.733333333333
(1, 0.1, 0.3): 0.4
(1, 1.0, 0.2): 0.866666666667
(1, 1.0, 0.225): 0.933333333333
(1, 1.0, 0.25): 0.866666666667
(1, 1.0, 0.275): 0.733333333333
(1, 1.0, 0.3): 0.4
(1, 10.0, 0.2): 0.866666666667
(1, 10.0, 0.225): 0.933333333333
(1, 10.0, 0.25): 0.866666666667
(1, 10.0, 0.275): 0.733333333333
(1, 10.0, 0.3): 0.4
(1, 100.0, 0.225): 0.933333333333
(1, 100.0, 0.25): 0.866666666667
(1, 100.0, 0.275): 0.733333333333
(1, 100.0, 0.3): 0.4
(2, 0.1, 0.225): 0.933333333333
(2, 0.1, 0.25): 0.933333333333
(2, 1.0, 0.2): 0.866666666667
(2, 1.0, 0.225): 0.933333333333
(2, 1.0, 0.25): 0.933333333333
(2, 1.0, 0.275): 0.6
(2, 1.0, 0.3): 0.666666666667
(2, 10.0, 0.2): 0.8
(2, 10.0, 0.225): 0.933333333333
(2, 10.0, 0.25): 0.933333333333
(2, 10.0, 0.275): 0.6
(2, 10.0, 0.3): 0.666666666667
(2, 100.0, 0.2): 0.8
(2, 100.0, 0.225): 0.933333333333
(2, 100.0, 0.25): 0.933333333333
(2, 100.0, 0.275): 0.6
(2, 100.0, 0.3): 0.666666666667
(3, 1.0, 0.2): 0.8
(3, 1.0, 0.225): 0.933333333333
(3, 1.0, 0.25): 0.866666666667
(3, 1.0, 0.275): 0.533333333333
(3, 1.0, 0.3): 0.866666666667
(3, 10.0, 0.2): 0.8
(3, 10.0, 0.225): 0.933333333333
(3, 10.0, 0.25): 0.866666666667
(3, 10.0, 0.275): 0.533333333333
(3, 10.0, 0.3): 0.866666666667
(3, 100.0, 0.2): 0.8
(3, 100.0, 0.25): 0.866666666667
(3, 100.0, 0.275): 0.533333333333
(3, 100.0, 0.3): 0.866666666667
(4, 1.0, 0.2): 0.2
(4, 1.0, 0.225): 0.933333333333
(4, 1.0, 0.25): 0.533333333333
(4, 1.0, 0.275): 0.533333333333
(4, 1.0, 0.3): 0.533333333333
(4, 10.0, 0.2): 0.666666666667
(4, 10.0, 0.225): 0.933333333333
(4, 10.0, 0.25): 0.533333333333
(4, 10.0, 0.275): 0.533333333333
(4, 10.0, 0.3): 0.533333333333
(4, 100.0, 0.2): 0.666666666667
(4, 100.0, 0.225): 0.933333333333
(4, 100.0, 0.25): 0.533333333333
(4, 100.0, 0.275): 0.533333333333
(4, 100.0, 0.3): 0.533333333333
(5, 0.1, 0.225): 0.533333333333
(5, 0.1, 0.25): 0.533333333333
(5, 0.1, 0.275): 0.533333333333
(5, 1.0, 0.2): 0.8
(5, 1.0, 0.225): 0.533333333333
(5, 1.0, 0.25): 0.533333333333
(5, 1.0, 0.275): 0.533333333333
(5, 1.0, 0.3): 0.6
(5, 10.0, 0.2): 0.8
(5, 10.0, 0.225): 0.533333333333
(5, 10.0, 0.25): 0.533333333333
(5, 10.0, 0.275): 0.533333333333
(5, 10.0, 0.3): 0.6
(5, 100.0, 0.2): 0.8
(5, 100.0, 0.225): 0.533333333333
(5, 100.0, 0.25): 0.533333333333
(5, 100.0, 0.275): 0.533333333333
(5, 100.0, 0.3): 0.666666666667
(6, 1.0, 0.2): 0.8
(6, 1.0, 0.225): 0.866666666667
(6, 1.0, 0.25): 0.6
(6, 1.0, 0.275): 0.933333333333
(6, 1.0, 0.3): 0.933333333333
(6, 10.0, 0.2): 0.8
(6, 10.0, 0.225): 0.866666666667
(6, 10.0, 0.25): 0.6
(6, 10.0, 0.275): 0.933333333333
(6, 10.0, 0.3): 0.933333333333
(6, 100.0, 0.2): 0.8
(6, 100.0, 0.225): 0.866666666667
(6, 100.0, 0.25): 0.933333333333
(6, 100.0, 0.275): 0.933333333333
(6, 100.0, 0.3): 0.866666666667
(7, 0.1, 0.275): 0.733333333333
(7, 1.0, 0.2): 0.8
(7, 1.0, 0.225): 0.933333333333
(7, 1.0, 0.25): 0.866666666667
(7, 1.0, 0.275): 0.733333333333
(7, 1.0, 0.3): 0.733333333333
(7, 10.0, 0.2): 0.8
(7, 10.0, 0.225): 0.933333333333
(7, 10.0, 0.25): 0.866666666667
(7, 10.0, 0.275): 0.733333333333
(7, 10.0, 0.3): 0.733333333333
(7, 100.0, 0.2): 0.8
(7, 100.0, 0.225): 0.933333333333
(7, 100.0, 0.25): 0.866666666667
(7, 100.0, 0.275): 0.733333333333
(7, 100.0, 0.3): 0.733333333333
(8, 1.0, 0.2): 0.333333333333
(8, 1.0, 0.225): 0.933333333333
(8, 1.0, 0.25): 0.866666666667
(8, 1.0, 0.275): 0.2
(8, 1.0, 0.3): 0.866666666667
(8, 10.0, 0.225): 0.666666666667
(8, 10.0, 0.275): 0.666666666667
(8, 10.0, 0.3): 0.866666666667
(8, 100.0, 0.2): 0.333333333333
(8, 100.0, 0.225): 0.466666666667
(8, 100.0, 0.275): 0.866666666667
(8, 100.0, 0.3): 0.866666666667
(9, 1.0, 0.225): 1.0
(9, 1.0, 0.25): 0.866666666667
(9, 1.0, 0.275): 0.2
(9, 1.0, 0.3): 0.2
(9, 10.0, 0.2): 0.933333333333
(9, 10.0, 0.225): 1.0
(9, 10.0, 0.25): 0.866666666667
(9, 10.0, 0.275): 0.4
(9, 10.0, 0.3): 0.6
(9, 100.0, 0.225): 1.0
(9, 100.0, 0.25): 0.866666666667
(9, 100.0, 0.275): 0.4
(9, 100.0, 0.3): 0.666666666667

Loss on all the set for every iteration, for every couple c,sigma (n_of_the_iter, best_c, best_sigma):
(0, 1.0, 0.2): 0.266666666667
(0, 1.0, 0.225): 0.133333333333
(0, 1.0, 0.25): 0.266666666667
(0, 1.0, 0.275): 0.4
(0, 1.0, 0.3): 0.266666666667
(0, 10.0, 0.2): 0.266666666667
(0, 10.0, 0.225): 0.133333333333
(0, 10.0, 0.25): 0.0666666666667
(0, 10.0, 0.275): 0.4
(0, 10.0, 0.3): 0.266666666667
(0, 100.0, 0.2): 0.333333333333
(0, 100.0, 0.225): 0.133333333333
(0, 100.0, 0.25): 0.266666666667
(0, 100.0, 0.275): 0.4
(0, 100.0, 0.3): 0.266666666667
(1, 0.1, 0.3): 0.6
(1, 1.0, 0.2): 0.133333333333
(1, 1.0, 0.225): 0.0666666666667
(1, 1.0, 0.25): 0.133333333333
(1, 1.0, 0.275): 0.266666666667
(1, 1.0, 0.3): 0.6
(1, 10.0, 0.2): 0.133333333333
(1, 10.0, 0.225): 0.0666666666667
(1, 10.0, 0.25): 0.133333333333
(1, 10.0, 0.275): 0.266666666667
(1, 10.0, 0.3): 0.6
(1, 100.0, 0.225): 0.0666666666667
(1, 100.0, 0.25): 0.133333333333
(1, 100.0, 0.275): 0.266666666667
(1, 100.0, 0.3): 0.6
(2, 0.1, 0.225): 0.0666666666667
(2, 0.1, 0.25): 0.0666666666667
(2, 1.0, 0.2): 0.133333333333
(2, 1.0, 0.225): 0.0666666666667
(2, 1.0, 0.25): 0.0666666666667
(2, 1.0, 0.275): 0.4
(2, 1.0, 0.3): 0.333333333333
(2, 10.0, 0.2): 0.2
(2, 10.0, 0.225): 0.0666666666667
(2, 10.0, 0.25): 0.0666666666667
(2, 10.0, 0.275): 0.4
(2, 10.0, 0.3): 0.333333333333
(2, 100.0, 0.2): 0.2
(2, 100.0, 0.225): 0.0666666666667
(2, 100.0, 0.25): 0.0666666666667
(2, 100.0, 0.275): 0.4
(2, 100.0, 0.3): 0.333333333333
(3, 1.0, 0.2): 0.2
(3, 1.0, 0.225): 0.0666666666667
(3, 1.0, 0.25): 0.133333333333
(3, 1.0, 0.275): 0.466666666667
(3, 1.0, 0.3): 0.133333333333
(3, 10.0, 0.2): 0.2
(3, 10.0, 0.225): 0.0666666666667
(3, 10.0, 0.25): 0.133333333333
(3, 10.0, 0.275): 0.466666666667
(3, 10.0, 0.3): 0.133333333333
(3, 100.0, 0.2): 0.2
(3, 100.0, 0.25): 0.133333333333
(3, 100.0, 0.275): 0.466666666667
(3, 100.0, 0.3): 0.133333333333
(4, 1.0, 0.2): 0.8
(4, 1.0, 0.225): 0.0666666666667
(4, 1.0, 0.25): 0.466666666667
(4, 1.0, 0.275): 0.466666666667
(4, 1.0, 0.3): 0.466666666667
(4, 10.0, 0.2): 0.333333333333
(4, 10.0, 0.225): 0.0666666666667
(4, 10.0, 0.25): 0.466666666667
(4, 10.0, 0.275): 0.466666666667
(4, 10.0, 0.3): 0.466666666667
(4, 100.0, 0.2): 0.333333333333
(4, 100.0, 0.225): 0.0666666666667
(4, 100.0, 0.25): 0.466666666667
(4, 100.0, 0.275): 0.466666666667
(4, 100.0, 0.3): 0.466666666667
(5, 0.1, 0.225): 0.466666666667
(5, 0.1, 0.25): 0.466666666667
(5, 0.1, 0.275): 0.466666666667
(5, 1.0, 0.2): 0.2
(5, 1.0, 0.225): 0.466666666667
(5, 1.0, 0.25): 0.466666666667
(5, 1.0, 0.275): 0.466666666667
(5, 1.0, 0.3): 0.4
(5, 10.0, 0.2): 0.2
(5, 10.0, 0.225): 0.466666666667
(5, 10.0, 0.25): 0.466666666667
(5, 10.0, 0.275): 0.466666666667
(5, 10.0, 0.3): 0.4
(5, 100.0, 0.2): 0.2
(5, 100.0, 0.225): 0.466666666667
(5, 100.0, 0.25): 0.466666666667
(5, 100.0, 0.275): 0.466666666667
(5, 100.0, 0.3): 0.333333333333
(6, 1.0, 0.2): 0.2
(6, 1.0, 0.225): 0.133333333333
(6, 1.0, 0.25): 0.4
(6, 1.0, 0.275): 0.0666666666667
(6, 1.0, 0.3): 0.0666666666667
(6, 10.0, 0.2): 0.2
(6, 10.0, 0.225): 0.133333333333
(6, 10.0, 0.25): 0.4
(6, 10.0, 0.275): 0.0666666666667
(6, 10.0, 0.3): 0.0666666666667
(6, 100.0, 0.2): 0.2
(6, 100.0, 0.225): 0.133333333333
(6, 100.0, 0.25): 0.0666666666667
(6, 100.0, 0.275): 0.0666666666667
(6, 100.0, 0.3): 0.133333333333
(7, 0.1, 0.275): 0.266666666667
(7, 1.0, 0.2): 0.2
(7, 1.0, 0.225): 0.0666666666667
(7, 1.0, 0.25): 0.133333333333
(7, 1.0, 0.275): 0.266666666667
(7, 1.0, 0.3): 0.266666666667
(7, 10.0, 0.2): 0.2
(7, 10.0, 0.225): 0.0666666666667
(7, 10.0, 0.25): 0.133333333333
(7, 10.0, 0.275): 0.266666666667
(7, 10.0, 0.3): 0.266666666667
(7, 100.0, 0.2): 0.2
(7, 100.0, 0.225): 0.0666666666667
(7, 100.0, 0.25): 0.133333333333
(7, 100.0, 0.275): 0.266666666667
(7, 100.0, 0.3): 0.266666666667
(8, 1.0, 0.2): 0.666666666667
(8, 1.0, 0.225): 0.0666666666667
(8, 1.0, 0.25): 0.133333333333
(8, 1.0, 0.275): 0.8
(8, 1.0, 0.3): 0.133333333333
(8, 10.0, 0.225): 0.333333333333
(8, 10.0, 0.275): 0.333333333333
(8, 10.0, 0.3): 0.133333333333
(8, 100.0, 0.2): 0.666666666667
(8, 100.0, 0.225): 0.533333333333
(8, 100.0, 0.275): 0.133333333333
(8, 100.0, 0.3): 0.133333333333
(9, 1.0, 0.225): 0.0
(9, 1.0, 0.25): 0.133333333333
(9, 1.0, 0.275): 0.8
(9, 1.0, 0.3): 0.8
(9, 10.0, 0.2): 0.0666666666667
(9, 10.0, 0.225): 0.0
(9, 10.0, 0.25): 0.133333333333
(9, 10.0, 0.275): 0.6
(9, 10.0, 0.3): 0.4
(9, 100.0, 0.225): 0.0
(9, 100.0, 0.25): 0.133333333333
(9, 100.0, 0.275): 0.6
(9, 100.0, 0.3): 0.333333333333

Accuracy mean :0.7279999999999999
Std deviation :0.1883291051639439
Loss mean :0.27199999999999996
Std deviation :0.1883291051639439



Force_True_4dim, number of iterations: 10

Parameters info
Tradeoffs parameter: [1.e-02 1.e-01 1.e+00 1.e+01 1.e+02]
Gaussian kernel sigmas: [0.2   0.225 0.25  0.275 0.3  ]
Number of principal dimension considerated: 4
Dataset length: 150

Clusterization info
Minimum size of a cluster: in perc: 0.01, in int: 2
Type of mu: Binary Muzzifier
Fuzzifier: Linear
Cluster to label info
Force the number of cluster to be the number of different labels: True
Force the labels to be always represent by a cluster: True

Validation info
Conflict resolution: random


RESULTS

On TEST set

Accuracy on test set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 100.0, 0.225): 0.8
(1, 100.0, 0.2): 0.6
(2, 1.0, 0.225): 0.8
(3, 1.0, 0.275): 0.933333333333
(4, 100.0, 0.275): 0.8
(5, 1.0, 0.25): 0.933333333333
(6, 100.0, 0.225): 0.733333333333
(7, 1.0, 0.225): 0.666666666667
(8, 10.0, 0.225): 0.866666666667
(9, 10.0, 0.225): 1.0

Loss on test set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 100.0, 0.225): 0.2
(1, 100.0, 0.2): 0.4
(2, 1.0, 0.225): 0.2
(3, 1.0, 0.275): 0.0666666666667
(4, 100.0, 0.275): 0.2
(5, 1.0, 0.25): 0.0666666666667
(6, 100.0, 0.225): 0.266666666667
(7, 1.0, 0.225): 0.333333333333
(8, 10.0, 0.225): 0.133333333333
(9, 10.0, 0.225): 0.0

Accuracy mean :0.8133333333333332
Std deviation :0.1185092588975412
Loss mean :0.18666666666666665
Std deviation :0.11850925889754119

On TRAINING set

Accuracy on training set for every iteration (n_of_the_iter, c, sigma):
(0, 100.0, 0.225): 0.82962962963
(1, 100.0, 0.2): 0.718518518519
(2, 1.0, 0.225): 0.785185185185
(3, 1.0, 0.275): 0.874074074074
(4, 100.0, 0.275): 0.807407407407
(5, 1.0, 0.25): 0.940740740741
(6, 100.0, 0.225): 0.755555555556
(7, 1.0, 0.225): 0.8
(8, 10.0, 0.225): 0.859259259259
(9, 10.0, 0.225): 0.851851851852
Loss on training set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 100.0, 0.225): 0.17037037037
(1, 100.0, 0.2): 0.281481481481
(2, 1.0, 0.225): 0.214814814815
(3, 1.0, 0.275): 0.125925925926
(4, 100.0, 0.275): 0.192592592593
(5, 1.0, 0.25): 0.0592592592593
(6, 100.0, 0.225): 0.244444444444
(7, 1.0, 0.225): 0.2
(8, 10.0, 0.225): 0.140740740741
(9, 10.0, 0.225): 0.148148148148

Accuracy mean :0.8222222222222223
Std deviation :0.06026917216831998
Loss mean :0.17777777777777776
Std deviation :0.06026917216831998

On ALL the sets

Accuracy on all the set for every iteration, for every couple c,sigma (n_of_the_iter, c, sigma):
(0, 1.0, 0.2): 0.6
(0, 1.0, 0.225): 0.666666666667
(0, 1.0, 0.25): 0.733333333333
(0, 1.0, 0.275): 0.666666666667
(0, 10.0, 0.2): 0.6
(0, 10.0, 0.225): 0.666666666667
(0, 10.0, 0.25): 0.733333333333
(0, 10.0, 0.275): 0.666666666667
(0, 100.0, 0.225): 0.666666666667
(0, 100.0, 0.25): 0.733333333333
(0, 100.0, 0.275): 0.933333333333
(1, 1.0, 0.2): 0.933333333333
(1, 1.0, 0.225): 0.733333333333
(1, 1.0, 0.25): 0.866666666667
(1, 1.0, 0.275): 0.866666666667
(1, 10.0, 0.225): 0.733333333333
(1, 10.0, 0.25): 0.866666666667
(1, 10.0, 0.275): 0.866666666667
(1, 100.0, 0.2): 0.933333333333
(1, 100.0, 0.225): 0.733333333333
(1, 100.0, 0.25): 0.866666666667
(1, 100.0, 0.275): 0.866666666667
(2, 1.0, 0.2): 0.533333333333
(2, 1.0, 0.225): 0.933333333333
(2, 1.0, 0.25): 0.866666666667
(2, 1.0, 0.3): 0.866666666667
(2, 10.0, 0.2): 0.533333333333
(2, 10.0, 0.225): 0.933333333333
(2, 10.0, 0.25): 0.866666666667
(2, 10.0, 0.3): 0.866666666667
(2, 100.0, 0.2): 0.533333333333
(2, 100.0, 0.225): 0.933333333333
(2, 100.0, 0.25): 0.866666666667
(2, 100.0, 0.3): 0.866666666667
(3, 1.0, 0.275): 0.933333333333
(3, 10.0, 0.275): 0.933333333333
(4, 0.1, 0.275): 0.866666666667
(4, 1.0, 0.2): 0.466666666667
(4, 1.0, 0.25): 0.733333333333
(4, 1.0, 0.275): 0.733333333333
(4, 10.0, 0.25): 0.733333333333
(4, 10.0, 0.275): 0.733333333333
(4, 100.0, 0.2): 0.4
(4, 100.0, 0.25): 0.733333333333
(4, 100.0, 0.275): 0.933333333333
(5, 0.1, 0.275): 0.733333333333
(5, 0.1, 0.3): 1.0
(5, 1.0, 0.25): 1.0
(5, 1.0, 0.275): 0.733333333333
(5, 1.0, 0.3): 1.0
(5, 10.0, 0.25): 0.933333333333
(5, 10.0, 0.275): 0.733333333333
(5, 10.0, 0.3): 1.0
(5, 100.0, 0.25): 0.933333333333
(5, 100.0, 0.275): 0.733333333333
(5, 100.0, 0.3): 1.0
(6, 1.0, 0.225): 0.733333333333
(6, 1.0, 0.25): 0.666666666667
(6, 10.0, 0.225): 0.733333333333
(6, 10.0, 0.25): 0.666666666667
(6, 100.0, 0.225): 0.733333333333
(6, 100.0, 0.25): 0.666666666667
(7, 1.0, 0.225): 0.933333333333
(7, 1.0, 0.25): 0.866666666667
(7, 10.0, 0.225): 0.866666666667
(7, 10.0, 0.25): 0.933333333333
(7, 100.0, 0.225): 0.866666666667
(7, 100.0, 0.25): 0.866666666667
(8, 1.0, 0.225): 0.8
(8, 1.0, 0.275): 0.8
(8, 10.0, 0.225): 0.8
(8, 10.0, 0.275): 0.8
(8, 100.0, 0.225): 0.733333333333
(8, 100.0, 0.275): 0.8
(9, 1.0, 0.225): 0.933333333333
(9, 10.0, 0.225): 0.933333333333

Loss on all the set for every iteration, for every couple c,sigma (n_of_the_iter, best_c, best_sigma):
(0, 1.0, 0.2): 0.4
(0, 1.0, 0.225): 0.333333333333
(0, 1.0, 0.25): 0.266666666667
(0, 1.0, 0.275): 0.333333333333
(0, 10.0, 0.2): 0.4
(0, 10.0, 0.225): 0.333333333333
(0, 10.0, 0.25): 0.266666666667
(0, 10.0, 0.275): 0.333333333333
(0, 100.0, 0.225): 0.333333333333
(0, 100.0, 0.25): 0.266666666667
(0, 100.0, 0.275): 0.0666666666667
(1, 1.0, 0.2): 0.0666666666667
(1, 1.0, 0.225): 0.266666666667
(1, 1.0, 0.25): 0.133333333333
(1, 1.0, 0.275): 0.133333333333
(1, 10.0, 0.225): 0.266666666667
(1, 10.0, 0.25): 0.133333333333
(1, 10.0, 0.275): 0.133333333333
(1, 100.0, 0.2): 0.0666666666667
(1, 100.0, 0.225): 0.266666666667
(1, 100.0, 0.25): 0.133333333333
(1, 100.0, 0.275): 0.133333333333
(2, 1.0, 0.2): 0.466666666667
(2, 1.0, 0.225): 0.0666666666667
(2, 1.0, 0.25): 0.133333333333
(2, 1.0, 0.3): 0.133333333333
(2, 10.0, 0.2): 0.466666666667
(2, 10.0, 0.225): 0.0666666666667
(2, 10.0, 0.25): 0.133333333333
(2, 10.0, 0.3): 0.133333333333
(2, 100.0, 0.2): 0.466666666667
(2, 100.0, 0.225): 0.0666666666667
(2, 100.0, 0.25): 0.133333333333
(2, 100.0, 0.3): 0.133333333333
(3, 1.0, 0.275): 0.0666666666667
(3, 10.0, 0.275): 0.0666666666667
(4, 0.1, 0.275): 0.133333333333
(4, 1.0, 0.2): 0.533333333333
(4, 1.0, 0.25): 0.266666666667
(4, 1.0, 0.275): 0.266666666667
(4, 10.0, 0.25): 0.266666666667
(4, 10.0, 0.275): 0.266666666667
(4, 100.0, 0.2): 0.6
(4, 100.0, 0.25): 0.266666666667
(4, 100.0, 0.275): 0.0666666666667
(5, 0.1, 0.275): 0.266666666667
(5, 0.1, 0.3): 0.0
(5, 1.0, 0.25): 0.0
(5, 1.0, 0.275): 0.266666666667
(5, 1.0, 0.3): 0.0
(5, 10.0, 0.25): 0.0666666666667
(5, 10.0, 0.275): 0.266666666667
(5, 10.0, 0.3): 0.0
(5, 100.0, 0.25): 0.0666666666667
(5, 100.0, 0.275): 0.266666666667
(5, 100.0, 0.3): 0.0
(6, 1.0, 0.225): 0.266666666667
(6, 1.0, 0.25): 0.333333333333
(6, 10.0, 0.225): 0.266666666667
(6, 10.0, 0.25): 0.333333333333
(6, 100.0, 0.225): 0.266666666667
(6, 100.0, 0.25): 0.333333333333
(7, 1.0, 0.225): 0.0666666666667
(7, 1.0, 0.25): 0.133333333333
(7, 10.0, 0.225): 0.133333333333
(7, 10.0, 0.25): 0.0666666666667
(7, 100.0, 0.225): 0.133333333333
(7, 100.0, 0.25): 0.133333333333
(8, 1.0, 0.225): 0.2
(8, 1.0, 0.275): 0.2
(8, 10.0, 0.225): 0.2
(8, 10.0, 0.275): 0.2
(8, 100.0, 0.225): 0.266666666667
(8, 100.0, 0.275): 0.2
(9, 1.0, 0.225): 0.0666666666667
(9, 10.0, 0.225): 0.0666666666667

Accuracy mean :0.7982456140350876
Std deviation :0.13244161649198083
Loss mean :0.2017543859649123
Std deviation :0.13244161649198083



Force_False_4dim, number of iterations: 10

Parameters info
Tradeoffs parameter: [1.e-02 1.e-01 1.e+00 1.e+01 1.e+02]
Gaussian kernel sigmas: [0.2   0.225 0.25  0.275 0.3  ]
Number of principal dimension considerated: 4
Dataset length: 150

Clusterization info
Minimum size of a cluster: in perc: 0.01, in int: 2
Type of mu: Binary Muzzifier
Fuzzifier: Linear
Cluster to label info
Force the number of cluster to be the number of different labels: False
Force the labels to be always represent by a cluster: False

Validation info
Conflict resolution: random


RESULTS

On TEST set

Accuracy on test set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 10.0, 0.25): 0.866666666667
(1, 100.0, 0.275): 0.466666666667
(2, 100.0, 0.25): 0.933333333333
(3, 1.0, 0.225): 0.866666666667
(4, 100.0, 0.25): 0.733333333333
(5, 1.0, 0.25): 0.266666666667
(6, 10.0, 0.3): 0.6
(7, 10.0, 0.225): 0.6
(8, 100.0, 0.25): 0.333333333333
(9, 10.0, 0.225): 0.666666666667

Loss on test set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 10.0, 0.25): 0.133333333333
(1, 100.0, 0.275): 0.533333333333
(2, 100.0, 0.25): 0.0666666666667
(3, 1.0, 0.225): 0.133333333333
(4, 100.0, 0.25): 0.266666666667
(5, 1.0, 0.25): 0.733333333333
(6, 10.0, 0.3): 0.4
(7, 10.0, 0.225): 0.4
(8, 100.0, 0.25): 0.666666666667
(9, 10.0, 0.225): 0.333333333333

Accuracy mean :0.6333333333333333
Std deviation :0.21550973166992818
Loss mean :0.36666666666666664
Std deviation :0.21550973166992818

On TRAINING set

Accuracy on training set for every iteration (n_of_the_iter, c, sigma):
(0, 10.0, 0.25): 0.681481481481
(1, 100.0, 0.275): 0.688888888889
(2, 100.0, 0.25): 0.918518518519
(3, 1.0, 0.225): 0.77037037037
(4, 100.0, 0.25): 0.659259259259
(5, 1.0, 0.25): 0.340740740741
(6, 10.0, 0.3): 0.674074074074
(7, 10.0, 0.225): 0.77037037037
(8, 100.0, 0.25): 0.703703703704
(9, 10.0, 0.225): 0.814814814815
Loss on training set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 10.0, 0.25): 0.318518518519
(1, 100.0, 0.275): 0.311111111111
(2, 100.0, 0.25): 0.0814814814815
(3, 1.0, 0.225): 0.22962962963
(4, 100.0, 0.25): 0.340740740741
(5, 1.0, 0.25): 0.659259259259
(6, 10.0, 0.3): 0.325925925926
(7, 10.0, 0.225): 0.22962962963
(8, 100.0, 0.25): 0.296296296296
(9, 10.0, 0.225): 0.185185185185

Accuracy mean :0.7022222222222222
Std deviation :0.14236104336041747
Loss mean :0.2977777777777778
Std deviation :0.14236104336041747

On ALL the sets

Accuracy on all the set for every iteration, for every couple c,sigma (n_of_the_iter, c, sigma):
(0, 0.1, 0.25): 0.466666666667
(0, 0.1, 0.3): 0.6
(0, 1.0, 0.2): 0.2
(0, 1.0, 0.225): 0.466666666667
(0, 1.0, 0.25): 0.866666666667
(0, 1.0, 0.275): 0.4
(0, 1.0, 0.3): 0.266666666667
(0, 10.0, 0.2): 0.133333333333
(0, 10.0, 0.225): 0.466666666667
(0, 10.0, 0.25): 0.866666666667
(0, 10.0, 0.275): 0.4
(0, 10.0, 0.3): 0.333333333333
(0, 100.0, 0.2): 0.2
(0, 100.0, 0.225): 0.0666666666667
(0, 100.0, 0.25): 0.866666666667
(0, 100.0, 0.275): 0.4
(0, 100.0, 0.3): 0.333333333333
(1, 0.1, 0.25): 0.666666666667
(1, 0.1, 0.275): 0.666666666667
(1, 1.0, 0.2): 0.266666666667
(1, 1.0, 0.225): 0.6
(1, 1.0, 0.25): 0.666666666667
(1, 1.0, 0.275): 0.666666666667
(1, 1.0, 0.3): 0.266666666667
(1, 10.0, 0.2): 0.266666666667
(1, 10.0, 0.225): 0.666666666667
(1, 10.0, 0.25): 0.666666666667
(1, 10.0, 0.275): 0.666666666667
(1, 10.0, 0.3): 0.266666666667
(1, 100.0, 0.2): 0.666666666667
(1, 100.0, 0.225): 0.6
(1, 100.0, 0.25): 0.666666666667
(1, 100.0, 0.275): 0.666666666667
(1, 100.0, 0.3): 0.266666666667
(2, 0.1, 0.3): 0.6
(2, 1.0, 0.2): 0.2
(2, 1.0, 0.225): 0.933333333333
(2, 1.0, 0.25): 0.933333333333
(2, 1.0, 0.275): 0.8
(2, 1.0, 0.3): 0.6
(2, 10.0, 0.2): 0.2
(2, 10.0, 0.225): 0.933333333333
(2, 10.0, 0.25): 0.933333333333
(2, 10.0, 0.275): 0.2
(2, 10.0, 0.3): 0.6
(2, 100.0, 0.2): 0.2
(2, 100.0, 0.225): 0.933333333333
(2, 100.0, 0.25): 0.933333333333
(2, 100.0, 0.275): 0.2
(2, 100.0, 0.3): 0.6
(3, 0.1, 0.2): 0.266666666667
(3, 0.1, 0.25): 0.533333333333
(3, 0.1, 0.275): 0.533333333333
(3, 0.1, 0.3): 0.533333333333
(3, 1.0, 0.2): 0.266666666667
(3, 1.0, 0.225): 0.733333333333
(3, 1.0, 0.25): 0.533333333333
(3, 1.0, 0.275): 0.266666666667
(3, 1.0, 0.3): 0.533333333333
(3, 10.0, 0.2): 0.266666666667
(3, 10.0, 0.225): 0.733333333333
(3, 10.0, 0.25): 0.533333333333
(3, 10.0, 0.275): 0.266666666667
(3, 10.0, 0.3): 0.533333333333
(3, 100.0, 0.2): 0.266666666667
(3, 100.0, 0.225): 0.733333333333
(3, 100.0, 0.25): 0.533333333333
(3, 100.0, 0.275): 0.533333333333
(3, 100.0, 0.3): 0.533333333333
(4, 0.1, 0.275): 0.6
(4, 0.1, 0.3): 0.6
(4, 1.0, 0.2): 0.4
(4, 1.0, 0.225): 0.733333333333
(4, 1.0, 0.25): 0.866666666667
(4, 1.0, 0.275): 0.6
(4, 1.0, 0.3): 0.6
(4, 10.0, 0.2): 0.266666666667
(4, 10.0, 0.225): 0.733333333333
(4, 10.0, 0.25): 0.866666666667
(4, 10.0, 0.275): 0.6
(4, 10.0, 0.3): 0.6
(4, 100.0, 0.2): 0.133333333333
(4, 100.0, 0.25): 0.866666666667
(4, 100.0, 0.275): 0.6
(4, 100.0, 0.3): 0.6
(5, 1.0, 0.2): 0.466666666667
(5, 1.0, 0.225): 0.466666666667
(5, 1.0, 0.25): 0.933333333333
(5, 1.0, 0.275): 0.466666666667
(5, 1.0, 0.3): 0.466666666667
(5, 10.0, 0.2): 0.466666666667
(5, 10.0, 0.225): 0.466666666667
(5, 10.0, 0.25): 0.933333333333
(5, 10.0, 0.275): 0.466666666667
(5, 10.0, 0.3): 0.466666666667
(5, 100.0, 0.2): 0.733333333333
(5, 100.0, 0.225): 0.466666666667
(5, 100.0, 0.25): 0.933333333333
(5, 100.0, 0.275): 0.466666666667
(5, 100.0, 0.3): 0.466666666667
(6, 0.1, 0.25): 0.466666666667
(6, 0.1, 0.275): 0.733333333333
(6, 1.0, 0.2): 0.466666666667
(6, 1.0, 0.225): 0.0666666666667
(6, 1.0, 0.25): 0.6
(6, 1.0, 0.275): 0.666666666667
(6, 1.0, 0.3): 0.733333333333
(6, 10.0, 0.2): 0.466666666667
(6, 10.0, 0.225): 0.0666666666667
(6, 10.0, 0.25): 0.466666666667
(6, 10.0, 0.275): 0.666666666667
(6, 10.0, 0.3): 0.733333333333
(6, 100.0, 0.2): 0.466666666667
(6, 100.0, 0.225): 0.666666666667
(6, 100.0, 0.25): 0.6
(6, 100.0, 0.275): 0.666666666667
(6, 100.0, 0.3): 0.733333333333
(7, 0.1, 0.25): 0.533333333333
(7, 0.1, 0.275): 0.533333333333
(7, 0.1, 0.3): 0.533333333333
(7, 1.0, 0.225): 0.733333333333
(7, 1.0, 0.25): 0.533333333333
(7, 1.0, 0.275): 0.533333333333
(7, 1.0, 0.3): 0.533333333333
(7, 10.0, 0.225): 0.733333333333
(7, 10.0, 0.25): 0.533333333333
(7, 10.0, 0.275): 0.533333333333
(7, 10.0, 0.3): 0.533333333333
(7, 100.0, 0.225): 0.733333333333
(7, 100.0, 0.25): 0.533333333333
(7, 100.0, 0.275): 0.533333333333
(7, 100.0, 0.3): 0.533333333333
(8, 0.1, 0.275): 0.733333333333
(8, 0.1, 0.3): 0.733333333333
(8, 1.0, 0.2): 0.4
(8, 1.0, 0.225): 0.666666666667
(8, 1.0, 0.25): 0.933333333333
(8, 1.0, 0.275): 0.333333333333
(8, 1.0, 0.3): 0.733333333333
(8, 10.0, 0.225): 0.733333333333
(8, 10.0, 0.25): 0.933333333333
(8, 10.0, 0.275): 0.733333333333
(8, 10.0, 0.3): 0.733333333333
(8, 100.0, 0.225): 0.666666666667
(8, 100.0, 0.25): 1.0
(8, 100.0, 0.275): 0.333333333333
(8, 100.0, 0.3): 0.733333333333
(9, 0.1, 0.275): 0.666666666667
(9, 1.0, 0.225): 0.733333333333
(9, 1.0, 0.275): 0.666666666667
(9, 1.0, 0.3): 0.466666666667
(9, 10.0, 0.225): 0.733333333333
(9, 10.0, 0.25): 0.733333333333
(9, 10.0, 0.275): 0.666666666667
(9, 10.0, 0.3): 0.466666666667
(9, 100.0, 0.225): 0.733333333333
(9, 100.0, 0.25): 0.2
(9, 100.0, 0.275): 0.666666666667
(9, 100.0, 0.3): 0.466666666667

Loss on all the set for every iteration, for every couple c,sigma (n_of_the_iter, best_c, best_sigma):
(0, 0.1, 0.25): 0.533333333333
(0, 0.1, 0.3): 0.4
(0, 1.0, 0.2): 0.8
(0, 1.0, 0.225): 0.533333333333
(0, 1.0, 0.25): 0.133333333333
(0, 1.0, 0.275): 0.6
(0, 1.0, 0.3): 0.733333333333
(0, 10.0, 0.2): 0.866666666667
(0, 10.0, 0.225): 0.533333333333
(0, 10.0, 0.25): 0.133333333333
(0, 10.0, 0.275): 0.6
(0, 10.0, 0.3): 0.666666666667
(0, 100.0, 0.2): 0.8
(0, 100.0, 0.225): 0.933333333333
(0, 100.0, 0.25): 0.133333333333
(0, 100.0, 0.275): 0.6
(0, 100.0, 0.3): 0.666666666667
(1, 0.1, 0.25): 0.333333333333
(1, 0.1, 0.275): 0.333333333333
(1, 1.0, 0.2): 0.733333333333
(1, 1.0, 0.225): 0.4
(1, 1.0, 0.25): 0.333333333333
(1, 1.0, 0.275): 0.333333333333
(1, 1.0, 0.3): 0.733333333333
(1, 10.0, 0.2): 0.733333333333
(1, 10.0, 0.225): 0.333333333333
(1, 10.0, 0.25): 0.333333333333
(1, 10.0, 0.275): 0.333333333333
(1, 10.0, 0.3): 0.733333333333
(1, 100.0, 0.2): 0.333333333333
(1, 100.0, 0.225): 0.4
(1, 100.0, 0.25): 0.333333333333
(1, 100.0, 0.275): 0.333333333333
(1, 100.0, 0.3): 0.733333333333
(2, 0.1, 0.3): 0.4
(2, 1.0, 0.2): 0.8
(2, 1.0, 0.225): 0.0666666666667
(2, 1.0, 0.25): 0.0666666666667
(2, 1.0, 0.275): 0.2
(2, 1.0, 0.3): 0.4
(2, 10.0, 0.2): 0.8
(2, 10.0, 0.225): 0.0666666666667
(2, 10.0, 0.25): 0.0666666666667
(2, 10.0, 0.275): 0.8
(2, 10.0, 0.3): 0.4
(2, 100.0, 0.2): 0.8
(2, 100.0, 0.225): 0.0666666666667
(2, 100.0, 0.25): 0.0666666666667
(2, 100.0, 0.275): 0.8
(2, 100.0, 0.3): 0.4
(3, 0.1, 0.2): 0.733333333333
(3, 0.1, 0.25): 0.466666666667
(3, 0.1, 0.275): 0.466666666667
(3, 0.1, 0.3): 0.466666666667
(3, 1.0, 0.2): 0.733333333333
(3, 1.0, 0.225): 0.266666666667
(3, 1.0, 0.25): 0.466666666667
(3, 1.0, 0.275): 0.733333333333
(3, 1.0, 0.3): 0.466666666667
(3, 10.0, 0.2): 0.733333333333
(3, 10.0, 0.225): 0.266666666667
(3, 10.0, 0.25): 0.466666666667
(3, 10.0, 0.275): 0.733333333333
(3, 10.0, 0.3): 0.466666666667
(3, 100.0, 0.2): 0.733333333333
(3, 100.0, 0.225): 0.266666666667
(3, 100.0, 0.25): 0.466666666667
(3, 100.0, 0.275): 0.466666666667
(3, 100.0, 0.3): 0.466666666667
(4, 0.1, 0.275): 0.4
(4, 0.1, 0.3): 0.4
(4, 1.0, 0.2): 0.6
(4, 1.0, 0.225): 0.266666666667
(4, 1.0, 0.25): 0.133333333333
(4, 1.0, 0.275): 0.4
(4, 1.0, 0.3): 0.4
(4, 10.0, 0.2): 0.733333333333
(4, 10.0, 0.225): 0.266666666667
(4, 10.0, 0.25): 0.133333333333
(4, 10.0, 0.275): 0.4
(4, 10.0, 0.3): 0.4
(4, 100.0, 0.2): 0.866666666667
(4, 100.0, 0.25): 0.133333333333
(4, 100.0, 0.275): 0.4
(4, 100.0, 0.3): 0.4
(5, 1.0, 0.2): 0.533333333333
(5, 1.0, 0.225): 0.533333333333
(5, 1.0, 0.25): 0.0666666666667
(5, 1.0, 0.275): 0.533333333333
(5, 1.0, 0.3): 0.533333333333
(5, 10.0, 0.2): 0.533333333333
(5, 10.0, 0.225): 0.533333333333
(5, 10.0, 0.25): 0.0666666666667
(5, 10.0, 0.275): 0.533333333333
(5, 10.0, 0.3): 0.533333333333
(5, 100.0, 0.2): 0.266666666667
(5, 100.0, 0.225): 0.533333333333
(5, 100.0, 0.25): 0.0666666666667
(5, 100.0, 0.275): 0.533333333333
(5, 100.0, 0.3): 0.533333333333
(6, 0.1, 0.25): 0.533333333333
(6, 0.1, 0.275): 0.266666666667
(6, 1.0, 0.2): 0.533333333333
(6, 1.0, 0.225): 0.933333333333
(6, 1.0, 0.25): 0.4
(6, 1.0, 0.275): 0.333333333333
(6, 1.0, 0.3): 0.266666666667
(6, 10.0, 0.2): 0.533333333333
(6, 10.0, 0.225): 0.933333333333
(6, 10.0, 0.25): 0.533333333333
(6, 10.0, 0.275): 0.333333333333
(6, 10.0, 0.3): 0.266666666667
(6, 100.0, 0.2): 0.533333333333
(6, 100.0, 0.225): 0.333333333333
(6, 100.0, 0.25): 0.4
(6, 100.0, 0.275): 0.333333333333
(6, 100.0, 0.3): 0.266666666667
(7, 0.1, 0.25): 0.466666666667
(7, 0.1, 0.275): 0.466666666667
(7, 0.1, 0.3): 0.466666666667
(7, 1.0, 0.225): 0.266666666667
(7, 1.0, 0.25): 0.466666666667
(7, 1.0, 0.275): 0.466666666667
(7, 1.0, 0.3): 0.466666666667
(7, 10.0, 0.225): 0.266666666667
(7, 10.0, 0.25): 0.466666666667
(7, 10.0, 0.275): 0.466666666667
(7, 10.0, 0.3): 0.466666666667
(7, 100.0, 0.225): 0.266666666667
(7, 100.0, 0.25): 0.466666666667
(7, 100.0, 0.275): 0.466666666667
(7, 100.0, 0.3): 0.466666666667
(8, 0.1, 0.275): 0.266666666667
(8, 0.1, 0.3): 0.266666666667
(8, 1.0, 0.2): 0.6
(8, 1.0, 0.225): 0.333333333333
(8, 1.0, 0.25): 0.0666666666667
(8, 1.0, 0.275): 0.666666666667
(8, 1.0, 0.3): 0.266666666667
(8, 10.0, 0.225): 0.266666666667
(8, 10.0, 0.25): 0.0666666666667
(8, 10.0, 0.275): 0.266666666667
(8, 10.0, 0.3): 0.266666666667
(8, 100.0, 0.225): 0.333333333333
(8, 100.0, 0.25): 0.0
(8, 100.0, 0.275): 0.666666666667
(8, 100.0, 0.3): 0.266666666667
(9, 0.1, 0.275): 0.333333333333
(9, 1.0, 0.225): 0.266666666667
(9, 1.0, 0.275): 0.333333333333
(9, 1.0, 0.3): 0.533333333333
(9, 10.0, 0.225): 0.266666666667
(9, 10.0, 0.25): 0.266666666667
(9, 10.0, 0.275): 0.333333333333
(9, 10.0, 0.3): 0.533333333333
(9, 100.0, 0.225): 0.266666666667
(9, 100.0, 0.25): 0.8
(9, 100.0, 0.275): 0.333333333333
(9, 100.0, 0.3): 0.533333333333

Accuracy mean :0.5614255765199162
Std deviation :0.2115311255293519
Loss mean :0.4385744234800838
Std deviation :0.2115311255293519



