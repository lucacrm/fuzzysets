Crisp_Binary Muzzifier_2dim, number of iterations: 10

Parameters info
Tradeoffs parameter: [  0.1   1.   10.  100. ]
Gaussian kernel sigmas: [0.2   0.225 0.25  0.275 0.3  ]
Number of principal dimension considerated: 2
Dataset length: 150

Clusterization info
Minimum size of a cluster: in perc: 0.01, in int: 2
Type of mu: Binary Muzzifier
Fuzzifier: Crisp
Cluster to label info
Force the number of cluster to be the number of different labels: False
Force the labels to be always represent by a cluster: False

Validation info
Conflict resolution: random


RESULTS

On TEST set

Accuracy on test set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 100.0, 0.25): 0.466666666667
(1, 1.0, 0.3): 0.533333333333
(2, 0.1, 0.275): 0.266666666667
(3, 100.0, 0.3): 0.4
(4, 100.0, 0.225): 0.6
(5, 100.0, 0.25): 0.466666666667
(6, 1.0, 0.275): 0.6
(7, 10.0, 0.25): 0.6
(8, 10.0, 0.3): 0.666666666667
(9, 1.0, 0.225): 0.6

Loss on test set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 100.0, 0.25): 0.533333333333
(1, 1.0, 0.3): 0.466666666667
(2, 0.1, 0.275): 0.733333333333
(3, 100.0, 0.3): 0.6
(4, 100.0, 0.225): 0.4
(5, 100.0, 0.25): 0.533333333333
(6, 1.0, 0.275): 0.4
(7, 10.0, 0.25): 0.4
(8, 10.0, 0.3): 0.333333333333
(9, 1.0, 0.225): 0.4

Accuracy mean :0.5199999999999999
Std deviation :0.11469767022723501
Loss mean :0.48
Std deviation :0.114697670227235

On TRAINING set

Accuracy on training set for every iteration (n_of_the_iter, c, sigma):
(0, 100.0, 0.25): 0.577777777778
(1, 1.0, 0.3): 0.614814814815
(2, 0.1, 0.275): 0.511111111111
(3, 100.0, 0.3): 0.62962962963
(4, 100.0, 0.225): 0.674074074074
(5, 100.0, 0.25): 0.518518518519
(6, 1.0, 0.275): 0.533333333333
(7, 10.0, 0.25): 0.644444444444
(8, 10.0, 0.3): 0.644444444444
(9, 1.0, 0.225): 0.696296296296
Loss on training set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 100.0, 0.25): 0.422222222222
(1, 1.0, 0.3): 0.385185185185
(2, 0.1, 0.275): 0.488888888889
(3, 100.0, 0.3): 0.37037037037
(4, 100.0, 0.225): 0.325925925926
(5, 100.0, 0.25): 0.481481481481
(6, 1.0, 0.275): 0.466666666667
(7, 10.0, 0.25): 0.355555555556
(8, 10.0, 0.3): 0.355555555556
(9, 1.0, 0.225): 0.303703703704

Accuracy mean :0.6044444444444445
Std deviation :0.06252132695113836
Loss mean :0.39555555555555555
Std deviation :0.06252132695113834

On ALL the sets

Accuracy on all the set for every iteration, for every couple c,sigma (n_of_the_iter, c, sigma):
(0, 0.1, 0.275): 0.266666666667
(0, 1.0, 0.2): 0.266666666667
(0, 1.0, 0.225): 0.466666666667
(0, 1.0, 0.25): 0.266666666667
(0, 1.0, 0.275): 0.266666666667
(0, 1.0, 0.3): 0.533333333333
(0, 10.0, 0.2): 0.333333333333
(0, 10.0, 0.225): 0.4
(0, 10.0, 0.25): 0.6
(0, 10.0, 0.275): 0.266666666667
(0, 10.0, 0.3): 0.533333333333
(0, 100.0, 0.2): 0.466666666667
(0, 100.0, 0.225): 0.4
(0, 100.0, 0.25): 0.8
(0, 100.0, 0.275): 0.266666666667
(0, 100.0, 0.3): 0.666666666667
(1, 0.1, 0.275): 0.466666666667
(1, 1.0, 0.2): 0.4
(1, 1.0, 0.225): 0.533333333333
(1, 1.0, 0.25): 0.533333333333
(1, 1.0, 0.275): 0.533333333333
(1, 1.0, 0.3): 0.666666666667
(1, 10.0, 0.2): 0.2
(1, 10.0, 0.225): 0.466666666667
(1, 10.0, 0.25): 0.533333333333
(1, 10.0, 0.275): 0.6
(1, 10.0, 0.3): 0.4
(1, 100.0, 0.2): 0.4
(1, 100.0, 0.225): 0.333333333333
(1, 100.0, 0.25): 0.533333333333
(1, 100.0, 0.275): 0.4
(1, 100.0, 0.3): 0.4
(2, 0.1, 0.25): 0.466666666667
(2, 0.1, 0.275): 0.666666666667
(2, 1.0, 0.2): 0.333333333333
(2, 1.0, 0.225): 0.4
(2, 1.0, 0.25): 0.533333333333
(2, 1.0, 0.275): 0.4
(2, 1.0, 0.3): 0.6
(2, 10.0, 0.2): 0.333333333333
(2, 10.0, 0.225): 0.266666666667
(2, 10.0, 0.25): 0.466666666667
(2, 10.0, 0.275): 0.533333333333
(2, 10.0, 0.3): 0.4
(2, 100.0, 0.2): 0.4
(2, 100.0, 0.225): 0.333333333333
(2, 100.0, 0.25): 0.466666666667
(2, 100.0, 0.275): 0.4
(2, 100.0, 0.3): 0.533333333333
(3, 0.1, 0.3): 0.533333333333
(3, 1.0, 0.2): 0.466666666667
(3, 1.0, 0.225): 0.4
(3, 1.0, 0.25): 0.4
(3, 1.0, 0.3): 0.6
(3, 10.0, 0.2): 0.466666666667
(3, 10.0, 0.225): 0.4
(3, 10.0, 0.25): 0.533333333333
(3, 10.0, 0.275): 0.4
(3, 10.0, 0.3): 0.533333333333
(3, 100.0, 0.2): 0.4
(3, 100.0, 0.225): 0.266666666667
(3, 100.0, 0.25): 0.4
(3, 100.0, 0.3): 0.733333333333
(4, 1.0, 0.2): 0.266666666667
(4, 1.0, 0.225): 0.6
(4, 1.0, 0.25): 0.2
(4, 1.0, 0.275): 0.4
(4, 1.0, 0.3): 0.466666666667
(4, 10.0, 0.2): 0.333333333333
(4, 10.0, 0.225): 0.6
(4, 10.0, 0.25): 0.4
(4, 10.0, 0.275): 0.4
(4, 10.0, 0.3): 0.4
(4, 100.0, 0.2): 0.533333333333
(4, 100.0, 0.225): 0.666666666667
(4, 100.0, 0.25): 0.4
(4, 100.0, 0.275): 0.333333333333
(4, 100.0, 0.3): 0.466666666667
(5, 0.1, 0.25): 0.266666666667
(5, 1.0, 0.2): 0.4
(5, 1.0, 0.225): 0.4
(5, 1.0, 0.25): 0.466666666667
(5, 1.0, 0.275): 0.266666666667
(5, 1.0, 0.3): 0.333333333333
(5, 10.0, 0.2): 0.333333333333
(5, 10.0, 0.225): 0.466666666667
(5, 10.0, 0.25): 0.466666666667
(5, 10.0, 0.275): 0.4
(5, 10.0, 0.3): 0.333333333333
(5, 100.0, 0.2): 0.4
(5, 100.0, 0.225): 0.333333333333
(5, 100.0, 0.25): 0.6
(5, 100.0, 0.275): 0.333333333333
(5, 100.0, 0.3): 0.533333333333
(6, 1.0, 0.2): 0.466666666667
(6, 1.0, 0.225): 0.533333333333
(6, 1.0, 0.25): 0.4
(6, 1.0, 0.275): 0.6
(6, 1.0, 0.3): 0.466666666667
(6, 10.0, 0.2): 0.466666666667
(6, 10.0, 0.225): 0.533333333333
(6, 10.0, 0.25): 0.333333333333
(6, 10.0, 0.275): 0.266666666667
(6, 10.0, 0.3): 0.4
(6, 100.0, 0.2): 0.466666666667
(6, 100.0, 0.225): 0.333333333333
(6, 100.0, 0.25): 0.6
(6, 100.0, 0.275): 0.533333333333
(6, 100.0, 0.3): 0.333333333333
(7, 0.1, 0.3): 0.533333333333
(7, 1.0, 0.2): 0.466666666667
(7, 1.0, 0.225): 0.533333333333
(7, 1.0, 0.25): 0.8
(7, 1.0, 0.275): 0.466666666667
(7, 1.0, 0.3): 0.6
(7, 10.0, 0.2): 0.8
(7, 10.0, 0.225): 0.466666666667
(7, 10.0, 0.25): 0.933333333333
(7, 10.0, 0.275): 0.533333333333
(7, 10.0, 0.3): 0.6
(7, 100.0, 0.2): 0.533333333333
(7, 100.0, 0.225): 0.466666666667
(7, 100.0, 0.25): 0.733333333333
(7, 100.0, 0.275): 0.533333333333
(7, 100.0, 0.3): 0.666666666667
(8, 1.0, 0.2): 0.533333333333
(8, 1.0, 0.225): 0.333333333333
(8, 1.0, 0.25): 0.466666666667
(8, 1.0, 0.275): 0.266666666667
(8, 1.0, 0.3): 0.466666666667
(8, 10.0, 0.2): 0.333333333333
(8, 10.0, 0.225): 0.4
(8, 10.0, 0.25): 0.333333333333
(8, 10.0, 0.275): 0.533333333333
(8, 10.0, 0.3): 0.6
(8, 100.0, 0.2): 0.333333333333
(8, 100.0, 0.225): 0.466666666667
(8, 100.0, 0.25): 0.533333333333
(8, 100.0, 0.275): 0.533333333333
(8, 100.0, 0.3): 0.466666666667
(9, 1.0, 0.2): 0.666666666667
(9, 1.0, 0.225): 0.8
(9, 1.0, 0.25): 0.666666666667
(9, 1.0, 0.275): 0.333333333333
(9, 1.0, 0.3): 0.4
(9, 10.0, 0.2): 0.466666666667
(9, 10.0, 0.225): 0.533333333333
(9, 10.0, 0.25): 0.466666666667
(9, 10.0, 0.275): 0.266666666667
(9, 10.0, 0.3): 0.266666666667
(9, 100.0, 0.2): 0.333333333333
(9, 100.0, 0.225): 0.666666666667
(9, 100.0, 0.25): 0.533333333333
(9, 100.0, 0.275): 0.333333333333
(9, 100.0, 0.3): 0.266666666667

Loss on all the set for every iteration, for every couple c,sigma (n_of_the_iter, best_c, best_sigma):
(0, 0.1, 0.275): 0.733333333333
(0, 1.0, 0.2): 0.733333333333
(0, 1.0, 0.225): 0.533333333333
(0, 1.0, 0.25): 0.733333333333
(0, 1.0, 0.275): 0.733333333333
(0, 1.0, 0.3): 0.466666666667
(0, 10.0, 0.2): 0.666666666667
(0, 10.0, 0.225): 0.6
(0, 10.0, 0.25): 0.4
(0, 10.0, 0.275): 0.733333333333
(0, 10.0, 0.3): 0.466666666667
(0, 100.0, 0.2): 0.533333333333
(0, 100.0, 0.225): 0.6
(0, 100.0, 0.25): 0.2
(0, 100.0, 0.275): 0.733333333333
(0, 100.0, 0.3): 0.333333333333
(1, 0.1, 0.275): 0.533333333333
(1, 1.0, 0.2): 0.6
(1, 1.0, 0.225): 0.466666666667
(1, 1.0, 0.25): 0.466666666667
(1, 1.0, 0.275): 0.466666666667
(1, 1.0, 0.3): 0.333333333333
(1, 10.0, 0.2): 0.8
(1, 10.0, 0.225): 0.533333333333
(1, 10.0, 0.25): 0.466666666667
(1, 10.0, 0.275): 0.4
(1, 10.0, 0.3): 0.6
(1, 100.0, 0.2): 0.6
(1, 100.0, 0.225): 0.666666666667
(1, 100.0, 0.25): 0.466666666667
(1, 100.0, 0.275): 0.6
(1, 100.0, 0.3): 0.6
(2, 0.1, 0.25): 0.533333333333
(2, 0.1, 0.275): 0.333333333333
(2, 1.0, 0.2): 0.666666666667
(2, 1.0, 0.225): 0.6
(2, 1.0, 0.25): 0.466666666667
(2, 1.0, 0.275): 0.6
(2, 1.0, 0.3): 0.4
(2, 10.0, 0.2): 0.666666666667
(2, 10.0, 0.225): 0.733333333333
(2, 10.0, 0.25): 0.533333333333
(2, 10.0, 0.275): 0.466666666667
(2, 10.0, 0.3): 0.6
(2, 100.0, 0.2): 0.6
(2, 100.0, 0.225): 0.666666666667
(2, 100.0, 0.25): 0.533333333333
(2, 100.0, 0.275): 0.6
(2, 100.0, 0.3): 0.466666666667
(3, 0.1, 0.3): 0.466666666667
(3, 1.0, 0.2): 0.533333333333
(3, 1.0, 0.225): 0.6
(3, 1.0, 0.25): 0.6
(3, 1.0, 0.3): 0.4
(3, 10.0, 0.2): 0.533333333333
(3, 10.0, 0.225): 0.6
(3, 10.0, 0.25): 0.466666666667
(3, 10.0, 0.275): 0.6
(3, 10.0, 0.3): 0.466666666667
(3, 100.0, 0.2): 0.6
(3, 100.0, 0.225): 0.733333333333
(3, 100.0, 0.25): 0.6
(3, 100.0, 0.3): 0.266666666667
(4, 1.0, 0.2): 0.733333333333
(4, 1.0, 0.225): 0.4
(4, 1.0, 0.25): 0.8
(4, 1.0, 0.275): 0.6
(4, 1.0, 0.3): 0.533333333333
(4, 10.0, 0.2): 0.666666666667
(4, 10.0, 0.225): 0.4
(4, 10.0, 0.25): 0.6
(4, 10.0, 0.275): 0.6
(4, 10.0, 0.3): 0.6
(4, 100.0, 0.2): 0.466666666667
(4, 100.0, 0.225): 0.333333333333
(4, 100.0, 0.25): 0.6
(4, 100.0, 0.275): 0.666666666667
(4, 100.0, 0.3): 0.533333333333
(5, 0.1, 0.25): 0.733333333333
(5, 1.0, 0.2): 0.6
(5, 1.0, 0.225): 0.6
(5, 1.0, 0.25): 0.533333333333
(5, 1.0, 0.275): 0.733333333333
(5, 1.0, 0.3): 0.666666666667
(5, 10.0, 0.2): 0.666666666667
(5, 10.0, 0.225): 0.533333333333
(5, 10.0, 0.25): 0.533333333333
(5, 10.0, 0.275): 0.6
(5, 10.0, 0.3): 0.666666666667
(5, 100.0, 0.2): 0.6
(5, 100.0, 0.225): 0.666666666667
(5, 100.0, 0.25): 0.4
(5, 100.0, 0.275): 0.666666666667
(5, 100.0, 0.3): 0.466666666667
(6, 1.0, 0.2): 0.533333333333
(6, 1.0, 0.225): 0.466666666667
(6, 1.0, 0.25): 0.6
(6, 1.0, 0.275): 0.4
(6, 1.0, 0.3): 0.533333333333
(6, 10.0, 0.2): 0.533333333333
(6, 10.0, 0.225): 0.466666666667
(6, 10.0, 0.25): 0.666666666667
(6, 10.0, 0.275): 0.733333333333
(6, 10.0, 0.3): 0.6
(6, 100.0, 0.2): 0.533333333333
(6, 100.0, 0.225): 0.666666666667
(6, 100.0, 0.25): 0.4
(6, 100.0, 0.275): 0.466666666667
(6, 100.0, 0.3): 0.666666666667
(7, 0.1, 0.3): 0.466666666667
(7, 1.0, 0.2): 0.533333333333
(7, 1.0, 0.225): 0.466666666667
(7, 1.0, 0.25): 0.2
(7, 1.0, 0.275): 0.533333333333
(7, 1.0, 0.3): 0.4
(7, 10.0, 0.2): 0.2
(7, 10.0, 0.225): 0.533333333333
(7, 10.0, 0.25): 0.0666666666667
(7, 10.0, 0.275): 0.466666666667
(7, 10.0, 0.3): 0.4
(7, 100.0, 0.2): 0.466666666667
(7, 100.0, 0.225): 0.533333333333
(7, 100.0, 0.25): 0.266666666667
(7, 100.0, 0.275): 0.466666666667
(7, 100.0, 0.3): 0.333333333333
(8, 1.0, 0.2): 0.466666666667
(8, 1.0, 0.225): 0.666666666667
(8, 1.0, 0.25): 0.533333333333
(8, 1.0, 0.275): 0.733333333333
(8, 1.0, 0.3): 0.533333333333
(8, 10.0, 0.2): 0.666666666667
(8, 10.0, 0.225): 0.6
(8, 10.0, 0.25): 0.666666666667
(8, 10.0, 0.275): 0.466666666667
(8, 10.0, 0.3): 0.4
(8, 100.0, 0.2): 0.666666666667
(8, 100.0, 0.225): 0.533333333333
(8, 100.0, 0.25): 0.466666666667
(8, 100.0, 0.275): 0.466666666667
(8, 100.0, 0.3): 0.533333333333
(9, 1.0, 0.2): 0.333333333333
(9, 1.0, 0.225): 0.2
(9, 1.0, 0.25): 0.333333333333
(9, 1.0, 0.275): 0.666666666667
(9, 1.0, 0.3): 0.6
(9, 10.0, 0.2): 0.533333333333
(9, 10.0, 0.225): 0.466666666667
(9, 10.0, 0.25): 0.533333333333
(9, 10.0, 0.275): 0.733333333333
(9, 10.0, 0.3): 0.733333333333
(9, 100.0, 0.2): 0.666666666667
(9, 100.0, 0.225): 0.333333333333
(9, 100.0, 0.25): 0.466666666667
(9, 100.0, 0.275): 0.666666666667
(9, 100.0, 0.3): 0.733333333333

Accuracy mean :0.458494623655914
Std deviation :0.13362022551408684
Loss mean :0.541505376344086
Std deviation :0.13362022551408684



Linear_Binary Muzzifier_2dim, number of iterations: 10

Parameters info
Tradeoffs parameter: [  0.1   1.   10.  100. ]
Gaussian kernel sigmas: [0.2   0.225 0.25  0.275 0.3  ]
Number of principal dimension considerated: 2
Dataset length: 150

Clusterization info
Minimum size of a cluster: in perc: 0.01, in int: 2
Type of mu: Binary Muzzifier
Fuzzifier: Linear
Cluster to label info
Force the number of cluster to be the number of different labels: False
Force the labels to be always represent by a cluster: False

Validation info
Conflict resolution: random


RESULTS

On TEST set

Accuracy on test set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 1.0, 0.225): 0.866666666667
(1, 1.0, 0.225): 0.866666666667
(2, 100.0, 0.25): 0.533333333333
(3, 10.0, 0.225): 0.733333333333
(4, 100.0, 0.2): 0.933333333333
(5, 1.0, 0.225): 0.8
(6, 10.0, 0.225): 0.8
(7, 1.0, 0.2): 0.733333333333
(8, 100.0, 0.2): 0.8
(9, 100.0, 0.225): 0.933333333333

Loss on test set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 1.0, 0.225): 0.133333333333
(1, 1.0, 0.225): 0.133333333333
(2, 100.0, 0.25): 0.466666666667
(3, 10.0, 0.225): 0.266666666667
(4, 100.0, 0.2): 0.0666666666667
(5, 1.0, 0.225): 0.2
(6, 10.0, 0.225): 0.2
(7, 1.0, 0.2): 0.266666666667
(8, 100.0, 0.2): 0.2
(9, 100.0, 0.225): 0.0666666666667

Accuracy mean :0.8
Std deviation :0.11155467020454343
Loss mean :0.2
Std deviation :0.1115546702045434

On TRAINING set

Accuracy on training set for every iteration (n_of_the_iter, c, sigma):
(0, 1.0, 0.225): 0.881481481481
(1, 1.0, 0.225): 0.940740740741
(2, 100.0, 0.25): 0.37037037037
(3, 10.0, 0.225): 0.844444444444
(4, 100.0, 0.2): 0.866666666667
(5, 1.0, 0.225): 0.925925925926
(6, 10.0, 0.225): 0.881481481481
(7, 1.0, 0.2): 0.911111111111
(8, 100.0, 0.2): 0.888888888889
(9, 100.0, 0.225): 0.866666666667
Loss on training set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 1.0, 0.225): 0.118518518519
(1, 1.0, 0.225): 0.0592592592593
(2, 100.0, 0.25): 0.62962962963
(3, 10.0, 0.225): 0.155555555556
(4, 100.0, 0.2): 0.133333333333
(5, 1.0, 0.225): 0.0740740740741
(6, 10.0, 0.225): 0.118518518519
(7, 1.0, 0.2): 0.0888888888889
(8, 100.0, 0.2): 0.111111111111
(9, 100.0, 0.225): 0.133333333333

Accuracy mean :0.8377777777777778
Std deviation :0.15822922719962973
Loss mean :0.1622222222222222
Std deviation :0.15822922719962973

On ALL the sets

Accuracy on all the set for every iteration, for every couple c,sigma (n_of_the_iter, c, sigma):
(0, 0.1, 0.275): 0.6
(0, 1.0, 0.2): 0.866666666667
(0, 1.0, 0.225): 0.933333333333
(0, 1.0, 0.25): 0.8
(0, 1.0, 0.275): 0.6
(0, 1.0, 0.3): 0.466666666667
(0, 10.0, 0.2): 0.866666666667
(0, 10.0, 0.225): 0.933333333333
(0, 10.0, 0.25): 0.8
(0, 10.0, 0.275): 0.6
(0, 10.0, 0.3): 0.466666666667
(0, 100.0, 0.2): 0.933333333333
(0, 100.0, 0.225): 0.933333333333
(0, 100.0, 0.25): 0.8
(0, 100.0, 0.275): 0.6
(0, 100.0, 0.3): 0.466666666667
(1, 1.0, 0.2): 1.0
(1, 1.0, 0.225): 1.0
(1, 1.0, 0.25): 1.0
(1, 1.0, 0.275): 0.933333333333
(1, 1.0, 0.3): 0.866666666667
(1, 10.0, 0.2): 1.0
(1, 10.0, 0.225): 0.666666666667
(1, 10.0, 0.25): 1.0
(1, 10.0, 0.275): 0.933333333333
(1, 10.0, 0.3): 0.866666666667
(1, 100.0, 0.2): 1.0
(1, 100.0, 0.225): 0.266666666667
(1, 100.0, 0.25): 1.0
(1, 100.0, 0.275): 0.933333333333
(1, 100.0, 0.3): 0.866666666667
(2, 0.1, 0.3): 0.666666666667
(2, 1.0, 0.2): 0.866666666667
(2, 1.0, 0.225): 0.866666666667
(2, 1.0, 0.25): 0.866666666667
(2, 1.0, 0.275): 0.733333333333
(2, 1.0, 0.3): 0.666666666667
(2, 10.0, 0.2): 0.866666666667
(2, 10.0, 0.225): 0.866666666667
(2, 10.0, 0.25): 0.866666666667
(2, 10.0, 0.275): 0.733333333333
(2, 10.0, 0.3): 0.666666666667
(2, 100.0, 0.2): 0.866666666667
(2, 100.0, 0.225): 0.866666666667
(2, 100.0, 0.25): 0.866666666667
(2, 100.0, 0.275): 0.733333333333
(2, 100.0, 0.3): 0.666666666667
(3, 0.1, 0.25): 0.533333333333
(3, 1.0, 0.2): 0.933333333333
(3, 1.0, 0.225): 0.933333333333
(3, 1.0, 0.25): 0.533333333333
(3, 1.0, 0.275): 0.866666666667
(3, 1.0, 0.3): 0.6
(3, 10.0, 0.2): 0.933333333333
(3, 10.0, 0.225): 0.933333333333
(3, 10.0, 0.25): 0.533333333333
(3, 10.0, 0.275): 0.8
(3, 10.0, 0.3): 0.6
(3, 100.0, 0.2): 0.933333333333
(3, 100.0, 0.225): 0.933333333333
(3, 100.0, 0.25): 0.533333333333
(3, 100.0, 0.275): 0.866666666667
(3, 100.0, 0.3): 0.6
(4, 1.0, 0.2): 0.866666666667
(4, 1.0, 0.225): 0.866666666667
(4, 1.0, 0.25): 0.8
(4, 1.0, 0.275): 0.733333333333
(4, 1.0, 0.3): 0.666666666667
(4, 10.0, 0.2): 0.866666666667
(4, 10.0, 0.225): 0.8
(4, 10.0, 0.25): 0.466666666667
(4, 10.0, 0.275): 0.733333333333
(4, 10.0, 0.3): 0.666666666667
(4, 100.0, 0.2): 0.866666666667
(4, 100.0, 0.225): 0.8
(4, 100.0, 0.25): 0.8
(4, 100.0, 0.275): 0.733333333333
(4, 100.0, 0.3): 0.666666666667
(5, 1.0, 0.2): 0.933333333333
(5, 1.0, 0.225): 0.933333333333
(5, 1.0, 0.25): 0.333333333333
(5, 1.0, 0.275): 0.8
(5, 1.0, 0.3): 0.8
(5, 10.0, 0.2): 0.933333333333
(5, 10.0, 0.225): 0.933333333333
(5, 10.0, 0.25): 0.933333333333
(5, 10.0, 0.275): 0.8
(5, 10.0, 0.3): 0.2
(5, 100.0, 0.2): 0.933333333333
(5, 100.0, 0.225): 0.933333333333
(5, 100.0, 0.25): 0.933333333333
(5, 100.0, 0.275): 0.8
(5, 100.0, 0.3): 0.8
(6, 0.1, 0.25): 0.733333333333
(6, 0.1, 0.275): 0.8
(6, 0.1, 0.3): 0.8
(6, 1.0, 0.2): 0.733333333333
(6, 1.0, 0.225): 0.8
(6, 1.0, 0.25): 0.733333333333
(6, 1.0, 0.275): 0.8
(6, 1.0, 0.3): 0.8
(6, 10.0, 0.2): 0.733333333333
(6, 10.0, 0.225): 0.866666666667
(6, 10.0, 0.25): 0.733333333333
(6, 10.0, 0.275): 0.733333333333
(6, 10.0, 0.3): 0.8
(6, 100.0, 0.2): 0.733333333333
(6, 100.0, 0.225): 0.866666666667
(6, 100.0, 0.25): 0.266666666667
(6, 100.0, 0.275): 0.266666666667
(6, 100.0, 0.3): 0.266666666667
(7, 1.0, 0.2): 0.933333333333
(7, 1.0, 0.225): 0.8
(7, 1.0, 0.25): 0.6
(7, 1.0, 0.275): 0.733333333333
(7, 1.0, 0.3): 0.266666666667
(7, 10.0, 0.2): 0.933333333333
(7, 10.0, 0.225): 0.8
(7, 10.0, 0.25): 0.6
(7, 10.0, 0.275): 0.733333333333
(7, 10.0, 0.3): 0.533333333333
(7, 100.0, 0.2): 0.933333333333
(7, 100.0, 0.225): 0.8
(7, 100.0, 0.25): 0.533333333333
(7, 100.0, 0.275): 0.733333333333
(7, 100.0, 0.3): 0.533333333333
(8, 1.0, 0.2): 0.866666666667
(8, 1.0, 0.225): 0.6
(8, 1.0, 0.25): 0.6
(8, 1.0, 0.275): 0.533333333333
(8, 1.0, 0.3): 0.533333333333
(8, 10.0, 0.2): 0.866666666667
(8, 10.0, 0.225): 0.6
(8, 10.0, 0.25): 0.6
(8, 10.0, 0.275): 0.6
(8, 10.0, 0.3): 0.533333333333
(8, 100.0, 0.2): 0.866666666667
(8, 100.0, 0.225): 0.6
(8, 100.0, 0.25): 0.6
(8, 100.0, 0.275): 0.8
(8, 100.0, 0.3): 0.533333333333
(9, 0.1, 0.275): 0.666666666667
(9, 1.0, 0.2): 0.866666666667
(9, 1.0, 0.225): 0.933333333333
(9, 1.0, 0.25): 0.533333333333
(9, 1.0, 0.275): 0.666666666667
(9, 1.0, 0.3): 0.733333333333
(9, 10.0, 0.2): 0.866666666667
(9, 10.0, 0.225): 0.933333333333
(9, 10.0, 0.25): 0.866666666667
(9, 10.0, 0.275): 0.666666666667
(9, 10.0, 0.3): 0.733333333333
(9, 100.0, 0.2): 0.866666666667
(9, 100.0, 0.225): 1.0
(9, 100.0, 0.25): 0.866666666667
(9, 100.0, 0.275): 0.666666666667
(9, 100.0, 0.3): 0.733333333333

Loss on all the set for every iteration, for every couple c,sigma (n_of_the_iter, best_c, best_sigma):
(0, 0.1, 0.275): 0.4
(0, 1.0, 0.2): 0.133333333333
(0, 1.0, 0.225): 0.0666666666667
(0, 1.0, 0.25): 0.2
(0, 1.0, 0.275): 0.4
(0, 1.0, 0.3): 0.533333333333
(0, 10.0, 0.2): 0.133333333333
(0, 10.0, 0.225): 0.0666666666667
(0, 10.0, 0.25): 0.2
(0, 10.0, 0.275): 0.4
(0, 10.0, 0.3): 0.533333333333
(0, 100.0, 0.2): 0.0666666666667
(0, 100.0, 0.225): 0.0666666666667
(0, 100.0, 0.25): 0.2
(0, 100.0, 0.275): 0.4
(0, 100.0, 0.3): 0.533333333333
(1, 1.0, 0.2): 0.0
(1, 1.0, 0.225): 0.0
(1, 1.0, 0.25): 0.0
(1, 1.0, 0.275): 0.0666666666667
(1, 1.0, 0.3): 0.133333333333
(1, 10.0, 0.2): 0.0
(1, 10.0, 0.225): 0.333333333333
(1, 10.0, 0.25): 0.0
(1, 10.0, 0.275): 0.0666666666667
(1, 10.0, 0.3): 0.133333333333
(1, 100.0, 0.2): 0.0
(1, 100.0, 0.225): 0.733333333333
(1, 100.0, 0.25): 0.0
(1, 100.0, 0.275): 0.0666666666667
(1, 100.0, 0.3): 0.133333333333
(2, 0.1, 0.3): 0.333333333333
(2, 1.0, 0.2): 0.133333333333
(2, 1.0, 0.225): 0.133333333333
(2, 1.0, 0.25): 0.133333333333
(2, 1.0, 0.275): 0.266666666667
(2, 1.0, 0.3): 0.333333333333
(2, 10.0, 0.2): 0.133333333333
(2, 10.0, 0.225): 0.133333333333
(2, 10.0, 0.25): 0.133333333333
(2, 10.0, 0.275): 0.266666666667
(2, 10.0, 0.3): 0.333333333333
(2, 100.0, 0.2): 0.133333333333
(2, 100.0, 0.225): 0.133333333333
(2, 100.0, 0.25): 0.133333333333
(2, 100.0, 0.275): 0.266666666667
(2, 100.0, 0.3): 0.333333333333
(3, 0.1, 0.25): 0.466666666667
(3, 1.0, 0.2): 0.0666666666667
(3, 1.0, 0.225): 0.0666666666667
(3, 1.0, 0.25): 0.466666666667
(3, 1.0, 0.275): 0.133333333333
(3, 1.0, 0.3): 0.4
(3, 10.0, 0.2): 0.0666666666667
(3, 10.0, 0.225): 0.0666666666667
(3, 10.0, 0.25): 0.466666666667
(3, 10.0, 0.275): 0.2
(3, 10.0, 0.3): 0.4
(3, 100.0, 0.2): 0.0666666666667
(3, 100.0, 0.225): 0.0666666666667
(3, 100.0, 0.25): 0.466666666667
(3, 100.0, 0.275): 0.133333333333
(3, 100.0, 0.3): 0.4
(4, 1.0, 0.2): 0.133333333333
(4, 1.0, 0.225): 0.133333333333
(4, 1.0, 0.25): 0.2
(4, 1.0, 0.275): 0.266666666667
(4, 1.0, 0.3): 0.333333333333
(4, 10.0, 0.2): 0.133333333333
(4, 10.0, 0.225): 0.2
(4, 10.0, 0.25): 0.533333333333
(4, 10.0, 0.275): 0.266666666667
(4, 10.0, 0.3): 0.333333333333
(4, 100.0, 0.2): 0.133333333333
(4, 100.0, 0.225): 0.2
(4, 100.0, 0.25): 0.2
(4, 100.0, 0.275): 0.266666666667
(4, 100.0, 0.3): 0.333333333333
(5, 1.0, 0.2): 0.0666666666667
(5, 1.0, 0.225): 0.0666666666667
(5, 1.0, 0.25): 0.666666666667
(5, 1.0, 0.275): 0.2
(5, 1.0, 0.3): 0.2
(5, 10.0, 0.2): 0.0666666666667
(5, 10.0, 0.225): 0.0666666666667
(5, 10.0, 0.25): 0.0666666666667
(5, 10.0, 0.275): 0.2
(5, 10.0, 0.3): 0.8
(5, 100.0, 0.2): 0.0666666666667
(5, 100.0, 0.225): 0.0666666666667
(5, 100.0, 0.25): 0.0666666666667
(5, 100.0, 0.275): 0.2
(5, 100.0, 0.3): 0.2
(6, 0.1, 0.25): 0.266666666667
(6, 0.1, 0.275): 0.2
(6, 0.1, 0.3): 0.2
(6, 1.0, 0.2): 0.266666666667
(6, 1.0, 0.225): 0.2
(6, 1.0, 0.25): 0.266666666667
(6, 1.0, 0.275): 0.2
(6, 1.0, 0.3): 0.2
(6, 10.0, 0.2): 0.266666666667
(6, 10.0, 0.225): 0.133333333333
(6, 10.0, 0.25): 0.266666666667
(6, 10.0, 0.275): 0.266666666667
(6, 10.0, 0.3): 0.2
(6, 100.0, 0.2): 0.266666666667
(6, 100.0, 0.225): 0.133333333333
(6, 100.0, 0.25): 0.733333333333
(6, 100.0, 0.275): 0.733333333333
(6, 100.0, 0.3): 0.733333333333
(7, 1.0, 0.2): 0.0666666666667
(7, 1.0, 0.225): 0.2
(7, 1.0, 0.25): 0.4
(7, 1.0, 0.275): 0.266666666667
(7, 1.0, 0.3): 0.733333333333
(7, 10.0, 0.2): 0.0666666666667
(7, 10.0, 0.225): 0.2
(7, 10.0, 0.25): 0.4
(7, 10.0, 0.275): 0.266666666667
(7, 10.0, 0.3): 0.466666666667
(7, 100.0, 0.2): 0.0666666666667
(7, 100.0, 0.225): 0.2
(7, 100.0, 0.25): 0.466666666667
(7, 100.0, 0.275): 0.266666666667
(7, 100.0, 0.3): 0.466666666667
(8, 1.0, 0.2): 0.133333333333
(8, 1.0, 0.225): 0.4
(8, 1.0, 0.25): 0.4
(8, 1.0, 0.275): 0.466666666667
(8, 1.0, 0.3): 0.466666666667
(8, 10.0, 0.2): 0.133333333333
(8, 10.0, 0.225): 0.4
(8, 10.0, 0.25): 0.4
(8, 10.0, 0.275): 0.4
(8, 10.0, 0.3): 0.466666666667
(8, 100.0, 0.2): 0.133333333333
(8, 100.0, 0.225): 0.4
(8, 100.0, 0.25): 0.4
(8, 100.0, 0.275): 0.2
(8, 100.0, 0.3): 0.466666666667
(9, 0.1, 0.275): 0.333333333333
(9, 1.0, 0.2): 0.133333333333
(9, 1.0, 0.225): 0.0666666666667
(9, 1.0, 0.25): 0.466666666667
(9, 1.0, 0.275): 0.333333333333
(9, 1.0, 0.3): 0.266666666667
(9, 10.0, 0.2): 0.133333333333
(9, 10.0, 0.225): 0.0666666666667
(9, 10.0, 0.25): 0.133333333333
(9, 10.0, 0.275): 0.333333333333
(9, 10.0, 0.3): 0.266666666667
(9, 100.0, 0.2): 0.133333333333
(9, 100.0, 0.225): 0.0
(9, 100.0, 0.25): 0.133333333333
(9, 100.0, 0.275): 0.333333333333
(9, 100.0, 0.3): 0.266666666667

Accuracy mean :0.7537154989384289
Std deviation :0.17512101493829108
Loss mean :0.24628450106157115
Std deviation :0.17512101493829105



QuantileConstPiecewise_Binary Muzzifier_2dim, number of iterations: 10

Parameters info
Tradeoffs parameter: [  0.1   1.   10.  100. ]
Gaussian kernel sigmas: [0.2   0.225 0.25  0.275 0.3  ]
Number of principal dimension considerated: 2
Dataset length: 150

Clusterization info
Minimum size of a cluster: in perc: 0.01, in int: 2
Type of mu: Binary Muzzifier
Fuzzifier: QuantileConstPiecewise
Cluster to label info
Force the number of cluster to be the number of different labels: False
Force the labels to be always represent by a cluster: False

Validation info
Conflict resolution: random


RESULTS

On TEST set

Accuracy on test set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 100.0, 0.3): 0.733333333333
(1, 10.0, 0.3): 0.6
(2, 10.0, 0.25): 0.6
(3, 10.0, 0.3): 0.866666666667
(4, 10.0, 0.25): 0.533333333333
(5, 10.0, 0.275): 0.6
(6, 1.0, 0.3): 0.6
(7, 10.0, 0.275): 0.6
(8, 100.0, 0.3): 0.533333333333
(9, 10.0, 0.275): 0.6

Loss on test set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 100.0, 0.3): 0.266666666667
(1, 10.0, 0.3): 0.4
(2, 10.0, 0.25): 0.4
(3, 10.0, 0.3): 0.133333333333
(4, 10.0, 0.25): 0.466666666667
(5, 10.0, 0.275): 0.4
(6, 1.0, 0.3): 0.4
(7, 10.0, 0.275): 0.4
(8, 100.0, 0.3): 0.466666666667
(9, 10.0, 0.275): 0.4

Accuracy mean :0.6266666666666667
Std deviation :0.09521904571390467
Loss mean :0.3733333333333334
Std deviation :0.09521904571390467

On TRAINING set

Accuracy on training set for every iteration (n_of_the_iter, c, sigma):
(0, 100.0, 0.3): 0.703703703704
(1, 10.0, 0.3): 0.8
(2, 10.0, 0.25): 0.659259259259
(3, 10.0, 0.3): 0.696296296296
(4, 10.0, 0.25): 0.688888888889
(5, 10.0, 0.275): 0.674074074074
(6, 1.0, 0.3): 0.688888888889
(7, 10.0, 0.275): 0.785185185185
(8, 100.0, 0.3): 0.666666666667
(9, 10.0, 0.275): 0.733333333333
Loss on training set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 100.0, 0.3): 0.296296296296
(1, 10.0, 0.3): 0.2
(2, 10.0, 0.25): 0.340740740741
(3, 10.0, 0.3): 0.303703703704
(4, 10.0, 0.25): 0.311111111111
(5, 10.0, 0.275): 0.325925925926
(6, 1.0, 0.3): 0.311111111111
(7, 10.0, 0.275): 0.214814814815
(8, 100.0, 0.3): 0.333333333333
(9, 10.0, 0.275): 0.266666666667

Accuracy mean :0.7096296296296296
Std deviation :0.04599755465558528
Loss mean :0.2903703703703704
Std deviation :0.04599755465558525

On ALL the sets

Accuracy on all the set for every iteration, for every couple c,sigma (n_of_the_iter, c, sigma):
(0, 1.0, 0.2): 0.466666666667
(0, 1.0, 0.225): 0.6
(0, 1.0, 0.25): 0.533333333333
(0, 1.0, 0.275): 0.733333333333
(0, 1.0, 0.3): 0.733333333333
(0, 10.0, 0.2): 0.4
(0, 10.0, 0.225): 0.466666666667
(0, 10.0, 0.25): 0.666666666667
(0, 10.0, 0.275): 0.666666666667
(0, 10.0, 0.3): 0.266666666667
(0, 100.0, 0.2): 0.6
(0, 100.0, 0.225): 0.533333333333
(0, 100.0, 0.25): 0.533333333333
(0, 100.0, 0.275): 0.733333333333
(0, 100.0, 0.3): 0.733333333333
(1, 0.1, 0.225): 0.6
(1, 1.0, 0.2): 0.466666666667
(1, 1.0, 0.225): 0.266666666667
(1, 1.0, 0.25): 0.8
(1, 1.0, 0.275): 0.6
(1, 1.0, 0.3): 1.0
(1, 10.0, 0.2): 0.266666666667
(1, 10.0, 0.225): 0.933333333333
(1, 10.0, 0.25): 0.933333333333
(1, 10.0, 0.275): 0.733333333333
(1, 10.0, 0.3): 1.0
(1, 100.0, 0.2): 0.0666666666667
(1, 100.0, 0.225): 0.533333333333
(1, 100.0, 0.25): 0.8
(1, 100.0, 0.275): 0.733333333333
(1, 100.0, 0.3): 1.0
(2, 1.0, 0.2): 0.466666666667
(2, 1.0, 0.225): 0.4
(2, 1.0, 0.25): 0.733333333333
(2, 1.0, 0.275): 0.8
(2, 1.0, 0.3): 0.666666666667
(2, 10.0, 0.2): 0.4
(2, 10.0, 0.225): 0.733333333333
(2, 10.0, 0.25): 0.8
(2, 10.0, 0.275): 0.666666666667
(2, 10.0, 0.3): 0.666666666667
(2, 100.0, 0.2): 0.533333333333
(2, 100.0, 0.225): 0.733333333333
(2, 100.0, 0.25): 0.533333333333
(2, 100.0, 0.275): 0.266666666667
(2, 100.0, 0.3): 0.666666666667
(3, 1.0, 0.2): 0.266666666667
(3, 1.0, 0.225): 0.4
(3, 1.0, 0.25): 0.666666666667
(3, 1.0, 0.275): 0.666666666667
(3, 1.0, 0.3): 0.4
(3, 10.0, 0.2): 0.266666666667
(3, 10.0, 0.225): 0.666666666667
(3, 10.0, 0.25): 0.666666666667
(3, 10.0, 0.275): 0.6
(3, 10.0, 0.3): 0.8
(3, 100.0, 0.2): 0.333333333333
(3, 100.0, 0.225): 0.6
(3, 100.0, 0.25): 0.733333333333
(3, 100.0, 0.275): 0.666666666667
(3, 100.0, 0.3): 0.8
(4, 1.0, 0.2): 0.533333333333
(4, 1.0, 0.225): 0.666666666667
(4, 1.0, 0.25): 0.666666666667
(4, 1.0, 0.275): 0.533333333333
(4, 1.0, 0.3): 0.2
(4, 10.0, 0.2): 0.333333333333
(4, 10.0, 0.225): 0.533333333333
(4, 10.0, 0.25): 0.866666666667
(4, 10.0, 0.275): 0.6
(4, 10.0, 0.3): 0.333333333333
(4, 100.0, 0.2): 0.666666666667
(4, 100.0, 0.225): 0.666666666667
(4, 100.0, 0.25): 0.533333333333
(4, 100.0, 0.275): 0.6
(4, 100.0, 0.3): 0.466666666667
(5, 0.1, 0.3): 0.866666666667
(5, 1.0, 0.2): 0.666666666667
(5, 1.0, 0.225): 0.666666666667
(5, 1.0, 0.25): 0.6
(5, 1.0, 0.275): 0.866666666667
(5, 1.0, 0.3): 0.866666666667
(5, 10.0, 0.2): 0.466666666667
(5, 10.0, 0.225): 0.266666666667
(5, 10.0, 0.25): 0.6
(5, 10.0, 0.275): 0.866666666667
(5, 10.0, 0.3): 0.8
(5, 100.0, 0.2): 0.6
(5, 100.0, 0.225): 0.4
(5, 100.0, 0.25): 0.666666666667
(5, 100.0, 0.275): 0.8
(5, 100.0, 0.3): 0.866666666667
(6, 1.0, 0.2): 0.6
(6, 1.0, 0.225): 0.733333333333
(6, 1.0, 0.25): 0.666666666667
(6, 1.0, 0.275): 0.6
(6, 1.0, 0.3): 0.866666666667
(6, 10.0, 0.2): 0.533333333333
(6, 10.0, 0.225): 0.6
(6, 10.0, 0.25): 0.666666666667
(6, 10.0, 0.275): 0.6
(6, 10.0, 0.3): 0.8
(6, 100.0, 0.2): 0.4
(6, 100.0, 0.225): 0.6
(6, 100.0, 0.25): 0.333333333333
(6, 100.0, 0.275): 0.533333333333
(6, 100.0, 0.3): 0.733333333333
(7, 1.0, 0.2): 0.533333333333
(7, 1.0, 0.225): 0.133333333333
(7, 1.0, 0.25): 0.6
(7, 1.0, 0.275): 1.0
(7, 1.0, 0.3): 0.866666666667
(7, 10.0, 0.2): 0.466666666667
(7, 10.0, 0.225): 0.133333333333
(7, 10.0, 0.25): 0.933333333333
(7, 10.0, 0.275): 1.0
(7, 10.0, 0.3): 0.866666666667
(7, 100.0, 0.2): 0.666666666667
(7, 100.0, 0.225): 0.466666666667
(7, 100.0, 0.25): 0.866666666667
(7, 100.0, 0.275): 0.866666666667
(7, 100.0, 0.3): 0.933333333333
(8, 1.0, 0.2): 0.266666666667
(8, 1.0, 0.225): 0.6
(8, 1.0, 0.25): 0.533333333333
(8, 1.0, 0.275): 0.733333333333
(8, 1.0, 0.3): 0.666666666667
(8, 10.0, 0.2): 0.266666666667
(8, 10.0, 0.225): 0.733333333333
(8, 10.0, 0.25): 0.733333333333
(8, 10.0, 0.275): 0.733333333333
(8, 10.0, 0.3): 0.666666666667
(8, 100.0, 0.2): 0.266666666667
(8, 100.0, 0.225): 0.466666666667
(8, 100.0, 0.25): 0.6
(8, 100.0, 0.275): 0.733333333333
(8, 100.0, 0.3): 0.8
(9, 0.1, 0.275): 0.4
(9, 0.1, 0.3): 0.466666666667
(9, 1.0, 0.2): 0.266666666667
(9, 1.0, 0.225): 0.733333333333
(9, 1.0, 0.25): 0.666666666667
(9, 1.0, 0.275): 0.6
(9, 1.0, 0.3): 0.466666666667
(9, 10.0, 0.2): 0.4
(9, 10.0, 0.225): 0.6
(9, 10.0, 0.25): 0.6
(9, 10.0, 0.275): 0.8
(9, 10.0, 0.3): 0.466666666667
(9, 100.0, 0.2): 0.8
(9, 100.0, 0.225): 0.266666666667
(9, 100.0, 0.25): 0.466666666667
(9, 100.0, 0.275): 0.6
(9, 100.0, 0.3): 0.466666666667

Loss on all the set for every iteration, for every couple c,sigma (n_of_the_iter, best_c, best_sigma):
(0, 1.0, 0.2): 0.533333333333
(0, 1.0, 0.225): 0.4
(0, 1.0, 0.25): 0.466666666667
(0, 1.0, 0.275): 0.266666666667
(0, 1.0, 0.3): 0.266666666667
(0, 10.0, 0.2): 0.6
(0, 10.0, 0.225): 0.533333333333
(0, 10.0, 0.25): 0.333333333333
(0, 10.0, 0.275): 0.333333333333
(0, 10.0, 0.3): 0.733333333333
(0, 100.0, 0.2): 0.4
(0, 100.0, 0.225): 0.466666666667
(0, 100.0, 0.25): 0.466666666667
(0, 100.0, 0.275): 0.266666666667
(0, 100.0, 0.3): 0.266666666667
(1, 0.1, 0.225): 0.4
(1, 1.0, 0.2): 0.533333333333
(1, 1.0, 0.225): 0.733333333333
(1, 1.0, 0.25): 0.2
(1, 1.0, 0.275): 0.4
(1, 1.0, 0.3): 0.0
(1, 10.0, 0.2): 0.733333333333
(1, 10.0, 0.225): 0.0666666666667
(1, 10.0, 0.25): 0.0666666666667
(1, 10.0, 0.275): 0.266666666667
(1, 10.0, 0.3): 0.0
(1, 100.0, 0.2): 0.933333333333
(1, 100.0, 0.225): 0.466666666667
(1, 100.0, 0.25): 0.2
(1, 100.0, 0.275): 0.266666666667
(1, 100.0, 0.3): 0.0
(2, 1.0, 0.2): 0.533333333333
(2, 1.0, 0.225): 0.6
(2, 1.0, 0.25): 0.266666666667
(2, 1.0, 0.275): 0.2
(2, 1.0, 0.3): 0.333333333333
(2, 10.0, 0.2): 0.6
(2, 10.0, 0.225): 0.266666666667
(2, 10.0, 0.25): 0.2
(2, 10.0, 0.275): 0.333333333333
(2, 10.0, 0.3): 0.333333333333
(2, 100.0, 0.2): 0.466666666667
(2, 100.0, 0.225): 0.266666666667
(2, 100.0, 0.25): 0.466666666667
(2, 100.0, 0.275): 0.733333333333
(2, 100.0, 0.3): 0.333333333333
(3, 1.0, 0.2): 0.733333333333
(3, 1.0, 0.225): 0.6
(3, 1.0, 0.25): 0.333333333333
(3, 1.0, 0.275): 0.333333333333
(3, 1.0, 0.3): 0.6
(3, 10.0, 0.2): 0.733333333333
(3, 10.0, 0.225): 0.333333333333
(3, 10.0, 0.25): 0.333333333333
(3, 10.0, 0.275): 0.4
(3, 10.0, 0.3): 0.2
(3, 100.0, 0.2): 0.666666666667
(3, 100.0, 0.225): 0.4
(3, 100.0, 0.25): 0.266666666667
(3, 100.0, 0.275): 0.333333333333
(3, 100.0, 0.3): 0.2
(4, 1.0, 0.2): 0.466666666667
(4, 1.0, 0.225): 0.333333333333
(4, 1.0, 0.25): 0.333333333333
(4, 1.0, 0.275): 0.466666666667
(4, 1.0, 0.3): 0.8
(4, 10.0, 0.2): 0.666666666667
(4, 10.0, 0.225): 0.466666666667
(4, 10.0, 0.25): 0.133333333333
(4, 10.0, 0.275): 0.4
(4, 10.0, 0.3): 0.666666666667
(4, 100.0, 0.2): 0.333333333333
(4, 100.0, 0.225): 0.333333333333
(4, 100.0, 0.25): 0.466666666667
(4, 100.0, 0.275): 0.4
(4, 100.0, 0.3): 0.533333333333
(5, 0.1, 0.3): 0.133333333333
(5, 1.0, 0.2): 0.333333333333
(5, 1.0, 0.225): 0.333333333333
(5, 1.0, 0.25): 0.4
(5, 1.0, 0.275): 0.133333333333
(5, 1.0, 0.3): 0.133333333333
(5, 10.0, 0.2): 0.533333333333
(5, 10.0, 0.225): 0.733333333333
(5, 10.0, 0.25): 0.4
(5, 10.0, 0.275): 0.133333333333
(5, 10.0, 0.3): 0.2
(5, 100.0, 0.2): 0.4
(5, 100.0, 0.225): 0.6
(5, 100.0, 0.25): 0.333333333333
(5, 100.0, 0.275): 0.2
(5, 100.0, 0.3): 0.133333333333
(6, 1.0, 0.2): 0.4
(6, 1.0, 0.225): 0.266666666667
(6, 1.0, 0.25): 0.333333333333
(6, 1.0, 0.275): 0.4
(6, 1.0, 0.3): 0.133333333333
(6, 10.0, 0.2): 0.466666666667
(6, 10.0, 0.225): 0.4
(6, 10.0, 0.25): 0.333333333333
(6, 10.0, 0.275): 0.4
(6, 10.0, 0.3): 0.2
(6, 100.0, 0.2): 0.6
(6, 100.0, 0.225): 0.4
(6, 100.0, 0.25): 0.666666666667
(6, 100.0, 0.275): 0.466666666667
(6, 100.0, 0.3): 0.266666666667
(7, 1.0, 0.2): 0.466666666667
(7, 1.0, 0.225): 0.866666666667
(7, 1.0, 0.25): 0.4
(7, 1.0, 0.275): 0.0
(7, 1.0, 0.3): 0.133333333333
(7, 10.0, 0.2): 0.533333333333
(7, 10.0, 0.225): 0.866666666667
(7, 10.0, 0.25): 0.0666666666667
(7, 10.0, 0.275): 0.0
(7, 10.0, 0.3): 0.133333333333
(7, 100.0, 0.2): 0.333333333333
(7, 100.0, 0.225): 0.533333333333
(7, 100.0, 0.25): 0.133333333333
(7, 100.0, 0.275): 0.133333333333
(7, 100.0, 0.3): 0.0666666666667
(8, 1.0, 0.2): 0.733333333333
(8, 1.0, 0.225): 0.4
(8, 1.0, 0.25): 0.466666666667
(8, 1.0, 0.275): 0.266666666667
(8, 1.0, 0.3): 0.333333333333
(8, 10.0, 0.2): 0.733333333333
(8, 10.0, 0.225): 0.266666666667
(8, 10.0, 0.25): 0.266666666667
(8, 10.0, 0.275): 0.266666666667
(8, 10.0, 0.3): 0.333333333333
(8, 100.0, 0.2): 0.733333333333
(8, 100.0, 0.225): 0.533333333333
(8, 100.0, 0.25): 0.4
(8, 100.0, 0.275): 0.266666666667
(8, 100.0, 0.3): 0.2
(9, 0.1, 0.275): 0.6
(9, 0.1, 0.3): 0.533333333333
(9, 1.0, 0.2): 0.733333333333
(9, 1.0, 0.225): 0.266666666667
(9, 1.0, 0.25): 0.333333333333
(9, 1.0, 0.275): 0.4
(9, 1.0, 0.3): 0.533333333333
(9, 10.0, 0.2): 0.6
(9, 10.0, 0.225): 0.4
(9, 10.0, 0.25): 0.4
(9, 10.0, 0.275): 0.2
(9, 10.0, 0.3): 0.533333333333
(9, 100.0, 0.2): 0.2
(9, 100.0, 0.225): 0.733333333333
(9, 100.0, 0.25): 0.533333333333
(9, 100.0, 0.275): 0.4
(9, 100.0, 0.3): 0.533333333333

Accuracy mean :0.6073593073593073
Std deviation :0.19892375479065055
Loss mean :0.3926406926406927
Std deviation :0.19892375479065055



Crisp_Linear Muzzifier_2dim, number of iterations: 10

Parameters info
Tradeoffs parameter: [  0.1   1.   10.  100. ]
Gaussian kernel sigmas: [0.2   0.225 0.25  0.275 0.3  ]
Number of principal dimension considerated: 2
Dataset length: 150

Clusterization info
Minimum size of a cluster: in perc: 0.01, in int: 2
Type of mu: Linear Muzzifier
Fuzzifier: Crisp
Cluster to label info
Force the number of cluster to be the number of different labels: False
Force the labels to be always represent by a cluster: False

Validation info
Conflict resolution: random


RESULTS

On TEST set

Accuracy on test set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 100.0, 0.25): 0.466666666667
(1, 10.0, 0.225): 0.533333333333
(2, 10.0, 0.275): 0.4
(3, 1.0, 0.3): 0.466666666667
(4, 1.0, 0.2): 0.466666666667
(5, 1.0, 0.2): 0.466666666667
(6, 100.0, 0.25): 0.333333333333
(7, 1.0, 0.25): 0.4
(8, 10.0, 0.3): 0.2
(9, 10.0, 0.25): 0.533333333333

Loss on test set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 100.0, 0.25): 0.533333333333
(1, 10.0, 0.225): 0.466666666667
(2, 10.0, 0.275): 0.6
(3, 1.0, 0.3): 0.533333333333
(4, 1.0, 0.2): 0.533333333333
(5, 1.0, 0.2): 0.533333333333
(6, 100.0, 0.25): 0.666666666667
(7, 1.0, 0.25): 0.6
(8, 10.0, 0.3): 0.8
(9, 10.0, 0.25): 0.466666666667

Accuracy mean :0.42666666666666675
Std deviation :0.09521904571390466
Loss mean :0.5733333333333333
Std deviation :0.09521904571390467

On TRAINING set

Accuracy on training set for every iteration (n_of_the_iter, c, sigma):
(0, 100.0, 0.25): 0.555555555556
(1, 10.0, 0.225): 0.696296296296
(2, 10.0, 0.275): 0.674074074074
(3, 1.0, 0.3): 0.637037037037
(4, 1.0, 0.2): 0.62962962963
(5, 1.0, 0.2): 0.577777777778
(6, 100.0, 0.25): 0.644444444444
(7, 1.0, 0.25): 0.577777777778
(8, 10.0, 0.3): 0.592592592593
(9, 10.0, 0.25): 0.562962962963
Loss on training set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 100.0, 0.25): 0.444444444444
(1, 10.0, 0.225): 0.303703703704
(2, 10.0, 0.275): 0.325925925926
(3, 1.0, 0.3): 0.362962962963
(4, 1.0, 0.2): 0.37037037037
(5, 1.0, 0.2): 0.422222222222
(6, 100.0, 0.25): 0.355555555556
(7, 1.0, 0.25): 0.422222222222
(8, 10.0, 0.3): 0.407407407407
(9, 10.0, 0.25): 0.437037037037

Accuracy mean :0.6148148148148148
Std deviation :0.046021406124471316
Loss mean :0.3851851851851852
Std deviation :0.046021406124471295

On ALL the sets

Accuracy on all the set for every iteration, for every couple c,sigma (n_of_the_iter, c, sigma):
(0, 1.0, 0.2): 0.333333333333
(0, 1.0, 0.225): 0.333333333333
(0, 1.0, 0.25): 0.666666666667
(0, 1.0, 0.275): 0.6
(0, 1.0, 0.3): 0.466666666667
(0, 10.0, 0.2): 0.533333333333
(0, 10.0, 0.225): 0.333333333333
(0, 10.0, 0.25): 0.466666666667
(0, 10.0, 0.275): 0.466666666667
(0, 10.0, 0.3): 0.533333333333
(0, 100.0, 0.2): 0.333333333333
(0, 100.0, 0.225): 0.533333333333
(0, 100.0, 0.25): 0.733333333333
(0, 100.0, 0.275): 0.466666666667
(0, 100.0, 0.3): 0.466666666667
(1, 1.0, 0.2): 0.466666666667
(1, 1.0, 0.225): 0.6
(1, 1.0, 0.25): 0.533333333333
(1, 1.0, 0.275): 0.6
(1, 1.0, 0.3): 0.733333333333
(1, 10.0, 0.2): 0.533333333333
(1, 10.0, 0.225): 0.733333333333
(1, 10.0, 0.25): 0.466666666667
(1, 10.0, 0.275): 0.466666666667
(1, 10.0, 0.3): 0.466666666667
(1, 100.0, 0.2): 0.533333333333
(1, 100.0, 0.225): 0.666666666667
(1, 100.0, 0.25): 0.533333333333
(1, 100.0, 0.275): 0.466666666667
(1, 100.0, 0.3): 0.6
(2, 1.0, 0.225): 0.533333333333
(2, 1.0, 0.25): 0.133333333333
(2, 1.0, 0.275): 0.6
(2, 1.0, 0.3): 0.466666666667
(2, 10.0, 0.2): 0.133333333333
(2, 10.0, 0.225): 0.466666666667
(2, 10.0, 0.25): 0.333333333333
(2, 10.0, 0.275): 0.8
(2, 10.0, 0.3): 0.4
(2, 100.0, 0.2): 0.133333333333
(2, 100.0, 0.225): 0.666666666667
(2, 100.0, 0.25): 0.133333333333
(2, 100.0, 0.275): 0.466666666667
(2, 100.0, 0.3): 0.4
(3, 1.0, 0.2): 0.6
(3, 1.0, 0.225): 0.8
(3, 1.0, 0.25): 0.533333333333
(3, 1.0, 0.275): 0.533333333333
(3, 1.0, 0.3): 0.8
(3, 10.0, 0.2): 0.6
(3, 10.0, 0.225): 0.6
(3, 10.0, 0.25): 0.533333333333
(3, 10.0, 0.275): 0.6
(3, 10.0, 0.3): 0.6
(3, 100.0, 0.2): 0.6
(3, 100.0, 0.225): 0.6
(3, 100.0, 0.25): 0.666666666667
(3, 100.0, 0.275): 0.533333333333
(3, 100.0, 0.3): 0.466666666667
(4, 1.0, 0.2): 0.8
(4, 1.0, 0.225): 0.8
(4, 1.0, 0.25): 0.6
(4, 1.0, 0.275): 0.733333333333
(4, 1.0, 0.3): 0.6
(4, 10.0, 0.2): 0.533333333333
(4, 10.0, 0.225): 0.666666666667
(4, 10.0, 0.25): 0.6
(4, 10.0, 0.275): 0.533333333333
(4, 10.0, 0.3): 0.533333333333
(4, 100.0, 0.2): 0.6
(4, 100.0, 0.225): 0.666666666667
(4, 100.0, 0.25): 0.666666666667
(4, 100.0, 0.275): 0.466666666667
(4, 100.0, 0.3): 0.533333333333
(5, 1.0, 0.2): 0.6
(5, 1.0, 0.225): 0.333333333333
(5, 1.0, 0.25): 0.6
(5, 1.0, 0.275): 0.4
(5, 1.0, 0.3): 0.533333333333
(5, 10.0, 0.2): 0.533333333333
(5, 10.0, 0.225): 0.333333333333
(5, 10.0, 0.25): 0.4
(5, 10.0, 0.275): 0.4
(5, 10.0, 0.3): 0.533333333333
(5, 100.0, 0.2): 0.6
(5, 100.0, 0.225): 0.466666666667
(5, 100.0, 0.25): 0.4
(5, 100.0, 0.275): 0.533333333333
(5, 100.0, 0.3): 0.6
(6, 0.1, 0.3): 0.533333333333
(6, 1.0, 0.2): 0.333333333333
(6, 1.0, 0.225): 0.466666666667
(6, 1.0, 0.25): 0.6
(6, 1.0, 0.275): 0.533333333333
(6, 1.0, 0.3): 0.533333333333
(6, 10.0, 0.2): 0.333333333333
(6, 10.0, 0.225): 0.466666666667
(6, 10.0, 0.25): 0.6
(6, 10.0, 0.275): 0.466666666667
(6, 10.0, 0.3): 0.666666666667
(6, 100.0, 0.2): 0.333333333333
(6, 100.0, 0.225): 0.466666666667
(6, 100.0, 0.25): 0.666666666667
(6, 100.0, 0.275): 0.6
(6, 100.0, 0.3): 0.533333333333
(7, 1.0, 0.2): 0.333333333333
(7, 1.0, 0.225): 0.6
(7, 1.0, 0.25): 0.733333333333
(7, 1.0, 0.275): 0.4
(7, 1.0, 0.3): 0.533333333333
(7, 10.0, 0.2): 0.4
(7, 10.0, 0.225): 0.333333333333
(7, 10.0, 0.25): 0.2
(7, 10.0, 0.275): 0.466666666667
(7, 10.0, 0.3): 0.533333333333
(7, 100.0, 0.2): 0.4
(7, 100.0, 0.225): 0.466666666667
(7, 100.0, 0.25): 0.6
(7, 100.0, 0.275): 0.533333333333
(7, 100.0, 0.3): 0.533333333333
(8, 1.0, 0.2): 0.466666666667
(8, 1.0, 0.225): 0.466666666667
(8, 1.0, 0.25): 0.266666666667
(8, 1.0, 0.275): 0.6
(8, 1.0, 0.3): 0.533333333333
(8, 10.0, 0.2): 0.533333333333
(8, 10.0, 0.225): 0.466666666667
(8, 10.0, 0.25): 0.266666666667
(8, 10.0, 0.275): 0.4
(8, 10.0, 0.3): 0.733333333333
(8, 100.0, 0.2): 0.466666666667
(8, 100.0, 0.225): 0.6
(8, 100.0, 0.25): 0.2
(8, 100.0, 0.275): 0.4
(8, 100.0, 0.3): 0.6
(9, 1.0, 0.2): 0.533333333333
(9, 1.0, 0.225): 0.466666666667
(9, 1.0, 0.25): 0.733333333333
(9, 1.0, 0.275): 0.733333333333
(9, 1.0, 0.3): 0.666666666667
(9, 10.0, 0.2): 0.666666666667
(9, 10.0, 0.225): 0.666666666667
(9, 10.0, 0.25): 0.8
(9, 10.0, 0.275): 0.6
(9, 10.0, 0.3): 0.466666666667
(9, 100.0, 0.2): 0.733333333333
(9, 100.0, 0.225): 0.733333333333
(9, 100.0, 0.25): 0.666666666667
(9, 100.0, 0.275): 0.533333333333
(9, 100.0, 0.3): 0.533333333333

Loss on all the set for every iteration, for every couple c,sigma (n_of_the_iter, best_c, best_sigma):
(0, 1.0, 0.2): 0.666666666667
(0, 1.0, 0.225): 0.666666666667
(0, 1.0, 0.25): 0.333333333333
(0, 1.0, 0.275): 0.4
(0, 1.0, 0.3): 0.533333333333
(0, 10.0, 0.2): 0.466666666667
(0, 10.0, 0.225): 0.666666666667
(0, 10.0, 0.25): 0.533333333333
(0, 10.0, 0.275): 0.533333333333
(0, 10.0, 0.3): 0.466666666667
(0, 100.0, 0.2): 0.666666666667
(0, 100.0, 0.225): 0.466666666667
(0, 100.0, 0.25): 0.266666666667
(0, 100.0, 0.275): 0.533333333333
(0, 100.0, 0.3): 0.533333333333
(1, 1.0, 0.2): 0.533333333333
(1, 1.0, 0.225): 0.4
(1, 1.0, 0.25): 0.466666666667
(1, 1.0, 0.275): 0.4
(1, 1.0, 0.3): 0.266666666667
(1, 10.0, 0.2): 0.466666666667
(1, 10.0, 0.225): 0.266666666667
(1, 10.0, 0.25): 0.533333333333
(1, 10.0, 0.275): 0.533333333333
(1, 10.0, 0.3): 0.533333333333
(1, 100.0, 0.2): 0.466666666667
(1, 100.0, 0.225): 0.333333333333
(1, 100.0, 0.25): 0.466666666667
(1, 100.0, 0.275): 0.533333333333
(1, 100.0, 0.3): 0.4
(2, 1.0, 0.225): 0.466666666667
(2, 1.0, 0.25): 0.866666666667
(2, 1.0, 0.275): 0.4
(2, 1.0, 0.3): 0.533333333333
(2, 10.0, 0.2): 0.866666666667
(2, 10.0, 0.225): 0.533333333333
(2, 10.0, 0.25): 0.666666666667
(2, 10.0, 0.275): 0.2
(2, 10.0, 0.3): 0.6
(2, 100.0, 0.2): 0.866666666667
(2, 100.0, 0.225): 0.333333333333
(2, 100.0, 0.25): 0.866666666667
(2, 100.0, 0.275): 0.533333333333
(2, 100.0, 0.3): 0.6
(3, 1.0, 0.2): 0.4
(3, 1.0, 0.225): 0.2
(3, 1.0, 0.25): 0.466666666667
(3, 1.0, 0.275): 0.466666666667
(3, 1.0, 0.3): 0.2
(3, 10.0, 0.2): 0.4
(3, 10.0, 0.225): 0.4
(3, 10.0, 0.25): 0.466666666667
(3, 10.0, 0.275): 0.4
(3, 10.0, 0.3): 0.4
(3, 100.0, 0.2): 0.4
(3, 100.0, 0.225): 0.4
(3, 100.0, 0.25): 0.333333333333
(3, 100.0, 0.275): 0.466666666667
(3, 100.0, 0.3): 0.533333333333
(4, 1.0, 0.2): 0.2
(4, 1.0, 0.225): 0.2
(4, 1.0, 0.25): 0.4
(4, 1.0, 0.275): 0.266666666667
(4, 1.0, 0.3): 0.4
(4, 10.0, 0.2): 0.466666666667
(4, 10.0, 0.225): 0.333333333333
(4, 10.0, 0.25): 0.4
(4, 10.0, 0.275): 0.466666666667
(4, 10.0, 0.3): 0.466666666667
(4, 100.0, 0.2): 0.4
(4, 100.0, 0.225): 0.333333333333
(4, 100.0, 0.25): 0.333333333333
(4, 100.0, 0.275): 0.533333333333
(4, 100.0, 0.3): 0.466666666667
(5, 1.0, 0.2): 0.4
(5, 1.0, 0.225): 0.666666666667
(5, 1.0, 0.25): 0.4
(5, 1.0, 0.275): 0.6
(5, 1.0, 0.3): 0.466666666667
(5, 10.0, 0.2): 0.466666666667
(5, 10.0, 0.225): 0.666666666667
(5, 10.0, 0.25): 0.6
(5, 10.0, 0.275): 0.6
(5, 10.0, 0.3): 0.466666666667
(5, 100.0, 0.2): 0.4
(5, 100.0, 0.225): 0.533333333333
(5, 100.0, 0.25): 0.6
(5, 100.0, 0.275): 0.466666666667
(5, 100.0, 0.3): 0.4
(6, 0.1, 0.3): 0.466666666667
(6, 1.0, 0.2): 0.666666666667
(6, 1.0, 0.225): 0.533333333333
(6, 1.0, 0.25): 0.4
(6, 1.0, 0.275): 0.466666666667
(6, 1.0, 0.3): 0.466666666667
(6, 10.0, 0.2): 0.666666666667
(6, 10.0, 0.225): 0.533333333333
(6, 10.0, 0.25): 0.4
(6, 10.0, 0.275): 0.533333333333
(6, 10.0, 0.3): 0.333333333333
(6, 100.0, 0.2): 0.666666666667
(6, 100.0, 0.225): 0.533333333333
(6, 100.0, 0.25): 0.333333333333
(6, 100.0, 0.275): 0.4
(6, 100.0, 0.3): 0.466666666667
(7, 1.0, 0.2): 0.666666666667
(7, 1.0, 0.225): 0.4
(7, 1.0, 0.25): 0.266666666667
(7, 1.0, 0.275): 0.6
(7, 1.0, 0.3): 0.466666666667
(7, 10.0, 0.2): 0.6
(7, 10.0, 0.225): 0.666666666667
(7, 10.0, 0.25): 0.8
(7, 10.0, 0.275): 0.533333333333
(7, 10.0, 0.3): 0.466666666667
(7, 100.0, 0.2): 0.6
(7, 100.0, 0.225): 0.533333333333
(7, 100.0, 0.25): 0.4
(7, 100.0, 0.275): 0.466666666667
(7, 100.0, 0.3): 0.466666666667
(8, 1.0, 0.2): 0.533333333333
(8, 1.0, 0.225): 0.533333333333
(8, 1.0, 0.25): 0.733333333333
(8, 1.0, 0.275): 0.4
(8, 1.0, 0.3): 0.466666666667
(8, 10.0, 0.2): 0.466666666667
(8, 10.0, 0.225): 0.533333333333
(8, 10.0, 0.25): 0.733333333333
(8, 10.0, 0.275): 0.6
(8, 10.0, 0.3): 0.266666666667
(8, 100.0, 0.2): 0.533333333333
(8, 100.0, 0.225): 0.4
(8, 100.0, 0.25): 0.8
(8, 100.0, 0.275): 0.6
(8, 100.0, 0.3): 0.4
(9, 1.0, 0.2): 0.466666666667
(9, 1.0, 0.225): 0.533333333333
(9, 1.0, 0.25): 0.266666666667
(9, 1.0, 0.275): 0.266666666667
(9, 1.0, 0.3): 0.333333333333
(9, 10.0, 0.2): 0.333333333333
(9, 10.0, 0.225): 0.333333333333
(9, 10.0, 0.25): 0.2
(9, 10.0, 0.275): 0.4
(9, 10.0, 0.3): 0.533333333333
(9, 100.0, 0.2): 0.266666666667
(9, 100.0, 0.225): 0.266666666667
(9, 100.0, 0.25): 0.333333333333
(9, 100.0, 0.275): 0.466666666667
(9, 100.0, 0.3): 0.466666666667

Accuracy mean :0.5248888888888888
Std deviation :0.1409589731048202
Loss mean :0.4751111111111111
Std deviation :0.14095897310482022



Linear_Linear Muzzifier_2dim, number of iterations: 10

Parameters info
Tradeoffs parameter: [  0.1   1.   10.  100. ]
Gaussian kernel sigmas: [0.2   0.225 0.25  0.275 0.3  ]
Number of principal dimension considerated: 2
Dataset length: 150

Clusterization info
Minimum size of a cluster: in perc: 0.01, in int: 2
Type of mu: Linear Muzzifier
Fuzzifier: Linear
Cluster to label info
Force the number of cluster to be the number of different labels: False
Force the labels to be always represent by a cluster: False

Validation info
Conflict resolution: random


RESULTS

On TEST set

Accuracy on test set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 10.0, 0.2): 0.933333333333
(1, 1.0, 0.225): 0.866666666667
(2, 1.0, 0.275): 0.666666666667
(3, 10.0, 0.2): 0.933333333333
(4, 10.0, 0.25): 0.666666666667
(5, 100.0, 0.225): 0.933333333333
(6, 1.0, 0.225): 0.866666666667
(7, 100.0, 0.25): 0.133333333333
(8, 100.0, 0.2): 0.733333333333
(9, 10.0, 0.25): 0.933333333333

Loss on test set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 10.0, 0.2): 0.0666666666667
(1, 1.0, 0.225): 0.133333333333
(2, 1.0, 0.275): 0.333333333333
(3, 10.0, 0.2): 0.0666666666667
(4, 10.0, 0.25): 0.333333333333
(5, 100.0, 0.225): 0.0666666666667
(6, 1.0, 0.225): 0.133333333333
(7, 100.0, 0.25): 0.866666666667
(8, 100.0, 0.2): 0.266666666667
(9, 10.0, 0.25): 0.0666666666667

Accuracy mean :0.7666666666666667
Std deviation :0.23523038352503137
Loss mean :0.23333333333333334
Std deviation :0.23523038352503134

On TRAINING set

Accuracy on training set for every iteration (n_of_the_iter, c, sigma):
(0, 10.0, 0.2): 0.911111111111
(1, 1.0, 0.225): 0.881481481481
(2, 1.0, 0.275): 0.659259259259
(3, 10.0, 0.2): 0.859259259259
(4, 10.0, 0.25): 0.666666666667
(5, 100.0, 0.225): 0.859259259259
(6, 1.0, 0.225): 0.874074074074
(7, 100.0, 0.25): 0.37037037037
(8, 100.0, 0.2): 0.696296296296
(9, 10.0, 0.25): 0.8
Loss on training set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 10.0, 0.2): 0.0888888888889
(1, 1.0, 0.225): 0.118518518519
(2, 1.0, 0.275): 0.340740740741
(3, 10.0, 0.2): 0.140740740741
(4, 10.0, 0.25): 0.333333333333
(5, 100.0, 0.225): 0.140740740741
(6, 1.0, 0.225): 0.125925925926
(7, 100.0, 0.25): 0.62962962963
(8, 100.0, 0.2): 0.303703703704
(9, 10.0, 0.25): 0.2

Accuracy mean :0.7577777777777778
Std deviation :0.15703179585942706
Loss mean :0.2422222222222222
Std deviation :0.15703179585942703

On ALL the sets

Accuracy on all the set for every iteration, for every couple c,sigma (n_of_the_iter, c, sigma):
(0, 1.0, 0.2): 0.866666666667
(0, 1.0, 0.225): 0.8
(0, 1.0, 0.25): 0.733333333333
(0, 1.0, 0.275): 0.6
(0, 1.0, 0.3): 0.666666666667
(0, 10.0, 0.2): 0.933333333333
(0, 10.0, 0.225): 0.8
(0, 10.0, 0.25): 0.266666666667
(0, 10.0, 0.275): 0.466666666667
(0, 10.0, 0.3): 0.533333333333
(0, 100.0, 0.2): 0.866666666667
(0, 100.0, 0.225): 0.666666666667
(0, 100.0, 0.25): 0.666666666667
(0, 100.0, 0.275): 0.4
(0, 100.0, 0.3): 0.533333333333
(1, 1.0, 0.2): 0.8
(1, 1.0, 0.225): 1.0
(1, 1.0, 0.25): 0.466666666667
(1, 1.0, 0.275): 0.466666666667
(1, 1.0, 0.3): 0.8
(1, 10.0, 0.2): 0.8
(1, 10.0, 0.225): 0.8
(1, 10.0, 0.25): 0.466666666667
(1, 10.0, 0.275): 0.466666666667
(1, 10.0, 0.3): 0.8
(1, 100.0, 0.2): 0.8
(1, 100.0, 0.225): 0.866666666667
(1, 100.0, 0.25): 0.466666666667
(1, 100.0, 0.275): 0.733333333333
(1, 100.0, 0.3): 0.8
(2, 1.0, 0.2): 0.666666666667
(2, 1.0, 0.225): 0.8
(2, 1.0, 0.25): 0.6
(2, 1.0, 0.275): 0.866666666667
(2, 1.0, 0.3): 0.8
(2, 10.0, 0.2): 0.666666666667
(2, 10.0, 0.225): 0.666666666667
(2, 10.0, 0.25): 0.266666666667
(2, 10.0, 0.275): 0.6
(2, 10.0, 0.3): 0.733333333333
(2, 100.0, 0.2): 0.733333333333
(2, 100.0, 0.225): 0.666666666667
(2, 100.0, 0.25): 0.266666666667
(2, 100.0, 0.275): 0.666666666667
(2, 100.0, 0.3): 0.533333333333
(3, 1.0, 0.2): 0.933333333333
(3, 1.0, 0.225): 0.666666666667
(3, 1.0, 0.25): 0.733333333333
(3, 1.0, 0.275): 0.666666666667
(3, 1.0, 0.3): 0.333333333333
(3, 10.0, 0.2): 0.933333333333
(3, 10.0, 0.225): 0.666666666667
(3, 10.0, 0.25): 0.6
(3, 10.0, 0.275): 0.666666666667
(3, 10.0, 0.3): 0.333333333333
(3, 100.0, 0.2): 0.866666666667
(3, 100.0, 0.225): 0.666666666667
(3, 100.0, 0.25): 0.666666666667
(3, 100.0, 0.275): 0.6
(3, 100.0, 0.3): 0.333333333333
(4, 1.0, 0.2): 0.8
(4, 1.0, 0.225): 0.866666666667
(4, 1.0, 0.25): 0.8
(4, 1.0, 0.275): 0.866666666667
(4, 1.0, 0.3): 0.733333333333
(4, 10.0, 0.2): 0.8
(4, 10.0, 0.225): 0.8
(4, 10.0, 0.25): 0.933333333333
(4, 10.0, 0.275): 0.733333333333
(4, 10.0, 0.3): 0.666666666667
(4, 100.0, 0.2): 0.8
(4, 100.0, 0.225): 0.733333333333
(4, 100.0, 0.275): 0.866666666667
(4, 100.0, 0.3): 0.666666666667
(5, 0.1, 0.225): 0.866666666667
(5, 0.1, 0.3): 0.533333333333
(5, 1.0, 0.2): 0.8
(5, 1.0, 0.225): 0.866666666667
(5, 1.0, 0.25): 0.866666666667
(5, 1.0, 0.275): 0.8
(5, 1.0, 0.3): 0.6
(5, 10.0, 0.2): 0.866666666667
(5, 10.0, 0.225): 0.8
(5, 10.0, 0.25): 0.2
(5, 10.0, 0.275): 0.6
(5, 10.0, 0.3): 0.6
(5, 100.0, 0.2): 0.866666666667
(5, 100.0, 0.225): 0.933333333333
(5, 100.0, 0.25): 0.2
(5, 100.0, 0.275): 0.6
(5, 100.0, 0.3): 0.6
(6, 1.0, 0.2): 0.8
(6, 1.0, 0.225): 1.0
(6, 1.0, 0.25): 0.933333333333
(6, 1.0, 0.275): 0.933333333333
(6, 1.0, 0.3): 0.933333333333
(6, 10.0, 0.2): 0.866666666667
(6, 10.0, 0.225): 0.333333333333
(6, 10.0, 0.25): 0.866666666667
(6, 10.0, 0.275): 0.866666666667
(6, 10.0, 0.3): 0.533333333333
(6, 100.0, 0.2): 0.933333333333
(6, 100.0, 0.225): 0.333333333333
(6, 100.0, 0.25): 0.866666666667
(6, 100.0, 0.275): 0.666666666667
(6, 100.0, 0.3): 0.6
(7, 1.0, 0.2): 0.8
(7, 1.0, 0.225): 0.8
(7, 1.0, 0.25): 0.8
(7, 1.0, 0.275): 0.6
(7, 1.0, 0.3): 0.666666666667
(7, 10.0, 0.2): 0.733333333333
(7, 10.0, 0.225): 0.8
(7, 10.0, 0.25): 0.6
(7, 10.0, 0.275): 0.666666666667
(7, 10.0, 0.3): 0.466666666667
(7, 100.0, 0.2): 0.733333333333
(7, 100.0, 0.225): 0.8
(7, 100.0, 0.25): 0.866666666667
(7, 100.0, 0.275): 0.733333333333
(7, 100.0, 0.3): 0.533333333333
(8, 0.1, 0.225): 0.8
(8, 0.1, 0.25): 0.733333333333
(8, 0.1, 0.275): 0.733333333333
(8, 1.0, 0.2): 0.4
(8, 1.0, 0.225): 0.866666666667
(8, 1.0, 0.25): 0.733333333333
(8, 1.0, 0.275): 0.733333333333
(8, 1.0, 0.3): 0.733333333333
(8, 10.0, 0.2): 0.866666666667
(8, 10.0, 0.225): 0.666666666667
(8, 10.0, 0.25): 0.666666666667
(8, 10.0, 0.275): 0.733333333333
(8, 10.0, 0.3): 0.666666666667
(8, 100.0, 0.2): 0.866666666667
(8, 100.0, 0.225): 0.133333333333
(8, 100.0, 0.25): 0.733333333333
(8, 100.0, 0.275): 0.866666666667
(8, 100.0, 0.3): 0.466666666667
(9, 1.0, 0.2): 0.733333333333
(9, 1.0, 0.225): 0.733333333333
(9, 1.0, 0.25): 0.733333333333
(9, 1.0, 0.275): 0.666666666667
(9, 1.0, 0.3): 0.533333333333
(9, 10.0, 0.2): 0.733333333333
(9, 10.0, 0.225): 0.8
(9, 10.0, 0.25): 0.933333333333
(9, 10.0, 0.275): 0.6
(9, 10.0, 0.3): 0.733333333333
(9, 100.0, 0.2): 0.733333333333
(9, 100.0, 0.225): 0.866666666667
(9, 100.0, 0.25): 0.933333333333
(9, 100.0, 0.275): 0.6
(9, 100.0, 0.3): 0.666666666667

Loss on all the set for every iteration, for every couple c,sigma (n_of_the_iter, best_c, best_sigma):
(0, 1.0, 0.2): 0.133333333333
(0, 1.0, 0.225): 0.2
(0, 1.0, 0.25): 0.266666666667
(0, 1.0, 0.275): 0.4
(0, 1.0, 0.3): 0.333333333333
(0, 10.0, 0.2): 0.0666666666667
(0, 10.0, 0.225): 0.2
(0, 10.0, 0.25): 0.733333333333
(0, 10.0, 0.275): 0.533333333333
(0, 10.0, 0.3): 0.466666666667
(0, 100.0, 0.2): 0.133333333333
(0, 100.0, 0.225): 0.333333333333
(0, 100.0, 0.25): 0.333333333333
(0, 100.0, 0.275): 0.6
(0, 100.0, 0.3): 0.466666666667
(1, 1.0, 0.2): 0.2
(1, 1.0, 0.225): 0.0
(1, 1.0, 0.25): 0.533333333333
(1, 1.0, 0.275): 0.533333333333
(1, 1.0, 0.3): 0.2
(1, 10.0, 0.2): 0.2
(1, 10.0, 0.225): 0.2
(1, 10.0, 0.25): 0.533333333333
(1, 10.0, 0.275): 0.533333333333
(1, 10.0, 0.3): 0.2
(1, 100.0, 0.2): 0.2
(1, 100.0, 0.225): 0.133333333333
(1, 100.0, 0.25): 0.533333333333
(1, 100.0, 0.275): 0.266666666667
(1, 100.0, 0.3): 0.2
(2, 1.0, 0.2): 0.333333333333
(2, 1.0, 0.225): 0.2
(2, 1.0, 0.25): 0.4
(2, 1.0, 0.275): 0.133333333333
(2, 1.0, 0.3): 0.2
(2, 10.0, 0.2): 0.333333333333
(2, 10.0, 0.225): 0.333333333333
(2, 10.0, 0.25): 0.733333333333
(2, 10.0, 0.275): 0.4
(2, 10.0, 0.3): 0.266666666667
(2, 100.0, 0.2): 0.266666666667
(2, 100.0, 0.225): 0.333333333333
(2, 100.0, 0.25): 0.733333333333
(2, 100.0, 0.275): 0.333333333333
(2, 100.0, 0.3): 0.466666666667
(3, 1.0, 0.2): 0.0666666666667
(3, 1.0, 0.225): 0.333333333333
(3, 1.0, 0.25): 0.266666666667
(3, 1.0, 0.275): 0.333333333333
(3, 1.0, 0.3): 0.666666666667
(3, 10.0, 0.2): 0.0666666666667
(3, 10.0, 0.225): 0.333333333333
(3, 10.0, 0.25): 0.4
(3, 10.0, 0.275): 0.333333333333
(3, 10.0, 0.3): 0.666666666667
(3, 100.0, 0.2): 0.133333333333
(3, 100.0, 0.225): 0.333333333333
(3, 100.0, 0.25): 0.333333333333
(3, 100.0, 0.275): 0.4
(3, 100.0, 0.3): 0.666666666667
(4, 1.0, 0.2): 0.2
(4, 1.0, 0.225): 0.133333333333
(4, 1.0, 0.25): 0.2
(4, 1.0, 0.275): 0.133333333333
(4, 1.0, 0.3): 0.266666666667
(4, 10.0, 0.2): 0.2
(4, 10.0, 0.225): 0.2
(4, 10.0, 0.25): 0.0666666666667
(4, 10.0, 0.275): 0.266666666667
(4, 10.0, 0.3): 0.333333333333
(4, 100.0, 0.2): 0.2
(4, 100.0, 0.225): 0.266666666667
(4, 100.0, 0.275): 0.133333333333
(4, 100.0, 0.3): 0.333333333333
(5, 0.1, 0.225): 0.133333333333
(5, 0.1, 0.3): 0.466666666667
(5, 1.0, 0.2): 0.2
(5, 1.0, 0.225): 0.133333333333
(5, 1.0, 0.25): 0.133333333333
(5, 1.0, 0.275): 0.2
(5, 1.0, 0.3): 0.4
(5, 10.0, 0.2): 0.133333333333
(5, 10.0, 0.225): 0.2
(5, 10.0, 0.25): 0.8
(5, 10.0, 0.275): 0.4
(5, 10.0, 0.3): 0.4
(5, 100.0, 0.2): 0.133333333333
(5, 100.0, 0.225): 0.0666666666667
(5, 100.0, 0.25): 0.8
(5, 100.0, 0.275): 0.4
(5, 100.0, 0.3): 0.4
(6, 1.0, 0.2): 0.2
(6, 1.0, 0.225): 0.0
(6, 1.0, 0.25): 0.0666666666667
(6, 1.0, 0.275): 0.0666666666667
(6, 1.0, 0.3): 0.0666666666667
(6, 10.0, 0.2): 0.133333333333
(6, 10.0, 0.225): 0.666666666667
(6, 10.0, 0.25): 0.133333333333
(6, 10.0, 0.275): 0.133333333333
(6, 10.0, 0.3): 0.466666666667
(6, 100.0, 0.2): 0.0666666666667
(6, 100.0, 0.225): 0.666666666667
(6, 100.0, 0.25): 0.133333333333
(6, 100.0, 0.275): 0.333333333333
(6, 100.0, 0.3): 0.4
(7, 1.0, 0.2): 0.2
(7, 1.0, 0.225): 0.2
(7, 1.0, 0.25): 0.2
(7, 1.0, 0.275): 0.4
(7, 1.0, 0.3): 0.333333333333
(7, 10.0, 0.2): 0.266666666667
(7, 10.0, 0.225): 0.2
(7, 10.0, 0.25): 0.4
(7, 10.0, 0.275): 0.333333333333
(7, 10.0, 0.3): 0.533333333333
(7, 100.0, 0.2): 0.266666666667
(7, 100.0, 0.225): 0.2
(7, 100.0, 0.25): 0.133333333333
(7, 100.0, 0.275): 0.266666666667
(7, 100.0, 0.3): 0.466666666667
(8, 0.1, 0.225): 0.2
(8, 0.1, 0.25): 0.266666666667
(8, 0.1, 0.275): 0.266666666667
(8, 1.0, 0.2): 0.6
(8, 1.0, 0.225): 0.133333333333
(8, 1.0, 0.25): 0.266666666667
(8, 1.0, 0.275): 0.266666666667
(8, 1.0, 0.3): 0.266666666667
(8, 10.0, 0.2): 0.133333333333
(8, 10.0, 0.225): 0.333333333333
(8, 10.0, 0.25): 0.333333333333
(8, 10.0, 0.275): 0.266666666667
(8, 10.0, 0.3): 0.333333333333
(8, 100.0, 0.2): 0.133333333333
(8, 100.0, 0.225): 0.866666666667
(8, 100.0, 0.25): 0.266666666667
(8, 100.0, 0.275): 0.133333333333
(8, 100.0, 0.3): 0.533333333333
(9, 1.0, 0.2): 0.266666666667
(9, 1.0, 0.225): 0.266666666667
(9, 1.0, 0.25): 0.266666666667
(9, 1.0, 0.275): 0.333333333333
(9, 1.0, 0.3): 0.466666666667
(9, 10.0, 0.2): 0.266666666667
(9, 10.0, 0.225): 0.2
(9, 10.0, 0.25): 0.0666666666667
(9, 10.0, 0.275): 0.4
(9, 10.0, 0.3): 0.266666666667
(9, 100.0, 0.2): 0.266666666667
(9, 100.0, 0.225): 0.133333333333
(9, 100.0,

