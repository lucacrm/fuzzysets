QuantileLinPiecewise_2dim, number of iterations: 10

Parameters info
Tradeoffs parameter: [  0.1   1.   10.  100. ]
Using same parameters for all the clusterization: True
Gaussian kernel sigmas: [0.2   0.225 0.25  0.275 0.3  ]
Number of principal dimension considerated: 2
Dataset length: 150

Clusterization info
Minimum size of a cluster: in perc: 0.01, in int: 2
Type of mu: Binary Muzzifier
Fuzzifier: QuantileLinPiecewise
Cluster graph uses all connections: False
Cluster to label info
Force the number of cluster to be the number of different labels: False
Force the labels to be always represent by a cluster: False

Validation info
Conflict resolution: random
Number of cluster considerated for validation (top_k): None


RESULTS

On TEST set

Accuracy on test set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 1.0, 1.0, 0.2): 1.0
(1, 10.0, 10.0, 0.275): 0.666666666667
(2, 10.0, 10.0, 0.275): 0.933333333333
(3, 10.0, 10.0, 0.2): 1.0
(4, 10.0, 10.0, 0.225): 0.933333333333
(5, 1.0, 1.0, 0.2): 0.866666666667
(6, 1.0, 1.0, 0.3): 0.666666666667
(7, 100.0, 100.0, 0.275): 0.6
(8, 1.0, 1.0, 0.2): 0.666666666667
(9, 1.0, 1.0, 0.3): 0.666666666667

Loss on test set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 1.0, 1.0, 0.2): 0.0
(1, 10.0, 10.0, 0.275): 0.333333333333
(2, 10.0, 10.0, 0.275): 0.0666666666667
(3, 10.0, 10.0, 0.2): 0.0
(4, 10.0, 10.0, 0.225): 0.0666666666667
(5, 1.0, 1.0, 0.2): 0.133333333333
(6, 1.0, 1.0, 0.3): 0.333333333333
(7, 100.0, 100.0, 0.275): 0.4
(8, 1.0, 1.0, 0.2): 0.333333333333
(9, 1.0, 1.0, 0.3): 0.333333333333

Accuracy mean :0.8
Std deviation :0.1520233900132184
Loss mean :0.19999999999999998
Std deviation :0.1520233900132184

On TRAINING set

Accuracy on training set for every iteration (n_of_the_iter, c, sigma):
(0, 1.0, 1.0, 0.2): 0.859259259259
(1, 10.0, 10.0, 0.275): 0.666666666667
(2, 10.0, 10.0, 0.275): 0.851851851852
(3, 10.0, 10.0, 0.2): 0.866666666667
(4, 10.0, 10.0, 0.225): 0.874074074074
(5, 1.0, 1.0, 0.2): 0.874074074074
(6, 1.0, 1.0, 0.3): 0.666666666667
(7, 100.0, 100.0, 0.275): 0.674074074074
(8, 1.0, 1.0, 0.2): 0.644444444444
(9, 1.0, 1.0, 0.3): 0.666666666667
Loss on training set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 1.0, 1.0, 0.2): 0.140740740741
(1, 10.0, 10.0, 0.275): 0.333333333333
(2, 10.0, 10.0, 0.275): 0.148148148148
(3, 10.0, 10.0, 0.2): 0.133333333333
(4, 10.0, 10.0, 0.225): 0.125925925926
(5, 1.0, 1.0, 0.2): 0.125925925926
(6, 1.0, 1.0, 0.3): 0.333333333333
(7, 100.0, 100.0, 0.275): 0.325925925926
(8, 1.0, 1.0, 0.2): 0.355555555556
(9, 1.0, 1.0, 0.3): 0.333333333333

Accuracy mean :0.7644444444444445
Std deviation :0.10117553231978595
Loss mean :0.23555555555555557
Std deviation :0.10117553231978592

On ALL the sets

Accuracy on all the set for every iteration, for every couple c,sigma (n_of_the_iter, c, sigma):
(0, 1.0, 1.0, 0.2): 0.8
(0, 1.0, 1.0, 0.225): 0.733333333333
(0, 1.0, 1.0, 0.25): 0.733333333333
(0, 1.0, 1.0, 0.275): 0.666666666667
(0, 1.0, 1.0, 0.3): 0.733333333333
(0, 10.0, 10.0, 0.2): 0.2
(0, 10.0, 10.0, 0.225): 0.733333333333
(0, 10.0, 10.0, 0.25): 0.733333333333
(0, 10.0, 10.0, 0.275): 0.2
(0, 10.0, 10.0, 0.3): 0.733333333333
(0, 100.0, 100.0, 0.2): 0.2
(0, 100.0, 100.0, 0.225): 0.733333333333
(0, 100.0, 100.0, 0.25): 0.733333333333
(0, 100.0, 100.0, 0.275): 0.2
(0, 100.0, 100.0, 0.3): 0.733333333333
(1, 0.1, 0.1, 0.275): 0.933333333333
(1, 0.1, 0.1, 0.3): 0.6
(1, 1.0, 1.0, 0.2): 0.933333333333
(1, 1.0, 1.0, 0.225): 0.933333333333
(1, 1.0, 1.0, 0.25): 0.933333333333
(1, 1.0, 1.0, 0.275): 0.933333333333
(1, 1.0, 1.0, 0.3): 0.6
(1, 10.0, 10.0, 0.2): 0.933333333333
(1, 10.0, 10.0, 0.225): 0.933333333333
(1, 10.0, 10.0, 0.25): 0.933333333333
(1, 10.0, 10.0, 0.275): 0.933333333333
(1, 10.0, 10.0, 0.3): 0.6
(1, 100.0, 100.0, 0.2): 0.933333333333
(1, 100.0, 100.0, 0.225): 0.933333333333
(1, 100.0, 100.0, 0.25): 0.266666666667
(1, 100.0, 100.0, 0.275): 0.866666666667
(1, 100.0, 100.0, 0.3): 0.6
(2, 1.0, 1.0, 0.2): 0.466666666667
(2, 1.0, 1.0, 0.225): 0.466666666667
(2, 1.0, 1.0, 0.25): 0.533333333333
(2, 1.0, 1.0, 0.275): 0.533333333333
(2, 1.0, 1.0, 0.3): 0.533333333333
(2, 10.0, 10.0, 0.2): 0.733333333333
(2, 10.0, 10.0, 0.225): 0.866666666667
(2, 10.0, 10.0, 0.25): 0.266666666667
(2, 10.0, 10.0, 0.275): 0.866666666667
(2, 10.0, 10.0, 0.3): 0.533333333333
(2, 100.0, 100.0, 0.2): 0.733333333333
(2, 100.0, 100.0, 0.225): 0.866666666667
(2, 100.0, 100.0, 0.25): 0.266666666667
(2, 100.0, 100.0, 0.275): 0.533333333333
(2, 100.0, 100.0, 0.3): 0.533333333333
(3, 1.0, 1.0, 0.2): 0.733333333333
(3, 1.0, 1.0, 0.225): 0.533333333333
(3, 1.0, 1.0, 0.25): 0.533333333333
(3, 1.0, 1.0, 0.275): 0.533333333333
(3, 1.0, 1.0, 0.3): 0.533333333333
(3, 10.0, 10.0, 0.2): 0.733333333333
(3, 10.0, 10.0, 0.225): 0.533333333333
(3, 10.0, 10.0, 0.25): 0.533333333333
(3, 10.0, 10.0, 0.275): 0.533333333333
(3, 10.0, 10.0, 0.3): 0.533333333333
(3, 100.0, 100.0, 0.2): 0.733333333333
(3, 100.0, 100.0, 0.225): 0.533333333333
(3, 100.0, 100.0, 0.25): 0.533333333333
(3, 100.0, 100.0, 0.275): 0.533333333333
(3, 100.0, 100.0, 0.3): 0.533333333333
(4, 0.1, 0.1, 0.25): 0.8
(4, 1.0, 1.0, 0.2): 0.733333333333
(4, 1.0, 1.0, 0.225): 0.8
(4, 1.0, 1.0, 0.25): 0.733333333333
(4, 1.0, 1.0, 0.275): 0.733333333333
(4, 1.0, 1.0, 0.3): 0.733333333333
(4, 10.0, 10.0, 0.2): 0.733333333333
(4, 10.0, 10.0, 0.225): 0.8
(4, 10.0, 10.0, 0.25): 0.733333333333
(4, 10.0, 10.0, 0.275): 0.733333333333
(4, 10.0, 10.0, 0.3): 0.733333333333
(4, 100.0, 100.0, 0.2): 0.666666666667
(4, 100.0, 100.0, 0.225): 0.8
(4, 100.0, 100.0, 0.25): 0.733333333333
(4, 100.0, 100.0, 0.275): 0.733333333333
(4, 100.0, 100.0, 0.3): 0.733333333333
(5, 0.1, 0.1, 0.275): 0.666666666667
(5, 1.0, 1.0, 0.2): 1.0
(5, 1.0, 1.0, 0.225): 0.933333333333
(5, 1.0, 1.0, 0.25): 0.6
(5, 1.0, 1.0, 0.275): 0.666666666667
(5, 1.0, 1.0, 0.3): 0.666666666667
(5, 10.0, 10.0, 0.2): 1.0
(5, 10.0, 10.0, 0.225): 0.933333333333
(5, 10.0, 10.0, 0.25): 0.666666666667
(5, 10.0, 10.0, 0.275): 0.666666666667
(5, 10.0, 10.0, 0.3): 0.666666666667
(5, 100.0, 100.0, 0.2): 1.0
(5, 100.0, 100.0, 0.225): 0.933333333333
(5, 100.0, 100.0, 0.25): 0.666666666667
(5, 100.0, 100.0, 0.275): 0.666666666667
(5, 100.0, 100.0, 0.3): 0.666666666667
(6, 1.0, 1.0, 0.2): 0.8
(6, 1.0, 1.0, 0.225): 0.866666666667
(6, 1.0, 1.0, 0.25): 0.533333333333
(6, 1.0, 1.0, 0.275): 0.8
(6, 1.0, 1.0, 0.3): 0.866666666667
(6, 10.0, 10.0, 0.2): 0.8
(6, 10.0, 10.0, 0.225): 0.866666666667
(6, 10.0, 10.0, 0.25): 0.533333333333
(6, 10.0, 10.0, 0.275): 0.8
(6, 10.0, 10.0, 0.3): 0.866666666667
(6, 100.0, 100.0, 0.2): 0.8
(6, 100.0, 100.0, 0.225): 0.866666666667
(6, 100.0, 100.0, 0.25): 0.533333333333
(6, 100.0, 100.0, 0.275): 0.8
(6, 100.0, 100.0, 0.3): 0.866666666667
(7, 0.1, 0.1, 0.3): 0.533333333333
(7, 1.0, 1.0, 0.2): 0.866666666667
(7, 1.0, 1.0, 0.225): 0.866666666667
(7, 1.0, 1.0, 0.25): 0.866666666667
(7, 1.0, 1.0, 0.275): 0.866666666667
(7, 1.0, 1.0, 0.3): 0.533333333333
(7, 10.0, 10.0, 0.2): 0.866666666667
(7, 10.0, 10.0, 0.225): 0.866666666667
(7, 10.0, 10.0, 0.25): 0.866666666667
(7, 10.0, 10.0, 0.275): 0.866666666667
(7, 10.0, 10.0, 0.3): 0.533333333333
(7, 100.0, 100.0, 0.2): 0.866666666667
(7, 100.0, 100.0, 0.225): 0.866666666667
(7, 100.0, 100.0, 0.25): 0.866666666667
(7, 100.0, 100.0, 0.275): 0.933333333333
(7, 100.0, 100.0, 0.3): 0.533333333333
(8, 1.0, 1.0, 0.2): 0.8
(8, 1.0, 1.0, 0.225): 0.8
(8, 1.0, 1.0, 0.25): 0.733333333333
(8, 1.0, 1.0, 0.275): 0.666666666667
(8, 1.0, 1.0, 0.3): 0.466666666667
(8, 10.0, 10.0, 0.2): 0.8
(8, 10.0, 10.0, 0.225): 0.8
(8, 10.0, 10.0, 0.25): 0.733333333333
(8, 10.0, 10.0, 0.275): 0.6
(8, 10.0, 10.0, 0.3): 0.466666666667
(8, 100.0, 100.0, 0.2): 0.8
(8, 100.0, 100.0, 0.225): 0.8
(8, 100.0, 100.0, 0.25): 0.8
(8, 100.0, 100.0, 0.275): 0.666666666667
(8, 100.0, 100.0, 0.3): 0.466666666667
(9, 1.0, 1.0, 0.2): 0.8
(9, 1.0, 1.0, 0.225): 0.933333333333
(9, 1.0, 1.0, 0.25): 0.866666666667
(9, 1.0, 1.0, 0.275): 0.866666666667
(9, 1.0, 1.0, 0.3): 0.933333333333
(9, 10.0, 10.0, 0.2): 0.866666666667
(9, 10.0, 10.0, 0.225): 0.933333333333
(9, 10.0, 10.0, 0.25): 0.866666666667
(9, 10.0, 10.0, 0.275): 0.866666666667
(9, 10.0, 10.0, 0.3): 0.933333333333
(9, 100.0, 100.0, 0.2): 0.133333333333
(9, 100.0, 100.0, 0.225): 0.933333333333
(9, 100.0, 100.0, 0.25): 0.6
(9, 100.0, 100.0, 0.275): 0.866666666667
(9, 100.0, 100.0, 0.3): 0.933333333333

Loss on all the set for every iteration, for every couple c,sigma (n_of_the_iter, best_c, best_sigma):
(0, 1.0, 1.0, 0.2): 0.2
(0, 1.0, 1.0, 0.225): 0.266666666667
(0, 1.0, 1.0, 0.25): 0.266666666667
(0, 1.0, 1.0, 0.275): 0.333333333333
(0, 1.0, 1.0, 0.3): 0.266666666667
(0, 10.0, 10.0, 0.2): 0.8
(0, 10.0, 10.0, 0.225): 0.266666666667
(0, 10.0, 10.0, 0.25): 0.266666666667
(0, 10.0, 10.0, 0.275): 0.8
(0, 10.0, 10.0, 0.3): 0.266666666667
(0, 100.0, 100.0, 0.2): 0.8
(0, 100.0, 100.0, 0.225): 0.266666666667
(0, 100.0, 100.0, 0.25): 0.266666666667
(0, 100.0, 100.0, 0.275): 0.8
(0, 100.0, 100.0, 0.3): 0.266666666667
(1, 0.1, 0.1, 0.275): 0.0666666666667
(1, 0.1, 0.1, 0.3): 0.4
(1, 1.0, 1.0, 0.2): 0.0666666666667
(1, 1.0, 1.0, 0.225): 0.0666666666667
(1, 1.0, 1.0, 0.25): 0.0666666666667
(1, 1.0, 1.0, 0.275): 0.0666666666667
(1, 1.0, 1.0, 0.3): 0.4
(1, 10.0, 10.0, 0.2): 0.0666666666667
(1, 10.0, 10.0, 0.225): 0.0666666666667
(1, 10.0, 10.0, 0.25): 0.0666666666667
(1, 10.0, 10.0, 0.275): 0.0666666666667
(1, 10.0, 10.0, 0.3): 0.4
(1, 100.0, 100.0, 0.2): 0.0666666666667
(1, 100.0, 100.0, 0.225): 0.0666666666667
(1, 100.0, 100.0, 0.25): 0.733333333333
(1, 100.0, 100.0, 0.275): 0.133333333333
(1, 100.0, 100.0, 0.3): 0.4
(2, 1.0, 1.0, 0.2): 0.533333333333
(2, 1.0, 1.0, 0.225): 0.533333333333
(2, 1.0, 1.0, 0.25): 0.466666666667
(2, 1.0, 1.0, 0.275): 0.466666666667
(2, 1.0, 1.0, 0.3): 0.466666666667
(2, 10.0, 10.0, 0.2): 0.266666666667
(2, 10.0, 10.0, 0.225): 0.133333333333
(2, 10.0, 10.0, 0.25): 0.733333333333
(2, 10.0, 10.0, 0.275): 0.133333333333
(2, 10.0, 10.0, 0.3): 0.466666666667
(2, 100.0, 100.0, 0.2): 0.266666666667
(2, 100.0, 100.0, 0.225): 0.133333333333
(2, 100.0, 100.0, 0.25): 0.733333333333
(2, 100.0, 100.0, 0.275): 0.466666666667
(2, 100.0, 100.0, 0.3): 0.466666666667
(3, 1.0, 1.0, 0.2): 0.266666666667
(3, 1.0, 1.0, 0.225): 0.466666666667
(3, 1.0, 1.0, 0.25): 0.466666666667
(3, 1.0, 1.0, 0.275): 0.466666666667
(3, 1.0, 1.0, 0.3): 0.466666666667
(3, 10.0, 10.0, 0.2): 0.266666666667
(3, 10.0, 10.0, 0.225): 0.466666666667
(3, 10.0, 10.0, 0.25): 0.466666666667
(3, 10.0, 10.0, 0.275): 0.466666666667
(3, 10.0, 10.0, 0.3): 0.466666666667
(3, 100.0, 100.0, 0.2): 0.266666666667
(3, 100.0, 100.0, 0.225): 0.466666666667
(3, 100.0, 100.0, 0.25): 0.466666666667
(3, 100.0, 100.0, 0.275): 0.466666666667
(3, 100.0, 100.0, 0.3): 0.466666666667
(4, 0.1, 0.1, 0.25): 0.2
(4, 1.0, 1.0, 0.2): 0.266666666667
(4, 1.0, 1.0, 0.225): 0.2
(4, 1.0, 1.0, 0.25): 0.266666666667
(4, 1.0, 1.0, 0.275): 0.266666666667
(4, 1.0, 1.0, 0.3): 0.266666666667
(4, 10.0, 10.0, 0.2): 0.266666666667
(4, 10.0, 10.0, 0.225): 0.2
(4, 10.0, 10.0, 0.25): 0.266666666667
(4, 10.0, 10.0, 0.275): 0.266666666667
(4, 10.0, 10.0, 0.3): 0.266666666667
(4, 100.0, 100.0, 0.2): 0.333333333333
(4, 100.0, 100.0, 0.225): 0.2
(4, 100.0, 100.0, 0.25): 0.266666666667
(4, 100.0, 100.0, 0.275): 0.266666666667
(4, 100.0, 100.0, 0.3): 0.266666666667
(5, 0.1, 0.1, 0.275): 0.333333333333
(5, 1.0, 1.0, 0.2): 0.0
(5, 1.0, 1.0, 0.225): 0.0666666666667
(5, 1.0, 1.0, 0.25): 0.4
(5, 1.0, 1.0, 0.275): 0.333333333333
(5, 1.0, 1.0, 0.3): 0.333333333333
(5, 10.0, 10.0, 0.2): 0.0
(5, 10.0, 10.0, 0.225): 0.0666666666667
(5, 10.0, 10.0, 0.25): 0.333333333333
(5, 10.0, 10.0, 0.275): 0.333333333333
(5, 10.0, 10.0, 0.3): 0.333333333333
(5, 100.0, 100.0, 0.2): 0.0
(5, 100.0, 100.0, 0.225): 0.0666666666667
(5, 100.0, 100.0, 0.25): 0.333333333333
(5, 100.0, 100.0, 0.275): 0.333333333333
(5, 100.0, 100.0, 0.3): 0.333333333333
(6, 1.0, 1.0, 0.2): 0.2
(6, 1.0, 1.0, 0.225): 0.133333333333
(6, 1.0, 1.0, 0.25): 0.466666666667
(6, 1.0, 1.0, 0.275): 0.2
(6, 1.0, 1.0, 0.3): 0.133333333333
(6, 10.0, 10.0, 0.2): 0.2
(6, 10.0, 10.0, 0.225): 0.133333333333
(6, 10.0, 10.0, 0.25): 0.466666666667
(6, 10.0, 10.0, 0.275): 0.2
(6, 10.0, 10.0, 0.3): 0.133333333333
(6, 100.0, 100.0, 0.2): 0.2
(6, 100.0, 100.0, 0.225): 0.133333333333
(6, 100.0, 100.0, 0.25): 0.466666666667
(6, 100.0, 100.0, 0.275): 0.2
(6, 100.0, 100.0, 0.3): 0.133333333333
(7, 0.1, 0.1, 0.3): 0.466666666667
(7, 1.0, 1.0, 0.2): 0.133333333333
(7, 1.0, 1.0, 0.225): 0.133333333333
(7, 1.0, 1.0, 0.25): 0.133333333333
(7, 1.0, 1.0, 0.275): 0.133333333333
(7, 1.0, 1.0, 0.3): 0.466666666667
(7, 10.0, 10.0, 0.2): 0.133333333333
(7, 10.0, 10.0, 0.225): 0.133333333333
(7, 10.0, 10.0, 0.25): 0.133333333333
(7, 10.0, 10.0, 0.275): 0.133333333333
(7, 10.0, 10.0, 0.3): 0.466666666667
(7, 100.0, 100.0, 0.2): 0.133333333333
(7, 100.0, 100.0, 0.225): 0.133333333333
(7, 100.0, 100.0, 0.25): 0.133333333333
(7, 100.0, 100.0, 0.275): 0.0666666666667
(7, 100.0, 100.0, 0.3): 0.466666666667
(8, 1.0, 1.0, 0.2): 0.2
(8, 1.0, 1.0, 0.225): 0.2
(8, 1.0, 1.0, 0.25): 0.266666666667
(8, 1.0, 1.0, 0.275): 0.333333333333
(8, 1.0, 1.0, 0.3): 0.533333333333
(8, 10.0, 10.0, 0.2): 0.2
(8, 10.0, 10.0, 0.225): 0.2
(8, 10.0, 10.0, 0.25): 0.266666666667
(8, 10.0, 10.0, 0.275): 0.4
(8, 10.0, 10.0, 0.3): 0.533333333333
(8, 100.0, 100.0, 0.2): 0.2
(8, 100.0, 100.0, 0.225): 0.2
(8, 100.0, 100.0, 0.25): 0.2
(8, 100.0, 100.0, 0.275): 0.333333333333
(8, 100.0, 100.0, 0.3): 0.533333333333
(9, 1.0, 1.0, 0.2): 0.2
(9, 1.0, 1.0, 0.225): 0.0666666666667
(9, 1.0, 1.0, 0.25): 0.133333333333
(9, 1.0, 1.0, 0.275): 0.133333333333
(9, 1.0, 1.0, 0.3): 0.0666666666667
(9, 10.0, 10.0, 0.2): 0.133333333333
(9, 10.0, 10.0, 0.225): 0.0666666666667
(9, 10.0, 10.0, 0.25): 0.133333333333
(9, 10.0, 10.0, 0.275): 0.133333333333
(9, 10.0, 10.0, 0.3): 0.0666666666667
(9, 100.0, 100.0, 0.2): 0.866666666667
(9, 100.0, 100.0, 0.225): 0.0666666666667
(9, 100.0, 100.0, 0.25): 0.4
(9, 100.0, 100.0, 0.275): 0.133333333333
(9, 100.0, 100.0, 0.3): 0.0666666666667

Accuracy mean :0.7178494623655914
Std deviation :0.1843822358027998
Loss mean :0.2821505376344086
Std deviation :0.1843822358027998



Crisp_2dim, number of iterations: 10

Parameters info
Tradeoffs parameter: [  0.1   1.   10.  100. ]
Using same parameters for all the clusterization: True
Gaussian kernel sigmas: [0.2   0.225 0.25  0.275 0.3  ]
Number of principal dimension considerated: 2
Dataset length: 150

Clusterization info
Minimum size of a cluster: in perc: 0.01, in int: 2
Type of mu: Binary Muzzifier
Fuzzifier: Crisp
Cluster graph uses all connections: False
Cluster to label info
Force the number of cluster to be the number of different labels: False
Force the labels to be always represent by a cluster: False

Validation info
Conflict resolution: random
Number of cluster considerated for validation (top_k): None


RESULTS

On TEST set

Accuracy on test set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 1.0, 1.0, 0.3): 0.533333333333
(1, 10.0, 10.0, 0.3): 0.333333333333
(2, 100.0, 100.0, 0.225): 0.333333333333
(3, 1.0, 1.0, 0.2): 0.266666666667
(4, 100.0, 100.0, 0.275): 0.2
(5, 100.0, 100.0, 0.225): 0.4
(6, 10.0, 10.0, 0.3): 0.6
(7, 10.0, 10.0, 0.225): 0.4
(8, 1.0, 1.0, 0.225): 0.733333333333
(9, 10.0, 10.0, 0.275): 0.466666666667

Loss on test set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 1.0, 1.0, 0.3): 0.466666666667
(1, 10.0, 10.0, 0.3): 0.666666666667
(2, 100.0, 100.0, 0.225): 0.666666666667
(3, 1.0, 1.0, 0.2): 0.733333333333
(4, 100.0, 100.0, 0.275): 0.8
(5, 100.0, 100.0, 0.225): 0.6
(6, 10.0, 10.0, 0.3): 0.4
(7, 10.0, 10.0, 0.225): 0.6
(8, 1.0, 1.0, 0.225): 0.266666666667
(9, 10.0, 10.0, 0.275): 0.533333333333

Accuracy mean :0.42666666666666664
Std deviation :0.15260697523012792
Loss mean :0.5733333333333334
Std deviation :0.15260697523012795

On TRAINING set

Accuracy on training set for every iteration (n_of_the_iter, c, sigma):
(0, 1.0, 1.0, 0.3): 0.637037037037
(1, 10.0, 10.0, 0.3): 0.585185185185
(2, 100.0, 100.0, 0.225): 0.681481481481
(3, 1.0, 1.0, 0.2): 0.585185185185
(4, 100.0, 100.0, 0.275): 0.348148148148
(5, 100.0, 100.0, 0.225): 0.62962962963
(6, 10.0, 10.0, 0.3): 0.696296296296
(7, 10.0, 10.0, 0.225): 0.748148148148
(8, 1.0, 1.0, 0.225): 0.62962962963
(9, 10.0, 10.0, 0.275): 0.274074074074
Loss on training set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 1.0, 1.0, 0.3): 0.362962962963
(1, 10.0, 10.0, 0.3): 0.414814814815
(2, 100.0, 100.0, 0.225): 0.318518518519
(3, 1.0, 1.0, 0.2): 0.414814814815
(4, 100.0, 100.0, 0.275): 0.651851851852
(5, 100.0, 100.0, 0.225): 0.37037037037
(6, 10.0, 10.0, 0.3): 0.303703703704
(7, 10.0, 10.0, 0.225): 0.251851851852
(8, 1.0, 1.0, 0.225): 0.37037037037
(9, 10.0, 10.0, 0.275): 0.725925925926

Accuracy mean :0.5814814814814815
Std deviation :0.14410215854998645
Loss mean :0.4185185185185185
Std deviation :0.14410215854998645

On ALL the sets

Accuracy on all the set for every iteration, for every couple c,sigma (n_of_the_iter, c, sigma):
(0, 1.0, 1.0, 0.2): 0.466666666667
(0, 1.0, 1.0, 0.225): 0.333333333333
(0, 1.0, 1.0, 0.25): 0.466666666667
(0, 1.0, 1.0, 0.275): 0.4
(0, 1.0, 1.0, 0.3): 0.666666666667
(0, 10.0, 10.0, 0.2): 0.6
(0, 10.0, 10.0, 0.225): 0.333333333333
(0, 10.0, 10.0, 0.25): 0.466666666667
(0, 10.0, 10.0, 0.275): 0.466666666667
(0, 10.0, 10.0, 0.3): 0.133333333333
(0, 100.0, 100.0, 0.2): 0.6
(0, 100.0, 100.0, 0.225): 0.4
(0, 100.0, 100.0, 0.25): 0.466666666667
(0, 100.0, 100.0, 0.275): 0.466666666667
(0, 100.0, 100.0, 0.3): 0.6
(1, 0.1, 0.1, 0.3): 0.466666666667
(1, 1.0, 1.0, 0.2): 0.4
(1, 1.0, 1.0, 0.225): 0.4
(1, 1.0, 1.0, 0.25): 0.266666666667
(1, 1.0, 1.0, 0.275): 0.266666666667
(1, 1.0, 1.0, 0.3): 0.466666666667
(1, 10.0, 10.0, 0.2): 0.466666666667
(1, 10.0, 10.0, 0.225): 0.333333333333
(1, 10.0, 10.0, 0.25): 0.333333333333
(1, 10.0, 10.0, 0.275): 0.466666666667
(1, 10.0, 10.0, 0.3): 0.6
(1, 100.0, 100.0, 0.2): 0.4
(1, 100.0, 100.0, 0.225): 0.533333333333
(1, 100.0, 100.0, 0.25): 0.133333333333
(1, 100.0, 100.0, 0.275): 0.4
(1, 100.0, 100.0, 0.3): 0.4
(2, 0.1, 0.1, 0.225): 0.533333333333
(2, 0.1, 0.1, 0.25): 0.6
(2, 1.0, 1.0, 0.2): 0.266666666667
(2, 1.0, 1.0, 0.225): 0.533333333333
(2, 1.0, 1.0, 0.25): 0.466666666667
(2, 1.0, 1.0, 0.275): 0.333333333333
(2, 1.0, 1.0, 0.3): 0.466666666667
(2, 10.0, 10.0, 0.2): 0.533333333333
(2, 10.0, 10.0, 0.225): 0.6
(2, 10.0, 10.0, 0.25): 0.533333333333
(2, 10.0, 10.0, 0.275): 0.333333333333
(2, 10.0, 10.0, 0.3): 0.533333333333
(2, 100.0, 100.0, 0.2): 0.4
(2, 100.0, 100.0, 0.225): 0.666666666667
(2, 100.0, 100.0, 0.25): 0.466666666667
(2, 100.0, 100.0, 0.275): 0.333333333333
(2, 100.0, 100.0, 0.3): 0.466666666667
(3, 1.0, 1.0, 0.2): 0.6
(3, 1.0, 1.0, 0.225): 0.4
(3, 1.0, 1.0, 0.25): 0.533333333333
(3, 1.0, 1.0, 0.275): 0.533333333333
(3, 1.0, 1.0, 0.3): 0.4
(3, 10.0, 10.0, 0.2): 0.466666666667
(3, 10.0, 10.0, 0.225): 0.333333333333
(3, 10.0, 10.0, 0.25): 0.4
(3, 10.0, 10.0, 0.275): 0.333333333333
(3, 10.0, 10.0, 0.3): 0.466666666667
(3, 100.0, 100.0, 0.2): 0.4
(3, 100.0, 100.0, 0.225): 0.266666666667
(3, 100.0, 100.0, 0.25): 0.533333333333
(3, 100.0, 100.0, 0.275): 0.4
(3, 100.0, 100.0, 0.3): 0.533333333333
(4, 1.0, 1.0, 0.2): 0.2
(4, 1.0, 1.0, 0.225): 0.333333333333
(4, 1.0, 1.0, 0.25): 0.6
(4, 1.0, 1.0, 0.275): 0.666666666667
(4, 1.0, 1.0, 0.3): 0.4
(4, 10.0, 10.0, 0.2): 0.333333333333
(4, 10.0, 10.0, 0.225): 0.333333333333
(4, 10.0, 10.0, 0.25): 0.266666666667
(4, 10.0, 10.0, 0.275): 0.4
(4, 10.0, 10.0, 0.3): 0.266666666667
(4, 100.0, 100.0, 0.2): 0.133333333333
(4, 100.0, 100.0, 0.225): 0.4
(4, 100.0, 100.0, 0.25): 0.466666666667
(4, 100.0, 100.0, 0.275): 0.666666666667
(4, 100.0, 100.0, 0.3): 0.466666666667
(5, 0.1, 0.1, 0.25): 0.6
(5, 1.0, 1.0, 0.2): 0.4
(5, 1.0, 1.0, 0.225): 0.6
(5, 1.0, 1.0, 0.25): 0.4
(5, 1.0, 1.0, 0.275): 0.6
(5, 1.0, 1.0, 0.3): 0.4
(5, 10.0, 10.0, 0.2): 0.466666666667
(5, 10.0, 10.0, 0.225): 0.6
(5, 10.0, 10.0, 0.25): 0.466666666667
(5, 10.0, 10.0, 0.275): 0.333333333333
(5, 10.0, 10.0, 0.3): 0.4
(5, 100.0, 100.0, 0.2): 0.4
(5, 100.0, 100.0, 0.225): 0.666666666667
(5, 100.0, 100.0, 0.25): 0.333333333333
(5, 100.0, 100.0, 0.275): 0.333333333333
(5, 100.0, 100.0, 0.3): 0.6
(6, 1.0, 1.0, 0.2): 0.2
(6, 1.0, 1.0, 0.225): 0.2
(6, 1.0, 1.0, 0.25): 0.4
(6, 1.0, 1.0, 0.275): 0.266666666667
(6, 1.0, 1.0, 0.3): 0.333333333333
(6, 10.0, 10.0, 0.2): 0.4
(6, 10.0, 10.0, 0.225): 0.333333333333
(6, 10.0, 10.0, 0.25): 0.2
(6, 10.0, 10.0, 0.275): 0.333333333333
(6, 10.0, 10.0, 0.3): 0.533333333333
(6, 100.0, 100.0, 0.2): 0.133333333333
(6, 100.0, 100.0, 0.225): 0.466666666667
(6, 100.0, 100.0, 0.25): 0.2
(6, 100.0, 100.0, 0.275): 0.4
(6, 100.0, 100.0, 0.3): 0.466666666667
(7, 0.1, 0.1, 0.25): 0.266666666667
(7, 1.0, 1.0, 0.2): 0.666666666667
(7, 1.0, 1.0, 0.225): 0.6
(7, 1.0, 1.0, 0.25): 0.333333333333
(7, 1.0, 1.0, 0.275): 0.2
(7, 1.0, 1.0, 0.3): 0.2
(7, 10.0, 10.0, 0.2): 0.466666666667
(7, 10.0, 10.0, 0.225): 0.8
(7, 10.0, 10.0, 0.25): 0.333333333333
(7, 10.0, 10.0, 0.275): 0.333333333333
(7, 10.0, 10.0, 0.3): 0.4
(7, 100.0, 100.0, 0.2): 0.4
(7, 100.0, 100.0, 0.225): 0.533333333333
(7, 100.0, 100.0, 0.25): 0.466666666667
(7, 100.0, 100.0, 0.275): 0.533333333333
(7, 100.0, 100.0, 0.3): 0.533333333333
(8, 1.0, 1.0, 0.2): 0.4
(8, 1.0, 1.0, 0.225): 0.8
(8, 1.0, 1.0, 0.25): 0.533333333333
(8, 1.0, 1.0, 0.275): 0.266666666667
(8, 1.0, 1.0, 0.3): 0.4
(8, 10.0, 10.0, 0.2): 0.333333333333
(8, 10.0, 10.0, 0.225): 0.4
(8, 10.0, 10.0, 0.25): 0.733333333333
(8, 10.0, 10.0, 0.275): 0.266666666667
(8, 10.0, 10.0, 0.3): 0.466666666667
(8, 100.0, 100.0, 0.2): 0.2
(8, 100.0, 100.0, 0.225): 0.733333333333
(8, 100.0, 100.0, 0.25): 0.533333333333
(8, 100.0, 100.0, 0.275): 0.4
(8, 100.0, 100.0, 0.3): 0.333333333333
(9, 1.0, 1.0, 0.2): 0.4
(9, 1.0, 1.0, 0.225): 0.266666666667
(9, 1.0, 1.0, 0.25): 0.4
(9, 1.0, 1.0, 0.275): 0.466666666667
(9, 1.0, 1.0, 0.3): 0.666666666667
(9, 10.0, 10.0, 0.2): 0.4
(9, 10.0, 10.0, 0.225): 0.4
(9, 10.0, 10.0, 0.25): 0.4
(9, 10.0, 10.0, 0.275): 0.666666666667
(9, 10.0, 10.0, 0.3): 0.466666666667
(9, 100.0, 100.0, 0.2): 0.6
(9, 100.0, 100.0, 0.225): 0.466666666667
(9, 100.0, 100.0, 0.25): 0.6
(9, 100.0, 100.0, 0.275): 0.533333333333
(9, 100.0, 100.0, 0.3): 0.533333333333

Loss on all the set for every iteration, for every couple c,sigma (n_of_the_iter, best_c, best_sigma):
(0, 1.0, 1.0, 0.2): 0.533333333333
(0, 1.0, 1.0, 0.225): 0.666666666667
(0, 1.0, 1.0, 0.25): 0.533333333333
(0, 1.0, 1.0, 0.275): 0.6
(0, 1.0, 1.0, 0.3): 0.333333333333
(0, 10.0, 10.0, 0.2): 0.4
(0, 10.0, 10.0, 0.225): 0.666666666667
(0, 10.0, 10.0, 0.25): 0.533333333333
(0, 10.0, 10.0, 0.275): 0.533333333333
(0, 10.0, 10.0, 0.3): 0.866666666667
(0, 100.0, 100.0, 0.2): 0.4
(0, 100.0, 100.0, 0.225): 0.6
(0, 100.0, 100.0, 0.25): 0.533333333333
(0, 100.0, 100.0, 0.275): 0.533333333333
(0, 100.0, 100.0, 0.3): 0.4
(1, 0.1, 0.1, 0.3): 0.533333333333
(1, 1.0, 1.0, 0.2): 0.6
(1, 1.0, 1.0, 0.225): 0.6
(1, 1.0, 1.0, 0.25): 0.733333333333
(1, 1.0, 1.0, 0.275): 0.733333333333
(1, 1.0, 1.0, 0.3): 0.533333333333
(1, 10.0, 10.0, 0.2): 0.533333333333
(1, 10.0, 10.0, 0.225): 0.666666666667
(1, 10.0, 10.0, 0.25): 0.666666666667
(1, 10.0, 10.0, 0.275): 0.533333333333
(1, 10.0, 10.0, 0.3): 0.4
(1, 100.0, 100.0, 0.2): 0.6
(1, 100.0, 100.0, 0.225): 0.466666666667
(1, 100.0, 100.0, 0.25): 0.866666666667
(1, 100.0, 100.0, 0.275): 0.6
(1, 100.0, 100.0, 0.3): 0.6
(2, 0.1, 0.1, 0.225): 0.466666666667
(2, 0.1, 0.1, 0.25): 0.4
(2, 1.0, 1.0, 0.2): 0.733333333333
(2, 1.0, 1.0, 0.225): 0.466666666667
(2, 1.0, 1.0, 0.25): 0.533333333333
(2, 1.0, 1.0, 0.275): 0.666666666667
(2, 1.0, 1.0, 0.3): 0.533333333333
(2, 10.0, 10.0, 0.2): 0.466666666667
(2, 10.0, 10.0, 0.225): 0.4
(2, 10.0, 10.0, 0.25): 0.466666666667
(2, 10.0, 10.0, 0.275): 0.666666666667
(2, 10.0, 10.0, 0.3): 0.466666666667
(2, 100.0, 100.0, 0.2): 0.6
(2, 100.0, 100.0, 0.225): 0.333333333333
(2, 100.0, 100.0, 0.25): 0.533333333333
(2, 100.0, 100.0, 0.275): 0.666666666667
(2, 100.0, 100.0, 0.3): 0.533333333333
(3, 1.0, 1.0, 0.2): 0.4
(3, 1.0, 1.0, 0.225): 0.6
(3, 1.0, 1.0, 0.25): 0.466666666667
(3, 1.0, 1.0, 0.275): 0.466666666667
(3, 1.0, 1.0, 0.3): 0.6
(3, 10.0, 10.0, 0.2): 0.533333333333
(3, 10.0, 10.0, 0.225): 0.666666666667
(3, 10.0, 10.0, 0.25): 0.6
(3, 10.0, 10.0, 0.275): 0.666666666667
(3, 10.0, 10.0, 0.3): 0.533333333333
(3, 100.0, 100.0, 0.2): 0.6
(3, 100.0, 100.0, 0.225): 0.733333333333
(3, 100.0, 100.0, 0.25): 0.466666666667
(3, 100.0, 100.0, 0.275): 0.6
(3, 100.0, 100.0, 0.3): 0.466666666667
(4, 1.0, 1.0, 0.2): 0.8
(4, 1.0, 1.0, 0.225): 0.666666666667
(4, 1.0, 1.0, 0.25): 0.4
(4, 1.0, 1.0, 0.275): 0.333333333333
(4, 1.0, 1.0, 0.3): 0.6
(4, 10.0, 10.0, 0.2): 0.666666666667
(4, 10.0, 10.0, 0.225): 0.666666666667
(4, 10.0, 10.0, 0.25): 0.733333333333
(4, 10.0, 10.0, 0.275): 0.6
(4, 10.0, 10.0, 0.3): 0.733333333333
(4, 100.0, 100.0, 0.2): 0.866666666667
(4, 100.0, 100.0, 0.225): 0.6
(4, 100.0, 100.0, 0.25): 0.533333333333
(4, 100.0, 100.0, 0.275): 0.333333333333
(4, 100.0, 100.0, 0.3): 0.533333333333
(5, 0.1, 0.1, 0.25): 0.4
(5, 1.0, 1.0, 0.2): 0.6
(5, 1.0, 1.0, 0.225): 0.4
(5, 1.0, 1.0, 0.25): 0.6
(5, 1.0, 1.0, 0.275): 0.4
(5, 1.0, 1.0, 0.3): 0.6
(5, 10.0, 10.0, 0.2): 0.533333333333
(5, 10.0, 10.0, 0.225): 0.4
(5, 10.0, 10.0, 0.25): 0.533333333333
(5, 10.0, 10.0, 0.275): 0.666666666667
(5, 10.0, 10.0, 0.3): 0.6
(5, 100.0, 100.0, 0.2): 0.6
(5, 100.0, 100.0, 0.225): 0.333333333333
(5, 100.0, 100.0, 0.25): 0.666666666667
(5, 100.0, 100.0, 0.275): 0.666666666667
(5, 100.0, 100.0, 0.3): 0.4
(6, 1.0, 1.0, 0.2): 0.8
(6, 1.0, 1.0, 0.225): 0.8
(6, 1.0, 1.0, 0.25): 0.6
(6, 1.0, 1.0, 0.275): 0.733333333333
(6, 1.0, 1.0, 0.3): 0.666666666667
(6, 10.0, 10.0, 0.2): 0.6
(6, 10.0, 10.0, 0.225): 0.666666666667
(6, 10.0, 10.0, 0.25): 0.8
(6, 10.0, 10.0, 0.275): 0.666666666667
(6, 10.0, 10.0, 0.3): 0.466666666667
(6, 100.0, 100.0, 0.2): 0.866666666667
(6, 100.0, 100.0, 0.225): 0.533333333333
(6, 100.0, 100.0, 0.25): 0.8
(6, 100.0, 100.0, 0.275): 0.6
(6, 100.0, 100.0, 0.3): 0.533333333333
(7, 0.1, 0.1, 0.25): 0.733333333333
(7, 1.0, 1.0, 0.2): 0.333333333333
(7, 1.0, 1.0, 0.225): 0.4
(7, 1.0, 1.0, 0.25): 0.666666666667
(7, 1.0, 1.0, 0.275): 0.8
(7, 1.0, 1.0, 0.3): 0.8
(7, 10.0, 10.0, 0.2): 0.533333333333
(7, 10.0, 10.0, 0.225): 0.2
(7, 10.0, 10.0, 0.25): 0.666666666667
(7, 10.0, 10.0, 0.275): 0.666666666667
(7, 10.0, 10.0, 0.3): 0.6
(7, 100.0, 100.0, 0.2): 0.6
(7, 100.0, 100.0, 0.225): 0.466666666667
(7, 100.0, 100.0, 0.25): 0.533333333333
(7, 100.0, 100.0, 0.275): 0.466666666667
(7, 100.0, 100.0, 0.3): 0.466666666667
(8, 1.0, 1.0, 0.2): 0.6
(8, 1.0, 1.0, 0.225): 0.2
(8, 1.0, 1.0, 0.25): 0.466666666667
(8, 1.0, 1.0, 0.275): 0.733333333333
(8, 1.0, 1.0, 0.3): 0.6
(8, 10.0, 10.0, 0.2): 0.666666666667
(8, 10.0, 10.0, 0.225): 0.6
(8, 10.0, 10.0, 0.25): 0.266666666667
(8, 10.0, 10.0, 0.275): 0.733333333333
(8, 10.0, 10.0, 0.3): 0.533333333333
(8, 100.0, 100.0, 0.2): 0.8
(8, 100.0, 100.0, 0.225): 0.266666666667
(8, 100.0, 100.0, 0.25): 0.466666666667
(8, 100.0, 100.0, 0.275): 0.6
(8, 100.0, 100.0, 0.3): 0.666666666667
(9, 1.0, 1.0, 0.2): 0.6
(9, 1.0, 1.0, 0.225): 0.733333333333
(9, 1.0, 1.0, 0.25): 0.6
(9, 1.0, 1.0, 0.275): 0.533333333333
(9, 1.0, 1.0, 0.3): 0.333333333333
(9, 10.0, 10.0, 0.2): 0.6
(9, 10.0, 10.0, 0.225): 0.6
(9, 10.0, 10.0, 0.25): 0.6
(9, 10.0, 10.0, 0.275): 0.333333333333
(9, 10.0, 10.0, 0.3): 0.533333333333
(9, 100.0, 100.0, 0.2): 0.4
(9, 100.0, 100.0, 0.225): 0.533333333333
(9, 100.0, 100.0, 0.25): 0.4
(9, 100.0, 100.0, 0.275): 0.466666666667
(9, 100.0, 100.0, 0.3): 0.466666666667

Accuracy mean :0.4348387096774194
Std deviation :0.1370106834901927
Loss mean :0.5651612903225806
Std deviation :0.1370106834901927



Linear_2dim, number of iterations: 10

Parameters info
Tradeoffs parameter: [  0.1   1.   10.  100. ]
Using same parameters for all the clusterization: True
Gaussian kernel sigmas: [0.2   0.225 0.25  0.275 0.3  ]
Number of principal dimension considerated: 2
Dataset length: 150

Clusterization info
Minimum size of a cluster: in perc: 0.01, in int: 2
Type of mu: Binary Muzzifier
Fuzzifier: Linear
Cluster graph uses all connections: False
Cluster to label info
Force the number of cluster to be the number of different labels: False
Force the labels to be always represent by a cluster: False

Validation info
Conflict resolution: random
Number of cluster considerated for validation (top_k): None


RESULTS

On TEST set

Accuracy on test set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 100.0, 100.0, 0.25): 0.733333333333
(1, 1.0, 1.0, 0.2): 0.866666666667
(2, 10.0, 10.0, 0.25): 0.733333333333
(3, 1.0, 1.0, 0.225): 0.866666666667
(4, 1.0, 1.0, 0.2): 0.933333333333
(5, 100.0, 100.0, 0.3): 0.266666666667
(6, 100.0, 100.0, 0.225): 0.666666666667
(7, 100.0, 100.0, 0.225): 1.0
(8, 1.0, 1.0, 0.2): 0.933333333333
(9, 10.0, 10.0, 0.3): 0.6

Loss on test set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 100.0, 100.0, 0.25): 0.266666666667
(1, 1.0, 1.0, 0.2): 0.133333333333
(2, 10.0, 10.0, 0.25): 0.266666666667
(3, 1.0, 1.0, 0.225): 0.133333333333
(4, 1.0, 1.0, 0.2): 0.0666666666667
(5, 100.0, 100.0, 0.3): 0.733333333333
(6, 100.0, 100.0, 0.225): 0.333333333333
(7, 100.0, 100.0, 0.225): 0.0
(8, 1.0, 1.0, 0.2): 0.0666666666667
(9, 10.0, 10.0, 0.3): 0.4

Accuracy mean :0.76
Std deviation :0.2048305532764962
Loss mean :0.24
Std deviation :0.20483055327649619

On TRAINING set

Accuracy on training set for every iteration (n_of_the_iter, c, sigma):
(0, 100.0, 100.0, 0.25): 0.755555555556
(1, 1.0, 1.0, 0.2): 0.911111111111
(2, 10.0, 10.0, 0.25): 0.785185185185
(3, 1.0, 1.0, 0.225): 0.874074074074
(4, 1.0, 1.0, 0.2): 0.859259259259
(5, 100.0, 100.0, 0.3): 0.340740740741
(6, 100.0, 100.0, 0.225): 0.785185185185
(7, 100.0, 100.0, 0.225): 0.874074074074
(8, 1.0, 1.0, 0.2): 0.933333333333
(9, 10.0, 10.0, 0.3): 0.674074074074
Loss on training set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 100.0, 100.0, 0.25): 0.244444444444
(1, 1.0, 1.0, 0.2): 0.0888888888889
(2, 10.0, 10.0, 0.25): 0.214814814815
(3, 1.0, 1.0, 0.225): 0.125925925926
(4, 1.0, 1.0, 0.2): 0.140740740741
(5, 100.0, 100.0, 0.3): 0.659259259259
(6, 100.0, 100.0, 0.225): 0.214814814815
(7, 100.0, 100.0, 0.225): 0.125925925926
(8, 1.0, 1.0, 0.2): 0.0666666666667
(9, 10.0, 10.0, 0.3): 0.325925925926

Accuracy mean :0.7792592592592593
Std deviation :0.1641639249003359
Loss mean :0.22074074074074077
Std deviation :0.16416392490033588

On ALL the sets

Accuracy on all the set for every iteration, for every couple c,sigma (n_of_the_iter, c, sigma):
(0, 1.0, 1.0, 0.2): 0.8
(0, 1.0, 1.0, 0.225): 0.8
(0, 1.0, 1.0, 0.25): 0.8
(0, 1.0, 1.0, 0.275): 0.533333333333
(0, 1.0, 1.0, 0.3): 0.533333333333
(0, 10.0, 10.0, 0.2): 0.8
(0, 10.0, 10.0, 0.225): 0.8
(0, 10.0, 10.0, 0.25): 0.8
(0, 10.0, 10.0, 0.275): 0.533333333333
(0, 10.0, 10.0, 0.3): 0.533333333333
(0, 100.0, 100.0, 0.2): 0.8
(0, 100.0, 100.0, 0.225): 0.8
(0, 100.0, 100.0, 0.25): 0.8
(0, 100.0, 100.0, 0.275): 0.533333333333
(0, 100.0, 100.0, 0.3): 0.533333333333
(1, 0.1, 0.1, 0.275): 0.733333333333
(1, 1.0, 1.0, 0.2): 0.933333333333
(1, 1.0, 1.0, 0.225): 0.933333333333
(1, 1.0, 1.0, 0.25): 0.933333333333
(1, 1.0, 1.0, 0.275): 0.733333333333
(1, 1.0, 1.0, 0.3): 0.666666666667
(1, 10.0, 10.0, 0.2): 0.933333333333
(1, 10.0, 10.0, 0.225): 0.933333333333
(1, 10.0, 10.0, 0.25): 0.666666666667
(1, 10.0, 10.0, 0.275): 0.733333333333
(1, 10.0, 10.0, 0.3): 0.666666666667
(1, 100.0, 100.0, 0.2): 0.933333333333
(1, 100.0, 100.0, 0.225): 0.933333333333
(1, 100.0, 100.0, 0.25): 0.666666666667
(1, 100.0, 100.0, 0.275): 0.733333333333
(1, 100.0, 100.0, 0.3): 0.666666666667
(2, 1.0, 1.0, 0.2): 0.666666666667
(2, 1.0, 1.0, 0.225): 0.266666666667
(2, 1.0, 1.0, 0.25): 0.733333333333
(2, 1.0, 1.0, 0.275): 0.733333333333
(2, 1.0, 1.0, 0.3): 0.6
(2, 10.0, 10.0, 0.2): 0.666666666667
(2, 10.0, 10.0, 0.225): 0.4
(2, 10.0, 10.0, 0.25): 0.733333333333
(2, 10.0, 10.0, 0.275): 0.733333333333
(2, 10.0, 10.0, 0.3): 0.6
(2, 100.0, 100.0, 0.2): 0.666666666667
(2, 100.0, 100.0, 0.225): 0.333333333333
(2, 100.0, 100.0, 0.25): 0.733333333333
(2, 100.0, 100.0, 0.275): 0.733333333333
(2, 100.0, 100.0, 0.3): 0.6
(3, 1.0, 1.0, 0.2): 0.933333333333
(3, 1.0, 1.0, 0.225): 0.933333333333
(3, 1.0, 1.0, 0.25): 0.933333333333
(3, 1.0, 1.0, 0.275): 0.133333333333
(3, 1.0, 1.0, 0.3): 0.4
(3, 10.0, 10.0, 0.2): 0.933333333333
(3, 10.0, 10.0, 0.225): 0.933333333333
(3, 10.0, 10.0, 0.25): 0.933333333333
(3, 10.0, 10.0, 0.275): 0.733333333333
(3, 10.0, 10.0, 0.3): 0.4
(3, 100.0, 100.0, 0.2): 0.933333333333
(3, 100.0, 100.0, 0.225): 0.933333333333
(3, 100.0, 100.0, 0.25): 0.866666666667
(3, 100.0, 100.0, 0.275): 0.733333333333
(3, 100.0, 100.0, 0.3): 0.4
(4, 1.0, 1.0, 0.2): 0.933333333333
(4, 1.0, 1.0, 0.225): 0.666666666667
(4, 1.0, 1.0, 0.25): 0.333333333333
(4, 1.0, 1.0, 0.275): 0.733333333333
(4, 1.0, 1.0, 0.3): 0.4
(4, 10.0, 10.0, 0.2): 0.933333333333
(4, 10.0, 10.0, 0.225): 0.866666666667
(4, 10.0, 10.0, 0.25): 0.866666666667
(4, 10.0, 10.0, 0.275): 0.8
(4, 10.0, 10.0, 0.3): 0.4
(4, 100.0, 100.0, 0.2): 0.933333333333
(4, 100.0, 100.0, 0.225): 0.866666666667
(4, 100.0, 100.0, 0.25): 0.866666666667
(4, 100.0, 100.0, 0.275): 0.8
(4, 100.0, 100.0, 0.3): 0.4
(5, 0.1, 0.1, 0.275): 0.4
(5, 1.0, 1.0, 0.2): 0.866666666667
(5, 1.0, 1.0, 0.225): 0.8
(5, 1.0, 1.0, 0.25): 0.6
(5, 1.0, 1.0, 0.275): 0.4
(5, 1.0, 1.0, 0.3): 0.866666666667
(5, 10.0, 10.0, 0.2): 0.866666666667
(5, 10.0, 10.0, 0.225): 0.8
(5, 10.0, 10.0, 0.25): 0.6
(5, 10.0, 10.0, 0.275): 0.4
(5, 10.0, 10.0, 0.3): 0.866666666667
(5, 100.0, 100.0, 0.2): 0.866666666667
(5, 100.0, 100.0, 0.225): 0.8
(5, 100.0, 100.0, 0.25): 0.733333333333
(5, 100.0, 100.0, 0.275): 0.4
(5, 100.0, 100.0, 0.3): 0.866666666667
(6, 0.1, 0.1, 0.3): 0.133333333333
(6, 1.0, 1.0, 0.2): 0.8
(6, 1.0, 1.0, 0.225): 0.8
(6, 1.0, 1.0, 0.25): 0.133333333333
(6, 1.0, 1.0, 0.275): 0.6
(6, 1.0, 1.0, 0.3): 0.133333333333
(6, 10.0, 10.0, 0.2): 0.8
(6, 10.0, 10.0, 0.225): 0.8
(6, 10.0, 10.0, 0.25): 0.266666666667
(6, 10.0, 10.0, 0.275): 0.6
(6, 10.0, 10.0, 0.3): 0.733333333333
(6, 100.0, 100.0, 0.2): 0.8
(6, 100.0, 100.0, 0.225): 0.8
(6, 100.0, 100.0, 0.25): 0.133333333333
(6, 100.0, 100.0, 0.275): 0.733333333333
(6, 100.0, 100.0, 0.3): 0.133333333333
(7, 0.1, 0.1, 0.25): 0.666666666667
(7, 1.0, 1.0, 0.2): 0.8
(7, 1.0, 1.0, 0.225): 0.866666666667
(7, 1.0, 1.0, 0.25): 0.666666666667
(7, 1.0, 1.0, 0.275): 0.866666666667
(7, 1.0, 1.0, 0.3): 0.533333333333
(7, 10.0, 10.0, 0.2): 0.933333333333
(7, 10.0, 10.0, 0.225): 0.866666666667
(7, 10.0, 10.0, 0.25): 0.666666666667
(7, 10.0, 10.0, 0.275): 0.933333333333
(7, 10.0, 10.0, 0.3): 0.533333333333
(7, 100.0, 100.0, 0.2): 0.933333333333
(7, 100.0, 100.0, 0.225): 0.933333333333
(7, 100.0, 100.0, 0.25): 0.666666666667
(7, 100.0, 100.0, 0.275): 0.866666666667
(7, 100.0, 100.0, 0.3): 0.533333333333
(8, 1.0, 1.0, 0.2): 0.866666666667
(8, 1.0, 1.0, 0.225): 0.533333333333
(8, 1.0, 1.0, 0.25): 0.733333333333
(8, 1.0, 1.0, 0.275): 0.8
(8, 1.0, 1.0, 0.3): 0.8
(8, 10.0, 10.0, 0.2): 0.866666666667
(8, 10.0, 10.0, 0.225): 0.533333333333
(8, 10.0, 10.0, 0.25): 0.733333333333
(8, 10.0, 10.0, 0.275): 0.8
(8, 10.0, 10.0, 0.3): 0.8
(8, 100.0, 100.0, 0.2): 0.733333333333
(8, 100.0, 100.0, 0.225): 0.533333333333
(8, 100.0, 100.0, 0.25): 0.733333333333
(8, 100.0, 100.0, 0.275): 0.8
(8, 100.0, 100.0, 0.3): 0.8
(9, 0.1, 0.1, 0.275): 0.733333333333
(9, 1.0, 1.0, 0.2): 0.733333333333
(9, 1.0, 1.0, 0.225): 0.0666666666667
(9, 1.0, 1.0, 0.25): 0.0666666666667
(9, 1.0, 1.0, 0.275): 0.733333333333
(9, 1.0, 1.0, 0.3): 0.733333333333
(9, 10.0, 10.0, 0.2): 0.733333333333
(9, 10.0, 10.0, 0.225): 0.0666666666667
(9, 10.0, 10.0, 0.25): 0.0666666666667
(9, 10.0, 10.0, 0.275): 0.6
(9, 10.0, 10.0, 0.3): 0.733333333333
(9, 100.0, 100.0, 0.2): 0.6
(9, 100.0, 100.0, 0.225): 0.0666666666667
(9, 100.0, 100.0, 0.25): 0.0666666666667
(9, 100.0, 100.0, 0.275): 0.6
(9, 100.0, 100.0, 0.3): 0.733333333333

Loss on all the set for every iteration, for every couple c,sigma (n_of_the_iter, best_c, best_sigma):
(0, 1.0, 1.0, 0.2): 0.2
(0, 1.0, 1.0, 0.225): 0.2
(0, 1.0, 1.0, 0.25): 0.2
(0, 1.0, 1.0, 0.275): 0.466666666667
(0, 1.0, 1.0, 0.3): 0.466666666667
(0, 10.0, 10.0, 0.2): 0.2
(0, 10.0, 10.0, 0.225): 0.2
(0, 10.0, 10.0, 0.25): 0.2
(0, 10.0, 10.0, 0.275): 0.466666666667
(0, 10.0, 10.0, 0.3): 0.466666666667
(0, 100.0, 100.0, 0.2): 0.2
(0, 100.0, 100.0, 0.225): 0.2
(0, 100.0, 100.0, 0.25): 0.2
(0, 100.0, 100.0, 0.275): 0.466666666667
(0, 100.0, 100.0, 0.3): 0.466666666667
(1, 0.1, 0.1, 0.275): 0.266666666667
(1, 1.0, 1.0, 0.2): 0.0666666666667
(1, 1.0, 1.0, 0.225): 0.0666666666667
(1, 1.0, 1.0, 0.25): 0.0666666666667
(1, 1.0, 1.0, 0.275): 0.266666666667
(1, 1.0, 1.0, 0.3): 0.333333333333
(1, 10.0, 10.0, 0.2): 0.0666666666667
(1, 10.0, 10.0, 0.225): 0.0666666666667
(1, 10.0, 10.0, 0.25): 0.333333333333
(1, 10.0, 10.0, 0.275): 0.266666666667
(1, 10.0, 10.0, 0.3): 0.333333333333
(1, 100.0, 100.0, 0.2): 0.0666666666667
(1, 100.0, 100.0, 0.225): 0.0666666666667
(1, 100.0, 100.0, 0.25): 0.333333333333
(1, 100.0, 100.0, 0.275): 0.266666666667
(1, 100.0, 100.0, 0.3): 0.333333333333
(2, 1.0, 1.0, 0.2): 0.333333333333
(2, 1.0, 1.0, 0.225): 0.733333333333
(2, 1.0, 1.0, 0.25): 0.266666666667
(2, 1.0, 1.0, 0.275): 0.266666666667
(2, 1.0, 1.0, 0.3): 0.4
(2, 10.0, 10.0, 0.2): 0.333333333333
(2, 10.0, 10.0, 0.225): 0.6
(2, 10.0, 10.0, 0.25): 0.266666666667
(2, 10.0, 10.0, 0.275): 0.266666666667
(2, 10.0, 10.0, 0.3): 0.4
(2, 100.0, 100.0, 0.2): 0.333333333333
(2, 100.0, 100.0, 0.225): 0.666666666667
(2, 100.0, 100.0, 0.25): 0.266666666667
(2, 100.0, 100.0, 0.275): 0.266666666667
(2, 100.0, 100.0, 0.3): 0.4
(3, 1.0, 1.0, 0.2): 0.0666666666667
(3, 1.0, 1.0, 0.225): 0.0666666666667
(3, 1.0, 1.0, 0.25): 0.0666666666667
(3, 1.0, 1.0, 0.275): 0.866666666667
(3, 1.0, 1.0, 0.3): 0.6
(3, 10.0, 10.0, 0.2): 0.0666666666667
(3, 10.0, 10.0, 0.225): 0.0666666666667
(3, 10.0, 10.0, 0.25): 0.0666666666667
(3, 10.0, 10.0, 0.275): 0.266666666667
(3, 10.0, 10.0, 0.3): 0.6
(3, 100.0, 100.0, 0.2): 0.0666666666667
(3, 100.0, 100.0, 0.225): 0.0666666666667
(3, 100.0, 100.0, 0.25): 0.133333333333
(3, 100.0, 100.0, 0.275): 0.266666666667
(3, 100.0, 100.0, 0.3): 0.6
(4, 1.0, 1.0, 0.2): 0.0666666666667
(4, 1.0, 1.0, 0.225): 0.333333333333
(4, 1.0, 1.0, 0.25): 0.666666666667
(4, 1.0, 1.0, 0.275): 0.266666666667
(4, 1.0, 1.0, 0.3): 0.6
(4, 10.0, 10.0, 0.2): 0.0666666666667
(4, 10.0, 10.0, 0.225): 0.133333333333
(4, 10.0, 10.0, 0.25): 0.133333333333
(4, 10.0, 10.0, 0.275): 0.2
(4, 10.0, 10.0, 0.3): 0.6
(4, 100.0, 100.0, 0.2): 0.0666666666667
(4, 100.0, 100.0, 0.225): 0.133333333333
(4, 100.0, 100.0, 0.25): 0.133333333333
(4, 100.0, 100.0, 0.275): 0.2
(4, 100.0, 100.0, 0.3): 0.6
(5, 0.1, 0.1, 0.275): 0.6
(5, 1.0, 1.0, 0.2): 0.133333333333
(5, 1.0, 1.0, 0.225): 0.2
(5, 1.0, 1.0, 0.25): 0.4
(5, 1.0, 1.0, 0.275): 0.6
(5, 1.0, 1.0, 0.3): 0.133333333333
(5, 10.0, 10.0, 0.2): 0.133333333333
(5, 10.0, 10.0, 0.225): 0.2
(5, 10.0, 10.0, 0.25): 0.4
(5, 10.0, 10.0, 0.275): 0.6
(5, 10.0, 10.0, 0.3): 0.133333333333
(5, 100.0, 100.0, 0.2): 0.133333333333
(5, 100.0, 100.0, 0.225): 0.2
(5, 100.0, 100.0, 0.25): 0.266666666667
(5, 100.0, 100.0, 0.275): 0.6
(5, 100.0, 100.0, 0.3): 0.133333333333
(6, 0.1, 0.1, 0.3): 0.866666666667
(6, 1.0, 1.0, 0.2): 0.2
(6, 1.0, 1.0, 0.225): 0.2
(6, 1.0, 1.0, 0.25): 0.866666666667
(6, 1.0, 1.0, 0.275): 0.4
(6, 1.0, 1.0, 0.3): 0.866666666667
(6, 10.0, 10.0, 0.2): 0.2
(6, 10.0, 10.0, 0.225): 0.2
(6, 10.0, 10.0, 0.25): 0.733333333333
(6, 10.0, 10.0, 0.275): 0.4
(6, 10.0, 10.0, 0.3): 0.266666666667
(6, 100.0, 100.0, 0.2): 0.2
(6, 100.0, 100.0, 0.225): 0.2
(6, 100.0, 100.0, 0.25): 0.866666666667
(6, 100.0, 100.0, 0.275): 0.266666666667
(6, 100.0, 100.0, 0.3): 0.866666666667
(7, 0.1, 0.1, 0.25): 0.333333333333
(7, 1.0, 1.0, 0.2): 0.2
(7, 1.0, 1.0, 0.225): 0.133333333333
(7, 1.0, 1.0, 0.25): 0.333333333333
(7, 1.0, 1.0, 0.275): 0.133333333333
(7, 1.0, 1.0, 0.3): 0.466666666667
(7, 10.0, 10.0, 0.2): 0.0666666666667
(7, 10.0, 10.0, 0.225): 0.133333333333
(7, 10.0, 10.0, 0.25): 0.333333333333
(7, 10.0, 10.0, 0.275): 0.0666666666667
(7, 10.0, 10.0, 0.3): 0.466666666667
(7, 100.0, 100.0, 0.2): 0.0666666666667
(7, 100.0, 100.0, 0.225): 0.0666666666667
(7, 100.0, 100.0, 0.25): 0.333333333333
(7, 100.0, 100.0, 0.275): 0.133333333333
(7, 100.0, 100.0, 0.3): 0.466666666667
(8, 1.0, 1.0, 0.2): 0.133333333333
(8, 1.0, 1.0, 0.225): 0.466666666667
(8, 1.0, 1.0, 0.25): 0.266666666667
(8, 1.0, 1.0, 0.275): 0.2
(8, 1.0, 1.0, 0.3): 0.2
(8, 10.0, 10.0, 0.2): 0.133333333333
(8, 10.0, 10.0, 0.225): 0.466666666667
(8, 10.0, 10.0, 0.25): 0.266666666667
(8, 10.0, 10.0, 0.275): 0.2
(8, 10.0, 10.0, 0.3): 0.2
(8, 100.0, 100.0, 0.2): 0.266666666667
(8, 100.0, 100.0, 0.225): 0.466666666667
(8, 100.0, 100.0, 0.25): 0.266666666667
(8, 100.0, 100.0, 0.275): 0.2
(8, 100.0, 100.0, 0.3): 0.2
(9, 0.1, 0.1, 0.275): 0.266666666667
(9, 1.0, 1.0, 0.2): 0.266666666667
(9, 1.0, 1.0, 0.225): 0.933333333333
(9, 1.0, 1.0, 0.25): 0.933333333333
(9, 1.0, 1.0, 0.275): 0.266666666667
(9, 1.0, 1.0, 0.3): 0.266666666667
(9, 10.0, 10.0, 0.2): 0.266666666667
(9, 10.0, 10.0, 0.225): 0.933333333333
(9, 10.0, 10.0, 0.25): 0.933333333333
(9, 10.0, 10.0, 0.275): 0.4
(9, 10.0, 10.0, 0.3): 0.266666666667
(9, 100.0, 100.0, 0.2): 0.4
(9, 100.0, 100.0, 0.225): 0.933333333333
(9, 100.0, 100.0, 0.25): 0.933333333333
(9, 100.0, 100.0, 0.275): 0.4
(9, 100.0, 100.0, 0.3): 0.266666666667

Accuracy mean :0.6744086021505377
Std deviation :0.23118269567389685
Loss mean :0.3255913978494624
Std deviation :0.23118269567389685



QuantileConstPiecewise_2dim, number of iterations: 10

Parameters info
Tradeoffs parameter: [  0.1   1.   10.  100. ]
Using same parameters for all the clusterization: True
Gaussian kernel sigmas: [0.2   0.225 0.25  0.275 0.3  ]
Number of principal dimension considerated: 2
Dataset length: 150

Clusterization info
Minimum size of a cluster: in perc: 0.01, in int: 2
Type of mu: Binary Muzzifier
Fuzzifier: QuantileConstPiecewise
Cluster graph uses all connections: False
Cluster to label info
Force the number of cluster to be the number of different labels: False
Force the labels to be always represent by a cluster: False

Validation info
Conflict resolution: random
Number of cluster considerated for validation (top_k): None


RESULTS

On TEST set

Accuracy on test set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 1.0, 1.0, 0.3): 0.533333333333
(1, 1.0, 1.0, 0.275): 0.8
(2, 100.0, 100.0, 0.25): 0.533333333333
(3, 100.0, 100.0, 0.3): 0.666666666667
(4, 100.0, 100.0, 0.275): 0.8
(5, 10.0, 10.0, 0.25): 0.8
(6, 1.0, 1.0, 0.275): 0.6
(7, 10.0, 10.0, 0.25): 0.533333333333
(8, 10.0, 10.0, 0.275): 0.466666666667
(9, 1.0, 1.0, 0.225): 0.4

Loss on test set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 1.0, 1.0, 0.3): 0.466666666667
(1, 1.0, 1.0, 0.275): 0.2
(2, 100.0, 100.0, 0.25): 0.466666666667
(3, 100.0, 100.0, 0.3): 0.333333333333
(4, 100.0, 100.0, 0.275): 0.2
(5, 10.0, 10.0, 0.25): 0.2
(6, 1.0, 1.0, 0.275): 0.4
(7, 10.0, 10.0, 0.25): 0.466666666667
(8, 10.0, 10.0, 0.275): 0.533333333333
(9, 1.0, 1.0, 0.225): 0.6

Accuracy mean :0.6133333333333334
Std deviation :0.139204086785474
Loss mean :0.3866666666666667
Std deviation :0.139204086785474

On TRAINING set

Accuracy on training set for every iteration (n_of_the_iter, c, sigma):
(0, 1.0, 1.0, 0.3): 0.681481481481
(1, 1.0, 1.0, 0.275): 0.792592592593
(2, 100.0, 100.0, 0.25): 0.674074074074
(3, 100.0, 100.0, 0.3): 0.748148148148
(4, 100.0, 100.0, 0.275): 0.837037037037
(5, 10.0, 10.0, 0.25): 0.725925925926
(6, 1.0, 1.0, 0.275): 0.674074074074
(7, 10.0, 10.0, 0.25): 0.711111111111
(8, 10.0, 10.0, 0.275): 0.659259259259
(9, 1.0, 1.0, 0.225): 0.644444444444
Loss on training set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 1.0, 1.0, 0.3): 0.318518518519
(1, 1.0, 1.0, 0.275): 0.207407407407
(2, 100.0, 100.0, 0.25): 0.325925925926
(3, 100.0, 100.0, 0.3): 0.251851851852
(4, 100.0, 100.0, 0.275): 0.162962962963
(5, 10.0, 10.0, 0.25): 0.274074074074
(6, 1.0, 1.0, 0.275): 0.325925925926
(7, 10.0, 10.0, 0.25): 0.288888888889
(8, 10.0, 10.0, 0.275): 0.340740740741
(9, 1.0, 1.0, 0.225): 0.355555555556

Accuracy mean :0.7148148148148148
Std deviation :0.05891101377995136
Loss mean :0.28518518518518515
Std deviation :0.05891101377995136

On ALL the sets

Accuracy on all the set for every iteration, for every couple c,sigma (n_of_the_iter, c, sigma):
(0, 0.1, 0.1, 0.25): 0.733333333333
(0, 1.0, 1.0, 0.2): 0.666666666667
(0, 1.0, 1.0, 0.225): 0.466666666667
(0, 1.0, 1.0, 0.25): 0.733333333333
(0, 1.0, 1.0, 0.275): 0.733333333333
(0, 1.0, 1.0, 0.3): 0.866666666667
(0, 10.0, 10.0, 0.2): 0.466666666667
(0, 10.0, 10.0, 0.225): 0.466666666667
(0, 10.0, 10.0, 0.25): 0.8
(0, 10.0, 10.0, 0.275): 0.733333333333
(0, 10.0, 10.0, 0.3): 0.866666666667
(0, 100.0, 100.0, 0.2): 0.6
(0, 100.0, 100.0, 0.225): 0.666666666667
(0, 100.0, 100.0, 0.25): 0.866666666667
(0, 100.0, 100.0, 0.275): 0.866666666667
(0, 100.0, 100.0, 0.3): 0.8
(1, 1.0, 1.0, 0.2): 0.2
(1, 1.0, 1.0, 0.225): 0.533333333333
(1, 1.0, 1.0, 0.275): 0.733333333333
(1, 1.0, 1.0, 0.3): 0.6
(1, 10.0, 10.0, 0.2): 0.466666666667
(1, 10.0, 10.0, 0.225): 0.6
(1, 10.0, 10.0, 0.25): 0.533333333333
(1, 10.0, 10.0, 0.275): 0.6
(1, 10.0, 10.0, 0.3): 0.6
(1, 100.0, 100.0, 0.2): 0.733333333333
(1, 100.0, 100.0, 0.225): 0.6
(1, 100.0, 100.0, 0.25): 0.533333333333
(1, 100.0, 100.0, 0.275): 0.6
(1, 100.0, 100.0, 0.3): 0.6
(2, 0.1, 0.1, 0.275): 0.8
(2, 0.1, 0.1, 0.3): 0.466666666667
(2, 1.0, 1.0, 0.2): 0.466666666667
(2, 1.0, 1.0, 0.225): 0.733333333333
(2, 1.0, 1.0, 0.25): 0.466666666667
(2, 1.0, 1.0, 0.275): 0.466666666667
(2, 1.0, 1.0, 0.3): 0.466666666667
(2, 10.0, 10.0, 0.2): 0.333333333333
(2, 10.0, 10.0, 0.225): 0.466666666667
(2, 10.0, 10.0, 0.25): 0.533333333333
(2, 10.0, 10.0, 0.275): 0.466666666667
(2, 10.0, 10.0, 0.3): 0.466666666667
(2, 100.0, 100.0, 0.2): 0.2
(2, 100.0, 100.0, 0.225): 0.6
(2, 100.0, 100.0, 0.25): 1.0
(2, 100.0, 100.0, 0.275): 0.466666666667
(2, 100.0, 100.0, 0.3): 0.466666666667
(3, 0.1, 0.1, 0.25): 0.533333333333
(3, 1.0, 1.0, 0.2): 0.266666666667
(3, 1.0, 1.0, 0.225): 0.533333333333
(3, 1.0, 1.0, 0.25): 0.533333333333
(3, 1.0, 1.0, 0.275): 0.733333333333
(3, 1.0, 1.0, 0.3): 0.733333333333
(3, 10.0, 10.0, 0.2): 0.266666666667
(3, 10.0, 10.0, 0.225): 0.666666666667
(3, 10.0, 10.0, 0.25): 0.533333333333
(3, 10.0, 10.0, 0.275): 0.733333333333
(3, 10.0, 10.0, 0.3): 0.733333333333
(3, 100.0, 100.0, 0.2): 0.266666666667
(3, 100.0, 100.0, 0.225): 0.533333333333
(3, 100.0, 100.0, 0.25): 0.533333333333
(3, 100.0, 100.0, 0.275): 0.733333333333
(3, 100.0, 100.0, 0.3): 0.8
(4, 0.1, 0.1, 0.275): 0.8
(4, 0.1, 0.1, 0.3): 0.666666666667
(4, 1.0, 1.0, 0.2): 0.4
(4, 1.0, 1.0, 0.225): 0.266666666667
(4, 1.0, 1.0, 0.25): 0.8
(4, 1.0, 1.0, 0.275): 0.8
(4, 1.0, 1.0, 0.3): 0.666666666667
(4, 10.0, 10.0, 0.2): 0.266666666667
(4, 10.0, 10.0, 0.225): 0.266666666667
(4, 10.0, 10.0, 0.25): 0.666666666667
(4, 10.0, 10.0, 0.275): 0.733333333333
(4, 10.0, 10.0, 0.3): 0.666666666667
(4, 100.0, 100.0, 0.2): 0.266666666667
(4, 100.0, 100.0, 0.225): 0.466666666667
(4, 100.0, 100.0, 0.25): 0.733333333333
(4, 100.0, 100.0, 0.275): 0.8
(4, 100.0, 100.0, 0.3): 0.666666666667
(5, 0.1, 0.1, 0.3): 0.8
(5, 1.0, 1.0, 0.2): 0.466666666667
(5, 1.0, 1.0, 0.225): 0.8
(5, 1.0, 1.0, 0.25): 0.6
(5, 1.0, 1.0, 0.275): 0.8
(5, 1.0, 1.0, 0.3): 0.8
(5, 10.0, 10.0, 0.2): 0.466666666667
(5, 10.0, 10.0, 0.225): 0.6
(5, 10.0, 10.0, 0.25): 0.8
(5, 10.0, 10.0, 0.275): 0.8
(5, 10.0, 10.0, 0.3): 0.8
(5, 100.0, 100.0, 0.2): 0.4
(5, 100.0, 100.0, 0.225): 0.666666666667
(5, 100.0, 100.0, 0.25): 0.8
(5, 100.0, 100.0, 0.275): 0.666666666667
(5, 100.0, 100.0, 0.3): 0.8
(6, 0.1, 0.1, 0.275): 0.8
(6, 1.0, 1.0, 0.2): 0.666666666667
(6, 1.0, 1.0, 0.225): 0.6
(6, 1.0, 1.0, 0.25): 0.6
(6, 1.0, 1.0, 0.275): 0.866666666667
(6, 1.0, 1.0, 0.3): 0.733333333333
(6, 10.0, 10.0, 0.2): 0.733333333333
(6, 10.0, 10.0, 0.225): 0.733333333333
(6, 10.0, 10.0, 0.25): 0.533333333333
(6, 10.0, 10.0, 0.275): 0.8
(6, 10.0, 10.0, 0.3): 0.666666666667
(6, 100.0, 100.0, 0.2): 0.6
(6, 100.0, 100.0, 0.225): 0.6
(6, 100.0, 100.0, 0.25): 0.8
(6, 100.0, 100.0, 0.275): 0.733333333333
(6, 100.0, 100.0, 0.3): 0.666666666667
(7, 0.1, 0.1, 0.3): 0.6
(7, 1.0, 1.0, 0.2): 0.333333333333
(7, 1.0, 1.0, 0.225): 0.6
(7, 1.0, 1.0, 0.25): 0.533333333333
(7, 1.0, 1.0, 0.275): 0.333333333333
(7, 1.0, 1.0, 0.3): 0.6
(7, 10.0, 10.0, 0.2): 0.4
(7, 10.0, 10.0, 0.225): 0.533333333333
(7, 10.0, 10.0, 0.25): 0.733333333333
(7, 10.0, 10.0, 0.275): 0.533333333333
(7, 10.0, 10.0, 0.3): 0.6
(7, 100.0, 100.0, 0.2): 0.466666666667
(7, 100.0, 100.0, 0.225): 0.533333333333
(7, 100.0, 100.0, 0.25): 0.533333333333
(7, 100.0, 100.0, 0.275): 0.4
(7, 100.0, 100.0, 0.3): 0.6
(8, 1.0, 1.0, 0.2): 0.6
(8, 1.0, 1.0, 0.225): 0.533333333333
(8, 1.0, 1.0, 0.25): 0.2
(8, 1.0, 1.0, 0.275): 0.466666666667
(8, 1.0, 1.0, 0.3): 0.6
(8, 10.0, 10.0, 0.2): 0.666666666667
(8, 10.0, 10.0, 0.225): 0.4
(8, 10.0, 10.0, 0.25): 0.2
(8, 10.0, 10.0, 0.275): 0.733333333333
(8, 10.0, 10.0, 0.3): 0.666666666667
(8, 100.0, 100.0, 0.2): 0.533333333333
(8, 100.0, 100.0, 0.225): 0.333333333333
(8, 100.0, 100.0, 0.25): 0.2
(8, 100.0, 100.0, 0.275): 0.533333333333
(8, 100.0, 100.0, 0.3): 0.466666666667
(9, 0.1, 0.1, 0.275): 0.666666666667
(9, 0.1, 0.1, 0.3): 0.666666666667
(9, 1.0, 1.0, 0.2): 0.6
(9, 1.0, 1.0, 0.225): 0.8
(9, 1.0, 1.0, 0.25): 0.733333333333
(9, 1.0, 1.0, 0.275): 0.733333333333
(9, 1.0, 1.0, 0.3): 0.666666666667
(9, 10.0, 10.0, 0.2): 0.666666666667
(9, 10.0, 10.0, 0.225): 0.8
(9, 10.0, 10.0, 0.25): 0.6
(9, 10.0, 10.0, 0.275): 0.6
(9, 10.0, 10.0, 0.3): 0.666666666667
(9, 100.0, 100.0, 0.2): 0.333333333333
(9, 100.0, 100.0, 0.225): 0.6
(9, 100.0, 100.0, 0.25): 0.666666666667
(9, 100.0, 100.0, 0.275): 0.733333333333
(9, 100.0, 100.0, 0.3): 0.666666666667

Loss on all the set for every iteration, for every couple c,sigma (n_of_the_iter, best_c, best_sigma):
(0, 0.1, 0.1, 0.25): 0.266666666667
(0, 1.0, 1.0, 0.2): 0.333333333333
(0, 1.0, 1.0, 0.225): 0.533333333333
(0, 1.0, 1.0, 0.25): 0.266666666667
(0, 1.0, 1.0, 0.275): 0.266666666667
(0, 1.0, 1.0, 0.3): 0.133333333333
(0, 10.0, 10.0, 0.2): 0.533333333333
(0, 10.0, 10.0, 0.225): 0.533333333333
(0, 10.0, 10.0, 0.25): 0.2
(0, 10.0, 10.0, 0.275): 0.266666666667
(0, 10.0, 10.0, 0.3): 0.133333333333
(0, 100.0, 100.0, 0.2): 0.4
(0, 100.0, 100.0, 0.225): 0.333333333333
(0, 100.0, 100.0, 0.25): 0.133333333333
(0, 100.0, 100.0, 0.275): 0.133333333333
(0, 100.0, 100.0, 0.3): 0.2
(1, 1.0, 1.0, 0.2): 0.8
(1, 1.0, 1.0, 0.225): 0.466666666667
(1, 1.0, 1.0, 0.275): 0.266666666667
(1, 1.0, 1.0, 0.3): 0.4
(1, 10.0, 10.0, 0.2): 0.533333333333
(1, 10.0, 10.0, 0.225): 0.4
(1, 10.0, 10.0, 0.25): 0.466666666667
(1, 10.0, 10.0, 0.275): 0.4
(1, 10.0, 10.0, 0.3): 0.4
(1, 100.0, 100.0, 0.2): 0.266666666667
(1, 100.0, 100.0, 0.225): 0.4
(1, 100.0, 100.0, 0.25): 0.466666666667
(1, 100.0, 100.0, 0.275): 0.4
(1, 100.0, 100.0, 0.3): 0.4
(2, 0.1, 0.1, 0.275): 0.2
(2, 0.1, 0.1, 0.3): 0.533333333333
(2, 1.0, 1.0, 0.2): 0.533333333333
(2, 1.0, 1.0, 0.225): 0.266666666667
(2, 1.0, 1.0, 0.25): 0.533333333333
(2, 1.0, 1.0, 0.275): 0.533333333333
(2, 1.0, 1.0, 0.3): 0.533333333333
(2, 10.0, 10.0, 0.2): 0.666666666667
(2, 10.0, 10.0, 0.225): 0.533333333333
(2, 10.0, 10.0, 0.25): 0.466666666667
(2, 10.0, 10.0, 0.275): 0.533333333333
(2, 10.0, 10.0, 0.3): 0.533333333333
(2, 100.0, 100.0, 0.2): 0.8
(2, 100.0, 100.0, 0.225): 0.4
(2, 100.0, 100.0, 0.25): 0.0
(2, 100.0, 100.0, 0.275): 0.533333333333
(2, 100.0, 100.0, 0.3): 0.533333333333
(3, 0.1, 0.1, 0.25): 0.466666666667
(3, 1.0, 1.0, 0.2): 0.733333333333
(3, 1.0, 1.0, 0.225): 0.466666666667
(3, 1.0, 1.0, 0.25): 0.466666666667
(3, 1.0, 1.0, 0.275): 0.266666666667
(3, 1.0, 1.0, 0.3): 0.266666666667
(3, 10.0, 10.0, 0.2): 0.733333333333
(3, 10.0, 10.0, 0.225): 0.333333333333
(3, 10.0, 10.0, 0.25): 0.466666666667
(3, 10.0, 10.0, 0.275): 0.266666666667
(3, 10.0, 10.0, 0.3): 0.266666666667
(3, 100.0, 100.0, 0.2): 0.733333333333
(3, 100.0, 100.0, 0.225): 0.466666666667
(3, 100.0, 100.0, 0.25): 0.466666666667
(3, 100.0, 100.0, 0.275): 0.266666666667
(3, 100.0, 100.0, 0.3): 0.2
(4, 0.1, 0.1, 0.275): 0.2
(4, 0.1, 0.1, 0.3): 0.333333333333
(4, 1.0, 1.0, 0.2): 0.6
(4, 1.0, 1.0, 0.225): 0.733333333333
(4, 1.0, 1.0, 0.25): 0.2
(4, 1.0, 1.0, 0.275): 0.2
(4, 1.0, 1.0, 0.3): 0.333333333333
(4, 10.0, 10.0, 0.2): 0.733333333333
(4, 10.0, 10.0, 0.225): 0.733333333333
(4, 10.0, 10.0, 0.25): 0.333333333333
(4, 10.0, 10.0, 0.275): 0.266666666667
(4, 10.0, 10.0, 0.3): 0.333333333333
(4, 100.0, 100.0, 0.2): 0.733333333333
(4, 100.0, 100.0, 0.225): 0.533333333333
(4, 100.0, 100.0, 0.25): 0.266666666667
(4, 100.0, 100.0, 0.275): 0.2
(4, 100.0, 100.0, 0.3): 0.333333333333
(5, 0.1, 0.1, 0.3): 0.2
(5, 1.0, 1.0, 0.2): 0.533333333333
(5, 1.0, 1.0, 0.225): 0.2
(5, 1.0, 1.0, 0.25): 0.4
(5, 1.0, 1.0, 0.275): 0.2
(5, 1.0, 1.0, 0.3): 0.2
(5, 10.0, 10.0, 0.2): 0.533333333333
(5, 10.0, 10.0, 0.225): 0.4
(5, 10.0, 10.0, 0.25): 0.2
(5, 10.0, 10.0, 0.275): 0.2
(5, 10.0, 10.0, 0.3): 0.2
(5, 100.0, 100.0, 0.2): 0.6
(5, 100.0, 100.0, 0.225): 0.333333333333
(5, 100.0, 100.0, 0.25): 0.2
(5, 100.0, 100.0, 0.275): 0.333333333333
(5, 100.0, 100.0, 0.3): 0.2
(6, 0.1, 0.1, 0.275): 0.2
(6, 1.0, 1.0, 0.2): 0.333333333333
(6, 1.0, 1.0, 0.225): 0.4
(6, 1.0, 1.0, 0.25): 0.4
(6, 1.0, 1.0, 0.275): 0.133333333333
(6, 1.0, 1.0, 0.3): 0.266666666667
(6, 10.0, 10.0, 0.2): 0.266666666667
(6, 10.0, 10.0, 0.225): 0.266666666667
(6, 10.0, 10.0, 0.25): 0.466666666667
(6, 10.0, 10.0, 0.275): 0.2
(6, 10.0, 10.0, 0.3): 0.333333333333
(6, 100.0, 100.0, 0.2): 0.4
(6, 100.0, 100.0, 0.225): 0.4
(6, 100.0, 100.0, 0.25): 0.2
(6, 100.0, 100.0, 0.275): 0.266666666667
(6, 100.0, 100.0, 0.3): 0.333333333333
(7, 0.1, 0.1, 0.3): 0.4
(7, 1.0, 1.0, 0.2): 0.666666666667
(7, 1.0, 1.0, 0.225): 0.4
(7, 1.0, 1.0, 0.25): 0.466666666667
(7, 1.0, 1.0, 0.275): 0.666666666667
(7, 1.0, 1.0, 0.3): 0.4
(7, 10.0, 10.0, 0.2): 0.6
(7, 10.0, 10.0, 0.225): 0.466666666667
(7, 10.0, 10.0, 0.25): 0.266666666667
(7, 10.0, 10.0, 0.275): 0.466666666667
(7, 10.0, 10.0, 0.3): 0.4
(7, 100.0, 100.0, 0.2): 0.533333333333
(7, 100.0, 100.0, 0.225): 0.466666666667
(7, 100.0, 100.0, 0.25): 0.466666666667
(7, 100.0, 100.0, 0.275): 0.6
(7, 100.0, 100.0, 0.3): 0.4
(8, 1.0, 1.0, 0.2): 0.4
(8, 1.0, 1.0, 0.225): 0.466666666667
(8, 1.0, 1.0, 0.25): 0.8
(8, 1.0, 1.0, 0.275): 0.533333333333
(8, 1.0, 1.0, 0.3): 0.4
(8, 10.0, 10.0, 0.2): 0.333333333333
(8, 10.0, 10.0, 0.225): 0.6
(8, 10.0, 10.0, 0.25): 0.8
(8, 10.0, 10.0, 0.275): 0.266666666667
(8, 10.0, 10.0, 0.3): 0.333333333333
(8, 100.0, 100.0, 0.2): 0.466666666667
(8, 100.0, 100.0, 0.225): 0.666666666667
(8, 100.0, 100.0, 0.25): 0.8
(8, 100.0, 100.0, 0.275): 0.466666666667
(8, 100.0, 100.0, 0.3): 0.533333333333
(9, 0.1, 0.1, 0.275): 0.333333333333
(9, 0.1, 0.1, 0.3): 0.333333333333
(9, 1.0, 1.0, 0.2): 0.4
(9, 1.0, 1.0, 0.225): 0.2
(9, 1.0, 1.0, 0.25): 0.266666666667
(9, 1.0, 1.0, 0.275): 0.266666666667
(9, 1.0, 1.0, 0.3): 0.333333333333
(9, 10.0, 10.0, 0.2): 0.333333333333
(9, 10.0, 10.0, 0.225): 0.2
(9, 10.0, 10.0, 0.25): 0.4
(9, 10.0, 10.0, 0.275): 0.4
(9, 10.0, 10.0, 0.3): 0.333333333333
(9, 100.0, 100.0, 0.2): 0.666666666667
(9, 100.0, 100.0, 0.225): 0.4
(9, 100.0, 100.0, 0.25): 0.333333333333
(9, 100.0, 100.0, 0.275): 0.266666666667
(9, 100.0, 100.0, 0.3): 0.333333333333

Accuracy mean :0.6004166666666666
Std deviation :0.1672484637032912
Loss mean :0.39958333333333335
Std deviation :0.16724846370329116



QuantileLinPiecewise_3dim, number of iterations: 10

Parameters info
Tradeoffs parameter: [  0.1   1.   10.  100. ]
Using same parameters for all the clusterization: True
Gaussian kernel sigmas: [0.2   0.225 0.25  0.275 0.3  ]
Number of principal dimension considerated: 3
Dataset length: 150

Clusterization info
Minimum size of a cluster: in perc: 0.01, in int: 2
Type of mu: Binary Muzzifier
Fuzzifier: QuantileLinPiecewise
Cluster graph uses all connections: False
Cluster to label info
Force the number of cluster to be the number of different labels: False
Force the labels to be always represent by a cluster: False

Validation info
Conflict resolution: random
Number of cluster considerated for validation (top_k): None


RESULTS

On TEST set

Accuracy on test set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 10.0, 10.0, 0.25): 0.733333333333
(1, 100.0, 100.0, 0.225): 0.866666666667
(2, 10.0, 10.0, 0.275): 1.0
(3, 1.0, 1.0, 0.2): 0.8
(4, 100.0, 100.0, 0.25): 0.866666666667
(5, 1.0, 1.0, 0.225): 0.466666666667
(6, 10.0, 10.0, 0.225): 0.866666666667
(7, 100.0, 100.0, 0.275): 0.933333333333
(8, 0.1, 0.1, 0.225): 0.533333333333
(9, 100.0, 100.0, 0.225): 0.933333333333

Loss on test set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 10.0, 10.0, 0.25): 0.266666666667
(1, 100.0, 100.0, 0.225): 0.133333333333
(2, 10.0, 10.0, 0.275): 0.0
(3, 1.0, 1.0, 0.2): 0.2
(4, 100.0, 100.0, 0.25): 0.133333333333
(5, 1.0, 1.0, 0.225): 0.533333333333
(6, 10.0, 10.0, 0.225): 0.133333333333
(7, 100.0, 100.0, 0.275): 0.0666666666667
(8, 0.1, 0.1, 0.225): 0.466666666667
(9, 100.0, 100.0, 0.225): 0.0666666666667

Accuracy mean :0.8
Std deviation :0.16599866130651644
Loss mean :0.19999999999999998
Std deviation :0.16599866130651644

On TRAINING set

Accuracy on training set for every iteration (n_of_the_iter, c, sigma):
(0, 10.0, 10.0, 0.25): 0.888888888889
(1, 100.0, 100.0, 0.225): 0.955555555556
(2, 10.0, 10.0, 0.275): 0.933333333333
(3, 1.0, 1.0, 0.2): 0.881481481481
(4, 100.0, 100.0, 0.25): 0.844444444444
(5, 1.0, 1.0, 0.225): 0.37037037037
(6, 10.0, 10.0, 0.225): 0.911111111111
(7, 100.0, 100.0, 0.275): 0.940740740741
(8, 0.1, 0.1, 0.225): 0.674074074074
(9, 100.0, 100.0, 0.225): 0.940740740741
Loss on training set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 10.0, 10.0, 0.25): 0.111111111111
(1, 100.0, 100.0, 0.225): 0.0444444444444
(2, 10.0, 10.0, 0.275): 0.0666666666667
(3, 1.0, 1.0, 0.2): 0.118518518519
(4, 100.0, 100.0, 0.25): 0.155555555556
(5, 1.0, 1.0, 0.225): 0.62962962963
(6, 10.0, 10.0, 0.225): 0.0888888888889
(7, 100.0, 100.0, 0.275): 0.0592592592593
(8, 0.1, 0.1, 0.225): 0.325925925926
(9, 100.0, 100.0, 0.225): 0.0592592592593

Accuracy mean :0.834074074074074
Std deviation :0.17299745869031113
Loss mean :0.16592592592592592
Std deviation :0.1729974586903111

On ALL the sets

Accuracy on all the set for every iteration, for every couple c,sigma (n_of_the_iter, c, sigma):
(0, 1.0, 1.0, 0.225): 0.866666666667
(0, 1.0, 1.0, 0.25): 0.933333333333
(0, 1.0, 1.0, 0.275): 0.933333333333
(0, 1.0, 1.0, 0.3): 0.733333333333
(0, 10.0, 10.0, 0.2): 0.133333333333
(0, 10.0, 10.0, 0.225): 0.866666666667
(0, 10.0, 10.0, 0.25): 0.933333333333
(0, 10.0, 10.0, 0.275): 0.933333333333
(0, 10.0, 10.0, 0.3): 0.733333333333
(0, 100.0, 100.0, 0.225): 0.933333333333
(0, 100.0, 100.0, 0.25): 0.933333333333
(0, 100.0, 100.0, 0.275): 0.8
(0, 100.0, 100.0, 0.3): 0.733333333333
(1, 0.1, 0.1, 0.275): 1.0
(1, 1.0, 1.0, 0.2): 1.0
(1, 1.0, 1.0, 0.225): 1.0
(1, 1.0, 1.0, 0.25): 1.0
(1, 1.0, 1.0, 0.275): 1.0
(1, 1.0, 1.0, 0.3): 0.933333333333
(1, 10.0, 10.0, 0.2): 1.0
(1, 10.0, 10.0, 0.225): 1.0
(1, 10.0, 10.0, 0.25): 1.0
(1, 10.0, 10.0, 0.275): 1.0
(1, 10.0, 10.0, 0.3): 0.933333333333
(1, 100.0, 100.0, 0.2): 1.0
(1, 100.0, 100.0, 0.225): 1.0
(1, 100.0, 100.0, 0.25): 1.0
(1, 100.0, 100.0, 0.275): 1.0
(1, 100.0, 100.0, 0.3): 0.933333333333
(2, 0.1, 0.1, 0.225): 0.733333333333
(2, 1.0, 1.0, 0.2): 0.8
(2, 1.0, 1.0, 0.225): 0.733333333333
(2, 1.0, 1.0, 0.25): 0.2
(2, 1.0, 1.0, 0.275): 0.866666666667
(2, 1.0, 1.0, 0.3): 0.6
(2, 10.0, 10.0, 0.2): 0.8
(2, 10.0, 10.0, 0.225): 0.733333333333
(2, 10.0, 10.0, 0.25): 0.2
(2, 10.0, 10.0, 0.275): 0.866666666667
(2, 10.0, 10.0, 0.3): 0.6
(2, 100.0, 100.0, 0.2): 0.8
(2, 100.0, 100.0, 0.225): 0.666666666667
(2, 100.0, 100.0, 0.25): 0.8
(2, 100.0, 100.0, 0.275): 0.733333333333
(2, 100.0, 100.0, 0.3): 0.6
(3, 1.0, 1.0, 0.2): 0.933333333333
(3, 1.0, 1.0, 0.225): 0.4
(3, 1.0, 1.0, 0.25): 0.8
(3, 1.0, 1.0, 0.275): 0.8
(3, 1.0, 1.0, 0.3): 0.8
(3, 10.0, 10.0, 0.2): 0.933333333333
(3, 10.0, 10.0, 0.225): 0.4
(3, 10.0, 10.0, 0.25): 0.8
(3, 10.0, 10.0, 0.275): 0.8
(3, 10.0, 10.0, 0.3): 0.8
(3, 100.0, 100.0, 0.2): 0.933333333333
(3, 100.0, 100.0, 0.225): 0.4
(3, 100.0, 100.0, 0.25): 0.8
(3, 100.0, 100.0, 0.275): 0.8
(3, 100.0, 100.0, 0.3): 0.8
(4, 0.1, 0.1, 0.225): 0.133333333333
(4, 1.0, 1.0, 0.2): 1.0
(4, 1.0, 1.0, 0.225): 0.133333333333
(4, 1.0, 1.0, 0.25): 1.0
(4, 1.0, 1.0, 0.275): 0.666666666667
(4, 1.0, 1.0, 0.3): 0.933333333333
(4, 10.0, 10.0, 0.2): 1.0
(4, 10.0, 10.0, 0.225): 0.133333333333
(4, 10.0, 10.0, 0.25): 1.0
(4, 10.0, 10.0, 0.275): 0.666666666667
(4, 10.0, 10.0, 0.3): 0.933333333333
(4, 100.0, 100.0, 0.2): 1.0
(4, 100.0, 100.0, 0.225): 0.133333333333
(4, 100.0, 100.0, 0.25): 1.0
(4, 100.0, 100.0, 0.275): 0.666666666667
(4, 100.0, 100.0, 0.3): 0.933333333333
(5, 0.1, 0.1, 0.25): 0.866666666667
(5, 0.1, 0.1, 0.275): 0.466666666667
(5, 1.0, 1.0, 0.2): 0.8
(5, 1.0, 1.0, 0.225): 0.933333333333
(5, 1.0, 1.0, 0.25): 0.866666666667
(5, 1.0, 1.0, 0.275): 0.466666666667
(5, 1.0, 1.0, 0.3): 0.466666666667
(5, 10.0, 10.0, 0.2): 0.8
(5, 10.0, 10.0, 0.225): 0.933333333333
(5, 10.0, 10.0, 0.25): 0.866666666667
(5, 10.0, 10.0, 0.275): 0.466666666667
(5, 10.0, 10.0, 0.3): 0.466666666667
(5, 100.0, 100.0, 0.225): 0.933333333333
(5, 100.0, 100.0, 0.25): 0.866666666667
(5, 100.0, 100.0, 0.275): 0.466666666667
(5, 100.0, 100.0, 0.3): 0.466666666667
(6, 1.0, 1.0, 0.2): 0.933333333333
(6, 1.0, 1.0, 0.225): 0.466666666667
(6, 1.0, 1.0, 0.25): 0.866666666667
(6, 1.0, 1.0, 0.275): 0.866666666667
(6, 1.0, 1.0, 0.3): 0.866666666667
(6, 10.0, 10.0, 0.2): 0.933333333333
(6, 10.0, 10.0, 0.225): 1.0
(6, 10.0, 10.0, 0.25): 0.866666666667
(6, 10.0, 10.0, 0.275): 0.866666666667
(6, 10.0, 10.0, 0.3): 0.866666666667
(6, 100.0, 100.0, 0.2): 0.933333333333
(6, 100.0, 100.0, 0.225): 0.533333333333
(6, 100.0, 100.0, 0.25): 0.866666666667
(6, 100.0, 100.0, 0.275): 0.866666666667
(6, 100.0, 100.0, 0.3): 0.866666666667
(7, 1.0, 1.0, 0.2): 0.933333333333
(7, 1.0, 1.0, 0.225): 0.933333333333
(7, 1.0, 1.0, 0.25): 1.0
(7, 1.0, 1.0, 0.275): 1.0
(7, 1.0, 1.0, 0.3): 1.0
(7, 10.0, 10.0, 0.2): 0.933333333333
(7, 10.0, 10.0, 0.225): 0.933333333333
(7, 10.0, 10.0, 0.25): 1.0
(7, 10.0, 10.0, 0.275): 1.0
(7, 10.0, 10.0, 0.3): 1.0
(7, 100.0, 100.0, 0.2): 0.933333333333
(7, 100.0, 100.0, 0.225): 0.933333333333
(7, 100.0, 100.0, 0.25): 1.0
(7, 100.0, 100.0, 0.275): 1.0
(7, 100.0, 100.0, 0.3): 1.0
(8, 0.1, 0.1, 0.225): 0.933333333333
(8, 0.1, 0.1, 0.25): 0.8
(8, 0.1, 0.1, 0.275): 0.8
(8, 1.0, 1.0, 0.2): 0.533333333333
(8, 1.0, 1.0, 0.225): 0.933333333333
(8, 1.0, 1.0, 0.25): 0.8
(8, 1.0, 1.0, 0.275): 0.8
(8, 1.0, 1.0, 0.3): 0.8
(8, 10.0, 10.0, 0.2): 0.733333333333
(8, 10.0, 10.0, 0.225): 0.933333333333
(8, 10.0, 10.0, 0.25): 0.8
(8, 10.0, 10.0, 0.275): 0.8
(8, 10.0, 10.0, 0.3): 0.8
(8, 100.0, 100.0, 0.2): 0.133333333333
(8, 100.0, 100.0, 0.225): 0.933333333333
(8, 100.0, 100.0, 0.25): 0.8
(8, 100.0, 100.0, 0.275): 0.8
(8, 100.0, 100.0, 0.3): 0.8
(9, 0.1, 0.1, 0.225): 0.866666666667
(9, 1.0, 1.0, 0.2): 0.8
(9, 1.0, 1.0, 0.225): 0.933333333333
(9, 1.0, 1.0, 0.25): 0.466666666667
(9, 1.0, 1.0, 0.275): 0.733333333333
(9, 1.0, 1.0, 0.3): 0.6
(9, 10.0, 10.0, 0.2): 0.8
(9, 10.0, 10.0, 0.225): 0.933333333333
(9, 10.0, 10.0, 0.25): 0.8
(9, 10.0, 10.0, 0.275): 0.733333333333
(9, 10.0, 10.0, 0.3): 0.6
(9, 100.0, 100.0, 0.2): 0.8
(9, 100.0, 100.0, 0.225): 0.933333333333
(9, 100.0, 100.0, 0.25): 0.6
(9, 100.0, 100.0, 0.275): 0.733333333333
(9, 100.0, 100.0, 0.3): 0.6

Loss on all the set for every iteration, for every couple c,sigma (n_of_the_iter, best_c, best_sigma):
(0, 1.0, 1.0, 0.225): 0.133333333333
(0, 1.0, 1.0, 0.25): 0.0666666666667
(0, 1.0, 1.0, 0.275): 0.0666666666667
(0, 1.0, 1.0, 0.3): 0.266666666667
(0, 10.0, 10.0, 0.2): 0.866666666667
(0, 10.0, 10.0, 0.225): 0.133333333333
(0, 10.0, 10.0, 0.25): 0.0666666666667
(0, 10.0, 10.0, 0.275): 0.0666666666667
(0, 10.0, 10.0, 0.3): 0.266666666667
(0, 100.0, 100.0, 0.225): 0.0666666666667
(0, 100.0, 100.0, 0.25): 0.0666666666667
(0, 100.0, 100.0, 0.275): 0.2
(0, 100.0, 100.0, 0.3): 0.266666666667
(1, 0.1, 0.1, 0.275): 0.0
(1, 1.0, 1.0, 0.2): 0.0
(1, 1.0, 1.0, 0.225): 0.0
(1, 1.0, 1.0, 0.25): 0.0
(1, 1.0, 1.0, 0.275): 0.0
(1, 1.0, 1.0, 0.3): 0.0666666666667
(1, 10.0, 10.0, 0.2): 0.0
(1, 10.0, 10.0, 0.225): 0.0
(1, 10.0, 10.0, 0.25): 0.0
(1, 10.0, 10.0, 0.275): 0.0
(1, 10.0, 10.0, 0.3): 0.0666666666667
(1, 100.0, 100.0, 0.2): 0.0
(1, 100.0, 100.0, 0.225): 0.0
(1, 100.0, 100.0, 0.25): 0.0
(1, 100.0, 100.0, 0.275): 0.0
(1, 100.0, 100.0, 0.3): 0.0666666666667
(2, 0.1, 0.1, 0.225): 0.266666666667
(2, 1.0, 1.0, 0.2): 0.2
(2, 1.0, 1.0, 0.225): 0.266666666667
(2, 1.0, 1.0, 0.25): 0.8
(2, 1.0, 1.0, 0.275): 0.133333333333
(2, 1.0, 1.0, 0.3): 0.4
(2, 10.0, 10.0, 0.2): 0.2
(2, 10.0, 10.0, 0.225): 0.266666666667
(2, 10.0, 10.0, 0.25): 0.8
(2, 10.0, 10.0, 0.275): 0.133333333333
(2, 10.0, 10.0, 0.3): 0.4
(2, 100.0, 100.0, 0.2): 0.2
(2, 100.0, 100.0, 0.225): 0.333333333333
(2, 100.0, 100.0, 0.25): 0.2
(2, 100.0, 100.0, 0.275): 0.266666666667
(2, 100.0, 100.0, 0.3): 0.4
(3, 1.0, 1.0, 0.2): 0.0666666666667
(3, 1.0, 1.0, 0.225): 0.6
(3, 1.0, 1.0, 0.25): 0.2
(3, 1.0, 1.0, 0.275): 0.2
(3, 1.0, 1.0, 0.3): 0.2
(3, 10.0, 10.0, 0.2): 0.0666666666667
(3, 10.0, 10.0, 0.225): 0.6
(3, 10.0, 10.0, 0.25): 0.2
(3, 10.0, 10.0, 0.275): 0.2
(3, 10.0, 10.0, 0.3): 0.2
(3, 100.0, 100.0, 0.2): 0.0666666666667
(3, 100.0, 100.0, 0.225): 0.6
(3, 100.0, 100.0, 0.25): 0.2
(3, 100.0, 100.0, 0.275): 0.2
(3, 100.0, 100.0, 0.3): 0.2
(4, 0.1, 0.1, 0.225): 0.866666666667
(4, 1.0, 1.0, 0.2): 0.0
(4, 1.0, 1.0, 0.225): 0.866666666667
(4, 1.0, 1.0, 0.25): 0.0
(4, 1.0, 1.0, 0.275): 0.333333333333
(4, 1.0, 1.0, 0.3): 0.0666666666667
(4, 10.0, 10.0, 0.2): 0.0
(4, 10.0, 10.0, 0.225): 0.866666666667
(4, 10.0, 10.0, 0.25): 0.0
(4, 10.0, 10.0, 0.275): 0.333333333333
(4, 10.0, 10.0, 0.3): 0.0666666666667
(4, 100.0, 100.0, 0.2): 0.0
(4, 100.0, 100.0, 0.225): 0.866666666667
(4, 100.0, 100.0, 0.25): 0.0
(4, 100.0, 100.0, 0.275): 0.333333333333
(4, 100.0, 100.0, 0.3): 0.0666666666667
(5, 0.1, 0.1, 0.25): 0.133333333333
(5, 0.1, 0.1, 0.275): 0.533333333333
(5, 1.0, 1.0, 0.2): 0.2
(5, 1.0, 1.0, 0.225): 0.0666666666667
(5, 1.0, 1.0, 0.25): 0.133333333333
(5, 1.0, 1.0, 0.275): 0.533333333333
(5, 1.0, 1.0, 0.3): 0.533333333333
(5, 10.0, 10.0, 0.2): 0.2
(5, 10.0, 10.0, 0.225): 0.0666666666667
(5, 10.0, 10.0, 0.25): 0.133333333333
(5, 10.0, 10.0, 0.275): 0.533333333333
(5, 10.0, 10.0, 0.3): 0.533333333333
(5, 100.0, 100.0, 0.225): 0.0666666666667
(5, 100.0, 100.0, 0.25): 0.133333333333
(5, 100.0, 100.0, 0.275): 0.533333333333
(5, 100.0, 100.0, 0.3): 0.533333333333
(6, 1.0, 1.0, 0.2): 0.0666666666667
(6, 1.0, 1.0, 0.225): 0.533333333333
(6, 1.0, 1.0, 0.25): 0.133333333333
(6, 1.0, 1.0, 0.275): 0.133333333333
(6, 1.0, 1.0, 0.3): 0.133333333333
(6, 10.0, 10.0, 0.2): 0.0666666666667
(6, 10.0, 10.0, 0.225): 0.0
(6, 10.0, 10.0, 0.25): 0.133333333333
(6, 10.0, 10.0, 0.275): 0.133333333333
(6, 10.0, 10.0, 0.3): 0.133333333333
(6, 100.0, 100.0, 0.2): 0.0666666666667
(6, 100.0, 100.0, 0.225): 0.466666666667
(6, 100.0, 100.0, 0.25): 0.133333333333
(6, 100.0, 100.0, 0.275): 0.133333333333
(6, 100.0, 100.0, 0.3): 0.133333333333
(7, 1.0, 1.0, 0.2): 0.0666666666667
(7, 1.0, 1.0, 0.225): 0.0666666666667
(7, 1.0, 1.0, 0.25): 0.0
(7, 1.0, 1.0, 0.275): 0.0
(7, 1.0, 1.0, 0.3): 0.0
(7, 10.0, 10.0, 0.2): 0.0666666666667
(7, 10.0, 10.0, 0.225): 0.0666666666667
(7, 10.0, 10.0, 0.25): 0.0
(7, 10.0, 10.0, 0.275): 0.0
(7, 10.0, 10.0, 0.3): 0.0
(7, 100.0, 100.0, 0.2): 0.0666666666667
(7, 100.0, 100.0, 0.225): 0.0666666666667
(7, 100.0, 100.0, 0.25): 0.0
(7, 100.0, 100.0, 0.275): 0.0
(7, 100.0, 100.0, 0.3): 0.0
(8, 0.1, 0.1, 0.225): 0.0666666666667
(8, 0.1, 0.1, 0.25): 0.2
(8, 0.1, 0.1, 0.275): 0.2
(8, 1.0, 1.0, 0.2): 0.466666666667
(8, 1.0, 1.0, 0.225): 0.0666666666667
(8, 1.0, 1.0, 0.25): 0.2
(8, 1.0, 1.0, 0.275): 0.2
(8, 1.0, 1.0, 0.3): 0.2
(8, 10.0, 10.0, 0.2): 0.266666666667
(8, 10.0, 10.0, 0.225): 0.0666666666667
(8, 10.0, 10.0, 0.25): 0.2
(8, 10.0, 10.0, 0.275): 0.2
(8, 10.0, 10.0, 0.3): 0.2
(8, 100.0, 100.0, 0.2): 0.866666666667
(8, 100.0, 100.0, 0.225): 0.0666666666667
(8, 100.0, 100.0, 0.25): 0.2
(8, 100.0, 100.0, 0.275): 0.2
(8, 100.0, 100.0, 0.3): 0.2
(9, 0.1, 0.1, 0.225): 0.133333333333
(9, 1.0, 1.0, 0.2): 0.2
(9, 1.0, 1.0, 0.225): 0.0666666666667
(9, 1.0, 1.0, 0.25): 0.533333333333
(9, 1.0, 1.0, 0.275): 0.266666666667
(9, 1.0, 1.0, 0.3): 0.4
(9, 10.0, 10.0, 0.2): 0.2
(9, 10.0, 10.0, 0.225): 0.0666666666667
(9, 10.0, 10.0, 0.25): 0.2
(9, 10.0, 10.0, 0.275): 0.266666666667
(9, 10.0, 10.0, 0.3): 0.4
(9, 100.0, 100.0, 0.2): 0.2
(9, 100.0, 100.0, 0.225): 0.0666666666667
(9, 100.0, 100.0, 0.25): 0.4
(9, 100.0, 100.0, 0.275): 0.266666666667
(9, 100.0, 100.0, 0.3): 0.4

Accuracy mean :0.7931623931623931
Std deviation :0.21552023948683058
Loss mean :0.20683760683760682
Std deviation :0.21552023948683058



Crisp_3dim, number of iterations: 10

Parameters info
Tradeoffs parameter: [  0.1   1.   10.  100. ]
Using same parameters for all the clusterization: True
Gaussian kernel sigmas: [0.2   0.225 0.25  0.275 0.3  ]
Number of principal dimension considerated: 3
Dataset length: 150

Clusterization info
Minimum size of a cluster: in perc: 0.01, in int: 2
Type of mu: Binary Muzzifier
Fuzzifier: Crisp
Cluster graph uses all connections: False
Cluster to label info
Force the number of cluster to be the number of different labels: False
Force the labels to be always represent by a cluster: False

Validation info
Conflict resolution: random
Number of cluster considerated for validation (top_k): None


RESULTS

On TEST set

Accuracy on test set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 1.0, 1.0, 0.3): 0.266666666667
(1, 1.0, 1.0, 0.3): 0.4
(2, 0.1, 0.1, 0.275): 0.266666666667
(3, 1.0, 1.0, 0.25): 0.666666666667
(4, 100.0, 100.0, 0.25): 0.533333333333
(5, 1.0, 1.0, 0.2): 0.133333333333
(6, 100.0, 100.0, 0.25): 0.533333333333
(7, 10.0, 10.0, 0.275): 0.333333333333
(8, 10.0, 10.0, 0.225): 0.333333333333
(9, 1.0, 1.0, 0.2): 0.333333333333

Loss on test set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 1.0, 1.0, 0.3): 0.733333333333
(1, 1.0, 1.0, 0.3): 0.6
(2, 0.1, 0.1, 0.275): 0.733333333333
(3, 1.0, 1.0, 0.25): 0.333333333333
(4, 100.0, 100.0, 0.25): 0.466666666667
(5, 1.0, 1.0, 0.2): 0.866666666667
(6, 100.0, 100.0, 0.25): 0.466666666667
(7, 10.0, 10.0, 0.275): 0.666666666667
(8, 10.0, 10.0, 0.225): 0.666666666667
(9, 1.0, 1.0, 0.2): 0.666666666667

Accuracy mean :0.38
Std deviation :0.14922019523732927
Loss mean :0.62
Std deviation :0.14922019523732927

On TRAINING set

Accuracy on training set for every iteration (n_of_the_iter, c, sigma):
(0, 1.0, 1.0, 0.3): 0.518518518519
(1, 1.0, 1.0, 0.3): 0.437037037037
(2, 0.1, 0.1, 0.275): 0.392592592593
(3, 1.0, 1.0, 0.25): 0.466666666667
(4, 100.0, 100.0, 0.25): 0.525925925926
(5, 1.0, 1.0, 0.2): 0.422222222222
(6, 100.0, 100.0, 0.25): 0.533333333333
(7, 10.0, 10.0, 0.275): 0.555555555556
(8, 10.0, 10.0, 0.225): 0.614814814815
(9, 1.0, 1.0, 0.2): 0.37037037037
Loss on training set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 1.0, 1.0, 0.3): 0.481481481481
(1, 1.0, 1.0, 0.3): 0.562962962963
(2, 0.1, 0.1, 0.275): 0.607407407407
(3, 1.0, 1.0, 0.25): 0.533333333333
(4, 100.0, 100.0, 0.25): 0.474074074074
(5, 1.0, 1.0, 0.2): 0.577777777778
(6, 100.0, 100.0, 0.25): 0.466666666667
(7, 10.0, 10.0, 0.275): 0.444444444444
(8, 10.0, 10.0, 0.225): 0.385185185185
(9, 1.0, 1.0, 0.2): 0.62962962963

Accuracy mean :0.4837037037037037
Std deviation :0.07429965650981164
Loss mean :0.5162962962962963
Std deviation :0.07429965650981164

On ALL the sets

Accuracy on all the set for every iteration, for every couple c,sigma (n_of_the_iter, c, sigma):
(0, 1.0, 1.0, 0.2): 0.0
(0, 1.0, 1.0, 0.225): 0.266666666667
(0, 1.0, 1.0, 0.25): 0.266666666667
(0, 1.0, 1.0, 0.275): 0.4
(0, 1.0, 1.0, 0.3): 0.6
(0, 10.0, 10.0, 0.2): 0.2
(0, 10.0, 10.0, 0.225): 0.4
(0, 10.0, 10.0, 0.25): 0.4
(0, 10.0, 10.0, 0.275): 0.333333333333
(0, 10.0, 10.0, 0.3): 0.533333333333
(0, 100.0, 100.0, 0.2): 0.133333333333
(0, 100.0, 100.0, 0.225): 0.6
(0, 100.0, 100.0, 0.25): 0.466666666667
(0, 100.0, 100.0, 0.275): 0.2
(0, 100.0, 100.0, 0.3): 0.466666666667
(1, 1.0, 1.0, 0.2): 0.4
(1, 1.0, 1.0, 0.225): 0.266666666667
(1, 1.0, 1.0, 0.25): 0.333333333333
(1, 1.0, 1.0, 0.275): 0.4
(1, 1.0, 1.0, 0.3): 0.533333333333
(1, 10.0, 10.0, 0.225): 0.333333333333
(1, 10.0, 10.0, 0.25): 0.333333333333
(1, 10.0, 10.0, 0.275): 0.333333333333
(1, 10.0, 10.0, 0.3): 0.266666666667
(1, 100.0, 100.0, 0.2): 0.4
(1, 100.0, 100.0, 0.225): 0.466666666667
(1, 100.0, 100.0, 0.25): 0.466666666667
(1, 100.0, 100.0, 0.275): 0.466666666667
(1, 100.0, 100.0, 0.3): 0.4
(2, 0.1, 0.1, 0.275): 0.466666666667
(2, 1.0, 1.0, 0.225): 0.333333333333
(2, 1.0, 1.0, 0.25): 0.333333333333
(2, 1.0, 1.0, 0.275): 0.0666666666667
(2, 1.0, 1.0, 0.3): 0.133333333333
(2, 10.0, 10.0, 0.2): 0.333333333333
(2, 10.0, 10.0, 0.225): 0.333333333333
(2, 10.0, 10.0, 0.25): 0.333333333333
(2, 10.0, 10.0, 0.275): 0.266666666667
(2, 10.0, 10.0, 0.3): 0.266666666667
(2, 100.0, 100.0, 0.225): 0.333333333333
(2, 100.0, 100.0, 0.25): 0.333333333333
(2, 100.0, 100.0, 0.275): 0.2
(2, 100.0, 100.0, 0.3): 0.333333333333
(3, 0.1, 0.1, 0.275): 0.2
(3, 1.0, 1.0, 0.2): 0.0666666666667
(3, 1.0, 1.0, 0.225): 0.2
(3, 1.0, 1.0, 0.25): 0.466666666667
(3, 1.0, 1.0, 0.275): 0.333333333333
(3, 10.0, 10.0, 0.2): 0.333333333333
(3, 10.0, 10.0, 0.225): 0.333333333333
(3, 10.0, 10.0, 0.25): 0.333333333333
(3, 10.0, 10.0, 0.275): 0.2
(3, 100.0, 100.0, 0.2): 0.4
(3, 100.0, 100.0, 0.225): 0.266666666667
(3, 100.0, 100.0, 0.25): 0.266666666667
(3, 100.0, 100.0, 0.275): 0.266666666667
(4, 0.1, 0.1, 0.25): 0.333333333333
(4, 0.1, 0.1, 0.275): 0.2
(4, 1.0, 1.0, 0.2): 0.533333333333
(4, 1.0, 1.0, 0.225): 0.266666666667
(4, 1.0, 1.0, 0.25): 0.333333333333
(4, 1.0, 1.0, 0.275): 0.4
(4, 1.0, 1.0, 0.3): 0.466666666667
(4, 10.0, 10.0, 0.2): 0.466666666667
(4, 10.0, 10.0, 0.225): 0.2
(4, 10.0, 10.0, 0.25): 0.333333333333
(4, 10.0, 10.0, 0.275): 0.533333333333
(4, 10.0, 10.0, 0.3): 0.466666666667
(4, 100.0, 100.0, 0.2): 0.4
(4, 100.0, 100.0, 0.225): 0.466666666667
(4, 100.0, 100.0, 0.25): 0.533333333333
(4, 100.0, 100.0, 0.275): 0.4
(4, 100.0, 100.0, 0.3): 0.333333333333
(5, 0.1, 0.1, 0.25): 0.2
(5, 0.1, 0.1, 0.275): 0.466666666667
(5, 0.1, 0.1, 0.3): 0.266666666667
(5, 1.0, 1.0, 0.2): 0.533333333333
(5, 1.0, 1.0, 0.225): 0.4
(5, 1.0, 1.0, 0.25): 0.466666666667
(5, 1.0, 1.0, 0.275): 0.4
(5, 1.0, 1.0, 0.3): 0.533333333333
(5, 10.0, 10.0, 0.2): 0.133333333333
(5, 10.0, 10.0, 0.225): 0.2
(5, 10.0, 10.0, 0.25): 0.4
(5, 10.0, 10.0, 0.275): 0.333333333333
(5, 10.0, 10.0, 0.3): 0.533333333333
(5, 100.0, 100.0, 0.2): 0.333333333333
(5, 100.0, 100.0, 0.225): 0.333333333333
(5, 100.0, 100.0, 0.25): 0.466666666667
(5, 100.0, 100.0, 0.275): 0.533333333333
(5, 100.0, 100.0, 0.3): 0.266666666667
(6, 0.1, 0.1, 0.25): 0.266666666667
(6, 0.1, 0.1, 0.3): 0.133333333333
(6, 1.0, 1.0, 0.2): 0.466666666667
(6, 1.0, 1.0, 0.225): 0.333333333333
(6, 1.0, 1.0, 0.25): 0.333333333333
(6, 1.0, 1.0, 0.275): 0.266666666667
(6, 1.0, 1.0, 0.3): 0.133333333333
(6, 10.0, 10.0, 0.2): 0.266666666667
(6, 10.0, 10.0, 0.225): 0.333333333333
(6, 10.0, 10.0, 0.25): 0.333333333333
(6, 10.0, 10.0, 0.275): 0.333333333333
(6, 10.0, 10.0, 0.3): 0.4
(6, 100.0, 100.0, 0.2): 0.266666666667
(6, 100.0, 100.0, 0.225): 0.266666666667
(6, 100.0, 100.0, 0.25): 0.666666666667
(6, 100.0, 100.0, 0.275): 0.333333333333
(6, 100.0, 100.0, 0.3): 0.333333333333
(7, 1.0, 1.0, 0.2): 0.333333333333
(7, 1.0, 1.0, 0.225): 0.133333333333
(7, 1.0, 1.0, 0.25): 0.4
(7, 1.0, 1.0, 0.275): 0.4
(7, 1.0, 1.0, 0.3): 0.4
(7, 10.0, 10.0, 0.2): 0.266666666667
(7, 10.0, 10.0, 0.225): 0.4
(7, 10.0, 10.0, 0.25): 0.533333333333
(7, 10.0, 10.0, 0.275): 0.6
(7, 10.0, 10.0, 0.3): 0.2
(7, 100.0, 100.0, 0.2): 0.4
(7, 100.0, 100.0, 0.225): 0.333333333333
(7, 100.0, 100.0, 0.25): 0.2
(7, 100.0, 100.0, 0.275): 0.333333333333
(7, 100.0, 100.0, 0.3): 0.333333333333
(8, 0.1, 0.1, 0.225): 0.466666666667
(8, 1.0, 1.0, 0.2): 0.4
(8, 1.0, 1.0, 0.225): 0.466666666667
(8, 1.0, 1.0, 0.25): 0.133333333333
(8, 1.0, 1.0, 0.275): 0.266666666667
(8, 1.0, 1.0, 0.3): 0.333333333333
(8, 10.0, 10.0, 0.2): 0.4
(8, 10.0, 10.0, 0.225): 0.666666666667
(8, 10.0, 10.0, 0.25): 0.133333333333
(8, 10.0, 10.0, 0.275): 0.4
(8, 10.0, 10.0, 0.3): 0.266666666667
(8, 100.0, 100.0, 0.2): 0.266666666667
(8, 100.0, 100.0, 0.225): 0.466666666667
(8, 100.0, 100.0, 0.25): 0.133333333333
(8, 100.0, 100.0, 0.275): 0.266666666667
(8, 100.0, 100.0, 0.3): 0.133333333333
(9, 1.0, 1.0, 0.2): 0.533333333333
(9, 1.0, 1.0, 0.225): 0.333333333333
(9, 1.0, 1.0, 0.25): 0.2
(9, 1.0, 1.0, 0.275): 0.266666666667
(9, 1.0, 1.0, 0.3): 0.2
(9, 10.0, 10.0, 0.2): 0.533333333333
(9, 10.0, 10.0, 0.225): 0.333333333333
(9, 10.0, 10.0, 0.25): 0.2
(9, 10.0, 10.0, 0.275): 0.266666666667
(9, 10.0, 10.0, 0.3): 0.4
(9, 100.0, 100.0, 0.2): 0.333333333333
(9, 100.0, 100.0, 0.225): 0.466666666667
(9, 100.0, 100.0, 0.25): 0.466666666667
(9, 100.0, 100.0, 0.275): 0.333333333333
(9, 100.0, 100.0, 0.3): 0.333333333333

Loss on all the set for every iteration, for every couple c,sigma (n_of_the_iter, best_c, best_sigma):
(0, 1.0, 1.0, 0.2): 1.0
(0, 1.0, 1.0, 0.225): 0.733333333333
(0, 1.0, 1.0, 0.25): 0.733333333333
(0, 1.0, 1.0, 0.275): 0.6
(0, 1.0, 1.0, 0.3): 0.4
(0, 10.0, 10.0, 0.2): 0.8
(0, 10.0, 10.0, 0.225): 0.6
(0, 10.0, 10.0, 0.25): 0.6
(0, 10.0, 10.0, 0.275): 0.666666666667
(0, 10.0, 10.0, 0.3): 0.466666666667
(0, 100.0, 100.0, 0.2): 0.866666666667
(0, 100.0, 100.0, 0.225): 0.4
(0, 100.0, 100.0, 0.25): 0.533333333333
(0, 100.0, 100.0, 0.275): 0.8
(0, 100.0, 100.0, 0.3): 0.533333333333
(1, 1.0, 1.0, 0.2): 0.6
(1, 1.0, 1.0, 0.225): 0.733333333333
(1, 1.0, 1.0, 0.25): 0.666666666667
(1, 1.0, 1.0, 0.275): 0.6
(1, 1.0, 1.0, 0.3): 0.466666666667
(1, 10.0, 10.0, 0.225): 0.666666666667
(1, 10.0, 10.0, 0.25): 0.666666666667
(1, 10.0, 10.0, 0.275): 0.666666666667
(1, 10.0, 10.0, 0.3): 0.733333333333
(1, 100.0, 100.0, 0.2): 0.6
(1, 100.0, 100.0, 0.225): 0.533333333333
(1, 100.0, 100.0, 0.25): 0.533333333333
(1, 100.0, 100.0, 0.275): 0.533333333333
(1, 100.0, 100.0, 0.3): 0.6
(2, 0.1, 0.1, 0.275): 0.533333333333
(2, 1.0, 1.0, 0.225): 0.666666666667
(2, 1.0, 1.0, 0.25): 0.666666666667
(2, 1.0, 1.0, 0.275): 0.933333333333
(2, 1.0, 1.0, 0.3): 0.866666666667
(2, 10.0, 10.0, 0.2): 0.666666666667
(2, 10.0, 10.0, 0.225): 0.666666666667
(2, 10.0, 10.0, 0.25): 0.666666666667
(2, 10.0, 10.0, 0.275): 0.733333333333
(2, 10.0, 10.0, 0.3): 0.733333333333
(2, 100.0, 100.0, 0.225): 0.666666666667
(2, 100.0, 100.0, 0.25): 0.666666666667
(2, 100.0, 100.0, 0.275): 0.8
(2, 100.0, 100.0, 0.3): 0.666666666667
(3, 0.1, 0.1, 0.275): 0.8
(3, 1.0, 1.0, 0.2): 0.933333333333
(3, 1.0, 1.0, 0.225): 0.8
(3, 1.0, 1.0, 0.25): 0.533333333333
(3, 1.0, 1.0, 0.275): 0.666666666667
(3, 10.0, 10.0, 0.2): 0.666666666667
(3, 10.0, 10.0, 0.225): 0.666666666667
(3, 10.0, 10.0, 0.25): 0.666666666667
(3, 10.0, 10.0, 0.275): 0.8
(3, 100.0, 100.0, 0.2): 0.6
(3, 100.0, 100.0, 0.225): 0.733333333333
(3, 100.0, 100.0, 0.25): 0.733333333333
(3, 100.0, 100.0, 0.275): 0.733333333333
(4, 0.1, 0.1, 0.25): 0.666666666667
(4, 0.1, 0.1, 0.275): 0.8
(4, 1.0, 1.0, 0.2): 0.466666666667
(4, 1.0, 1.0, 0.225): 0.733333333333
(4, 1.0, 1.0, 0.25): 0.666666666667
(4, 1.0, 1.0, 0.275): 0.6
(4, 1.0, 1.0, 0.3): 0.533333333333
(4, 10.0, 10.0, 0.2): 0.533333333333
(4, 10.0, 10.0, 0.225): 0.8
(4, 10.0, 10.0, 0.25): 0.666666666667
(4, 10.0, 10.0, 0.275): 0.466666666667
(4, 10.0, 10.0, 0.3): 0.533333333333
(4, 100.0, 100.0, 0.2): 0.6
(4, 100.0, 100.0, 0.225): 0.533333333333
(4, 100.0, 100.0, 0.25): 0.466666666667
(4, 100.0, 100.0, 0.275): 0.6
(4, 100.0, 100.0, 0.3): 0.666666666667
(5, 0.1, 0.1, 0.25): 0.8
(5, 0.1, 0.1, 0.275): 0.533333333333
(5, 0.1, 0.1, 0.3): 0.733333333333
(5, 1.0, 1.0, 0.2): 0.466666666667
(5, 1.0, 1.0, 0.225): 0.6
(5, 1.0, 1.0, 0.25): 0.533333333333
(5, 1.0, 1.0, 0.275): 0.6
(5, 1.0, 1.0, 0.3): 0.466666666667
(5, 10.0, 10.0, 0.2): 0.866666666667
(5, 10.0, 10.0, 0.225): 0.8
(5, 10.0, 10.0, 0.25): 0.6
(5, 10.0, 10.0, 0.275): 0.666666666667
(5, 10.0, 10.0, 0.3): 0.466666666667
(5, 100.0, 100.0, 0.2): 0.666666666667
(5, 100.0, 100.0, 0.225): 0.666666666667
(5, 100.0, 100.0, 0.25): 0.533333333333
(5, 100.0, 100.0, 0.275): 0.466666666667
(5, 100.0, 100.0, 0.3): 0.733333333333
(6, 0.1, 0.1, 0.25): 0.733333333333
(6, 0.1, 0.1, 0.3): 0.866666666667
(6, 1.0, 1.0, 0.2): 0.533333333333
(6, 1.0, 1.0, 0.225): 0.666666666667
(6, 1.0, 1.0, 0.25): 0.666666666667
(6, 1.0, 1.0, 0.275): 0.733333333333
(6, 1.0, 1.0, 0.3): 0.866666666667
(6, 10.0, 10.0, 0.2): 0.733333333333
(6, 10.0, 10.0, 0.225): 0.666666666667
(6, 10.0, 10.0, 0.25): 0.666666666667
(6, 10.0, 10.0, 0.275): 0.666666666667
(6, 10.0, 10.0, 0.3): 0.6
(6, 100.0, 100.0, 0.2): 0.733333333333
(6, 100.0, 100.0, 0.225): 0.733333333333
(6, 100.0, 100.0, 0.25): 0.333333333333
(6, 100.0, 100.0, 0.275): 0.666666666667
(6, 100.0, 100.0, 0.3): 0.666666666667
(7, 1.0, 1.0, 0.2): 0.666666666667
(7, 1.0, 1.0, 0.225): 0.866666666667
(7, 1.0, 1.0, 0.25): 0.6
(7, 1.0, 1.0, 0.275): 0.6
(7, 1.0, 1.0, 0.3): 0.6
(7, 10.0, 10.0, 0.2): 0.733333333333
(7, 10.0, 10.0, 0.225): 0.6
(7, 10.0, 10.0, 0.25): 0.466666666667
(7, 10.0, 10.0, 0.275): 0.4
(7, 10.0, 10.0, 0.3): 0.8
(7, 100.0, 100.0, 0.2): 0.6
(7, 100.0, 100.0, 0.225): 0.666666666667
(7, 100.0, 100.0, 0.25): 0.8
(7, 100.0, 100.0, 0.275): 0.666666666667
(7, 100.0, 100.0, 0.3): 0.666666666667
(8, 0.1, 0.1, 0.225): 0.533333333333
(8, 1.0, 1.0, 0.2): 0.6
(8, 1.0, 1.0, 0.225): 0.533333333333
(8, 1.0, 1.0, 0.25): 0.866666666667
(8, 1.0, 1.0, 0.275): 0.733333333333
(8, 1.0, 1.0, 0.3): 0.666666666667
(8, 10.0, 10.0, 0.2): 0.6
(8, 10.0, 10.0, 0.225): 0.333333333333
(8, 10.0, 10.0, 0.25): 0.866666666667
(8, 10.0, 10.0, 0.275): 0.6
(8, 10.0, 10.0, 0.3): 0.733333333333
(8, 100.0, 100.0, 0.2): 0.733333333333
(8, 100.0, 100.0, 0.225): 0.533333333333
(8, 100.0, 100.0, 0.25): 0.866666666667
(8, 100.0, 100.0, 0.275): 0.733333333333
(8, 100.0, 100.0, 0.3): 0.866666666667
(9, 1.0, 1.0, 0.2): 0.466666666667
(9, 1.0, 1.0, 0.225): 0.666666666667
(9, 1.0, 1.0, 0.25): 0.8
(9, 1.0, 1.0, 0.275): 0.733333333333
(9, 1.0, 1.0, 0.3): 0.8
(9, 10.0, 10.0, 0.2): 0.466666666667
(9, 10.0, 10.0, 0.225): 0.666666666667
(9, 10.0, 10.0, 0.25): 0.8
(9, 10.0, 10.0, 0.275): 0.733333333333
(9, 10.0, 10.0, 0.3): 0.6
(9, 100.0, 100.0, 0.2): 0.666666666667
(9, 100.0, 100.0, 0.225): 0.533333333333
(9, 100.0, 100.0, 0.25): 0.533333333333
(9, 100.0, 100.0, 0.275): 0.666666666667
(9, 100.0, 100.0, 0.3): 0.666666666667

Accuracy mean :0.34415584415584416
Std deviation :0.1244835285199301
Loss mean :0.6558441558441559
Std deviation :0.1244835285199301



Linear_3dim, number of iterations: 10

Parameters info
Tradeoffs parameter: [  0.1   1.   10.  100. ]
Using same parameters for all the clusterization: True
Gaussian kernel sigmas: [0.2   0.225 0.25  0.275 0.3  ]
Number of principal dimension considerated: 3
Dataset length: 150

Clusterization info
Minimum size of a cluster: in perc: 0.01, in int: 2
Type of mu: Binary Muzzifier
Fuzzifier: Linear
Cluster graph uses all connections: False
Cluster to label info
Force the number of cluster to be the number of different labels: False
Force the labels to be always represent by a cluster: False

Validation info
Conflict resolution: random
Number of cluster considerated for validation (top_k): None


RESULTS

On TEST set

Accuracy on test set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 100.0, 100.0, 0.2): 0.133333333333
(1, 10.0, 10.0, 0.25): 0.266666666667
(2, 100.0, 100.0, 0.225): 0.2
(3, 100.0, 100.0, 0.25): 0.933333333333
(4, 10.0, 10.0, 0.225): 0.8
(5, 10.0, 10.0, 0.2): 0.8
(6, 100.0, 100.0, 0.225): 0.933333333333
(7, 1.0, 1.0, 0.25): 0.666666666667
(8, 10.0, 10.0, 0.225): 0.866666666667
(9, 1.0, 1.0, 0.225): 1.0

Loss on test set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 100.0, 100.0, 0.2): 0.866666666667
(1, 10.0, 10.0, 0.25): 0.733333333333
(2, 100.0, 100.0, 0.225): 0.8
(3, 100.0, 100.0, 0.25): 0.0666666666667
(4, 10.0, 10.0, 0.225): 0.2
(5, 10.0, 10.0, 0.2): 0.2
(6, 100.0, 100.0, 0.225): 0.0666666666667
(7, 1.0, 1.0, 0.25): 0.333333333333
(8, 10.0, 10.0, 0.225): 0.133333333333
(9, 1.0, 1.0, 0.225): 0.0

Accuracy mean :0.6599999999999999
Std deviation :0.3147485769096767
Loss mean :0.33999999999999997
Std deviation :0.31474857690967667

On TRAINING set

Accuracy on training set for every iteration (n_of_the_iter, c, sigma):
(0, 100.0, 100.0, 0.2): 0.355555555556
(1, 10.0, 10.0, 0.25): 0.340740740741
(2, 100.0, 100.0, 0.225): 0.348148148148
(3, 100.0, 100.0, 0.25): 0.711111111111
(4, 10.0, 10.0, 0.225): 0.940740740741
(5, 10.0, 10.0, 0.2): 0.881481481481
(6, 100.0, 100.0, 0.225): 0.859259259259
(7, 1.0, 1.0, 0.25): 0.822222222222
(8, 10.0, 10.0, 0.225): 0.925925925926
(9, 1.0, 1.0, 0.225): 0.918518518519
Loss on training set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 100.0, 100.0, 0.2): 0.644444444444
(1, 10.0, 10.0, 0.25): 0.659259259259
(2, 100.0, 100.0, 0.225): 0.651851851852
(3, 100.0, 100.0, 0.25): 0.288888888889
(4, 10.0, 10.0, 0.225): 0.0592592592593
(5, 10.0, 10.0, 0.2): 0.118518518519
(6, 100.0, 100.0, 0.225): 0.140740740741
(7, 1.0, 1.0, 0.25): 0.177777777778
(8, 10.0, 10.0, 0.225): 0.0740740740741
(9, 1.0, 1.0, 0.225): 0.0814814814815

Accuracy mean :0.7103703703703703
Std deviation :0.24505983144459706
Loss mean :0.2896296296296296
Std deviation :0.24505983144459706

On ALL the sets

Accuracy on all the set for every iteration, for every couple c,sigma (n_of_the_iter, c, sigma):
(0, 1.0, 1.0, 0.225): 0.8
(0, 1.0, 1.0, 0.25): 0.8
(0, 1.0, 1.0, 0.275): 0.666666666667
(0, 1.0, 1.0, 0.3): 0.666666666667
(0, 10.0, 10.0, 0.2): 0.866666666667
(0, 10.0, 10.0, 0.225): 0.8
(0, 10.0, 10.0, 0.25): 0.8
(0, 10.0, 10.0, 0.275): 0.666666666667
(0, 10.0, 10.0, 0.3): 0.666666666667
(0, 100.0, 100.0, 0.2): 0.866666666667
(0, 100.0, 100.0, 0.225): 0.8
(0, 100.0, 100.0, 0.25): 0.8
(0, 100.0, 100.0, 0.275): 0.666666666667
(0, 100.0, 100.0, 0.3): 0.666666666667
(1, 1.0, 1.0, 0.2): 0.466666666667
(1, 1.0, 1.0, 0.225): 0.8
(1, 1.0, 1.0, 0.25): 0.866666666667
(1, 1.0, 1.0, 0.275): 0.666666666667
(1, 1.0, 1.0, 0.3): 0.8
(1, 10.0, 10.0, 0.2): 0.266666666667
(1, 10.0, 10.0, 0.225): 0.733333333333
(1, 10.0, 10.0, 0.25): 0.866666666667
(1, 10.0, 10.0, 0.275): 0.666666666667
(1, 10.0, 10.0, 0.3): 0.8
(1, 100.0, 100.0, 0.2): 0.666666666667
(1, 100.0, 100.0, 0.225): 0.6
(1, 100.0, 100.0, 0.25): 0.866666666667
(1, 100.0, 100.0, 0.275): 0.666666666667
(1, 100.0, 100.0, 0.3): 0.8
(2, 1.0, 1.0, 0.2): 0.866666666667
(2, 1.0, 1.0, 0.225): 0.866666666667
(2, 1.0, 1.0, 0.25): 0.866666666667
(2, 1.0, 1.0, 0.275): 0.866666666667
(2, 1.0, 1.0, 0.3): 0.866666666667
(2, 10.0, 10.0, 0.2): 0.866666666667
(2, 10.0, 10.0, 0.225): 0.866666666667
(2, 10.0, 10.0, 0.25): 0.866666666667
(2, 10.0, 10.0, 0.275): 0.866666666667
(2, 10.0, 10.0, 0.3): 0.866666666667
(2, 100.0, 100.0, 0.2): 0.333333333333
(2, 100.0, 100.0, 0.225): 0.866666666667
(2, 100.0, 100.0, 0.25): 0.866666666667
(2, 100.0, 100.0, 0.275): 0.333333333333
(2, 100.0, 100.0, 0.3): 0.866666666667
(3, 1.0, 1.0, 0.225): 0.733333333333
(3, 1.0, 1.0, 0.25): 0.733333333333
(3, 1.0, 1.0, 0.275): 0.133333333333
(3, 1.0, 1.0, 0.3): 0.666666666667
(3, 10.0, 10.0, 0.225): 0.666666666667
(3, 10.0, 10.0, 0.25): 0.733333333333
(3, 10.0, 10.0, 0.275): 0.133333333333
(3, 10.0, 10.0, 0.3): 0.666666666667
(3, 100.0, 100.0, 0.225): 0.666666666667
(3, 100.0, 100.0, 0.25): 0.733333333333
(3, 100.0, 100.0, 0.275): 0.133333333333
(3, 100.0, 100.0, 0.3): 0.666666666667
(4, 1.0, 1.0, 0.2): 0.2
(4, 1.0, 1.0, 0.225): 0.866666666667
(4, 1.0, 1.0, 0.25): 0.533333333333
(4, 1.0, 1.0, 0.275): 0.6
(4, 1.0, 1.0, 0.3): 0.6
(4, 10.0, 10.0, 0.2): 0.2
(4, 10.0, 10.0, 0.225): 0.866666666667
(4, 10.0, 10.0, 0.25): 0.533333333333
(4, 10.0, 10.0, 0.275): 0.6
(4, 10.0, 10.0, 0.3): 0.6
(4, 100.0, 100.0, 0.2): 0.466666666667
(4, 100.0, 100.0, 0.225): 0.866666666667
(4, 100.0, 100.0, 0.25): 0.533333333333
(4, 100.0, 100.0, 0.275): 0.6
(4, 100.0, 100.0, 0.3): 0.6
(5, 0.1, 0.1, 0.3): 0.733333333333
(5, 1.0, 1.0, 0.2): 0.933333333333
(5, 1.0, 1.0, 0.225): 0.4
(5, 1.0, 1.0, 0.25): 0.733333333333
(5, 1.0, 1.0, 0.275): 0.333333333333
(5, 1.0, 1.0, 0.3): 0.733333333333
(5, 10.0, 10.0, 0.2): 0.933333333333
(5, 10.0, 10.0, 0.225): 0.4
(5, 10.0, 10.0, 0.25): 0.733333333333
(5, 10.0, 10.0, 0.275): 0.4
(5, 10.0, 10.0, 0.3): 0.733333333333
(5, 100.0, 100.0, 0.2): 0.933333333333
(5, 100.0, 100.0, 0.225): 0.866666666667
(5, 100.0, 100.0, 0.25): 0.733333333333
(5, 100.0, 100.0, 0.275): 0.333333333333
(5, 100.0, 100.0, 0.3): 0.733333333333
(6, 0.1, 0.1, 0.3): 0.666666666667
(6, 1.0, 1.0, 0.2): 0.866666666667
(6, 1.0, 1.0, 0.225): 1.0
(6, 1.0, 1.0, 0.275): 0.666666666667
(6, 1.0, 1.0, 0.3): 0.666666666667
(6, 10.0, 10.0, 0.2): 0.933333333333
(6, 10.0, 10.0, 0.225): 1.0
(6, 10.0, 10.0, 0.275): 0.6
(6, 10.0, 10.0, 0.3): 0.666666666667
(6, 100.0, 100.0, 0.2): 0.866666666667
(6, 100.0, 100.0, 0.225): 1.0
(6, 100.0, 100.0, 0.275): 0.466666666667
(6, 100.0, 100.0, 0.3): 0.666666666667
(7, 1.0, 1.0, 0.2): 0.933333333333
(7, 1.0, 1.0, 0.225): 0.933333333333
(7, 1.0, 1.0, 0.25): 1.0
(7, 1.0, 1.0, 0.275): 0.666666666667
(7, 1.0, 1.0, 0.3): 0.666666666667
(7, 10.0, 10.0, 0.2): 0.933333333333
(7, 10.0, 10.0, 0.225): 0.933333333333
(7, 10.0, 10.0, 0.25): 1.0
(7, 10.0, 10.0, 0.275): 0.666666666667
(7, 10.0, 10.0, 0.3): 0.666666666667
(7, 100.0, 100.0, 0.2): 0.2
(7, 100.0, 100.0, 0.225): 0.933333333333
(7, 100.0, 100.0, 0.25): 1.0
(7, 100.0, 100.0, 0.275): 0.666666666667
(7, 100.0, 100.0, 0.3): 0.666666666667
(8, 1.0, 1.0, 0.2): 0.8
(8, 1.0, 1.0, 0.225): 1.0
(8, 1.0, 1.0, 0.25): 0.933333333333
(8, 1.0, 1.0, 0.275): 0.8
(8, 1.0, 1.0, 0.3): 0.933333333333
(8, 10.0, 10.0, 0.2): 0.866666666667
(8, 10.0, 10.0, 0.225): 1.0
(8, 10.0, 10.0, 0.25): 0.933333333333
(8, 10.0, 10.0, 0.275): 0.8
(8, 10.0, 10.0, 0.3): 0.933333333333
(8, 100.0, 100.0, 0.2): 0.8
(8, 100.0, 100.0, 0.225): 1.0
(8, 100.0, 100.0, 0.25): 0.933333333333
(8, 100.0, 100.0, 0.275): 0.933333333333
(8, 100.0, 100.0, 0.3): 0.933333333333
(9, 1.0, 1.0, 0.2): 0.733333333333
(9, 1.0, 1.0, 0.225): 0.866666666667
(9, 1.0, 1.0, 0.25): 0.6
(9, 1.0, 1.0, 0.275): 0.733333333333
(9, 1.0, 1.0, 0.3): 0.6
(9, 10.0, 10.0, 0.225): 0.866666666667
(9, 10.0, 10.0, 0.25): 0.6
(9, 10.0, 10.0, 0.275): 0.733333333333
(9, 10.0, 10.0, 0.3): 0.6
(9, 100.0, 100.0, 0.2): 0.4
(9, 100.0, 100.0, 0.225): 0.866666666667
(9, 100.0, 100.0, 0.25): 0.6
(9, 100.0, 100.0, 0.275): 0.733333333333
(9, 100.0, 100.0, 0.3): 0.6

Loss on all the set for every iteration, for every couple c,sigma (n_of_the_iter, best_c, best_sigma):
(0, 1.0, 1.0, 0.225): 0.2
(0, 1.0, 1.0, 0.25): 0.2
(0, 1.0, 1.0, 0.275): 0.333333333333
(0, 1.0, 1.0, 0.3): 0.333333333333
(0, 10.0, 10.0, 0.2): 0.133333333333
(0, 10.0, 10.0, 0.225): 0.2
(0, 10.0, 10.0, 0.25): 0.2
(0, 10.0, 10.0, 0.275): 0.333333333333
(0, 10.0, 10.0, 0.3): 0.333333333333
(0, 100.0, 100.0, 0.2): 0.133333333333
(0, 100.0, 100.0, 0.225): 0.2
(0, 100.0, 100.0, 0.25): 0.2
(0, 100.0, 100.0, 0.275): 0.333333333333
(0, 100.0, 100.0, 0.3): 0.333333333333
(1, 1.0, 1.0, 0.2): 0.533333333333
(1, 1.0, 1.0, 0.225): 0.2
(1, 1.0, 1.0, 0.25): 0.133333333333
(1, 1.0, 1.0, 0.275): 0.333333333333
(1, 1.0, 1.0, 0.3): 0.2
(1, 10.0, 10.0, 0.2): 0.733333333333
(1, 10.0, 10.0, 0.225): 0.266666666667
(1, 10.0, 10.0, 0.25): 0.133333333333
(1, 10.0, 10.0, 0.275): 0.333333333333
(1, 10.0, 10.0, 0.3): 0.2
(1, 100.0, 100.0, 0.2): 0.333333333333
(1, 100.0, 100.0, 0.225): 0.4
(1, 100.0, 100.0, 0.25): 0.133333333333
(1, 100.0, 100.0, 0.275): 0.333333333333
(1, 100.0, 100.0, 0.3): 0.2
(2, 1.0, 1.0, 0.2): 0.133333333333
(2, 1.0, 1.0, 0.225): 0.133333333333
(2, 1.0, 1.0, 0.25): 0.133333333333
(2, 1.0, 1.0, 0.275): 0.133333333333
(2, 1.0, 1.0, 0.3): 0.133333333333
(2, 10.0, 10.0, 0.2): 0.133333333333
(2, 10.0, 10.0, 0.225): 0.133333333333
(2, 10.0, 10.0, 0.25): 0.133333333333
(2, 10.0, 10.0, 0.275): 0.133333333333
(2, 10.0, 10.0, 0.3): 0.133333333333
(2, 100.0, 100.0, 0.2): 0.666666666667
(2, 100.0, 100.0, 0.225): 0.133333333333
(2, 100.0, 100.0, 0.25): 0.133333333333
(2, 100.0, 100.0, 0.275): 0.666666666667
(2, 100.0, 100.0, 0.3): 0.133333333333
(3, 1.0, 1.0, 0.225): 0.266666666667
(3, 1.0, 1.0, 0.25): 0.266666666667
(3, 1.0, 1.0, 0.275): 0.866666666667
(3, 1.0, 1.0, 0.3): 0.333333333333
(3, 10.0, 10.0, 0.225): 0.333333333333
(3, 10.0, 10.0, 0.25): 0.266666666667
(3, 10.0, 10.0, 0.275): 0.866666666667
(3, 10.0, 10.0, 0.3): 0.333333333333
(3, 100.0, 100.0, 0.225): 0.333333333333
(3, 100.0, 100.0, 0.25): 0.266666666667
(3, 100.0, 100.0, 0.275): 0.866666666667
(3, 100.0, 100.0, 0.3): 0.333333333333
(4, 1.0, 1.0, 0.2): 0.8
(4, 1.0, 1.0, 0.225): 0.133333333333
(4, 1.0, 1.0, 0.25): 0.466666666667
(4, 1.0, 1.0, 0.275): 0.4
(4, 1.0, 1.0, 0.3): 0.4
(4, 10.0, 10.0, 0.2): 0.8
(4, 10.0, 10.0, 0.225): 0.133333333333
(4, 10.0, 10.0, 0.25): 0.466666666667
(4, 10.0, 10.0, 0.275): 0.4
(4, 10.0, 10.0, 0.3): 0.4
(4, 100.0, 100.0, 0.2): 0.533333333333
(4, 100.0, 100.0, 0.225): 0.133333333333
(4, 100.0, 100.0, 0.25): 0.466666666667
(4, 100.0, 100.0, 0.275): 0.4
(4, 100.0, 100.0, 0.3): 0.4
(5, 0.1, 0.1, 0.3): 0.266666666667
(5, 1.0, 1.0, 0.2): 0.0666666666667
(5, 1.0, 1.0, 0.225): 0.6
(5, 1.0, 1.0, 0.25): 0.266666666667
(5, 1.0, 1.0, 0.275): 0.666666666667
(5, 1.0, 1.0, 0.3): 0.266666666667
(5, 10.0, 10.0, 0.2): 0.0666666666667
(5, 10.0, 10.0, 0.225): 0.6
(5, 10.0, 10.0, 0.25): 0.266666666667
(5, 10.0, 10.0, 0.275): 0.6
(5, 10.0, 10.0, 0.3): 0.266666666667
(5, 100.0, 100.0, 0.2): 0.0666666666667
(5, 100.0, 100.0, 0.225): 0.133333333333
(5, 100.0, 100.0, 0.25): 0.266666666667
(5, 100.0, 100.0, 0.275): 0.666666666667
(5, 100.0, 100.0, 0.3): 0.266666666667
(6, 0.1, 0.1, 0.3): 0.333333333333
(6, 1.0, 1.0, 0.2): 0.133333333333
(6, 1.0, 1.0, 0.225): 0.0
(6, 1.0, 1.0, 0.275): 0.333333333333
(6, 1.0, 1.0, 0.3): 0.333333333333
(6, 10.0, 10.0, 0.2): 0.0666666666667
(6, 10.0, 10.0, 0.225): 0.0
(6, 10.0, 10.0, 0.275): 0.4
(6, 10.0, 10.0, 0.3): 0.333333333333
(6, 100.0, 100.0, 0.2): 0.133333333333
(6, 100.0, 100.0, 0.225): 0.0
(6, 100.0, 100.0, 0.275): 0.533333333333
(6, 100.0, 100.0, 0.3): 0.333333333333
(7, 1.0, 1.0, 0.2): 0.0666666666667
(7, 1.0, 1.0, 0.225): 0.0666666666667
(7, 1.0, 1.0, 0.25): 0.0
(7, 1.0, 1.0, 0.275): 0.333333333333
(7, 1.0, 1.0, 0.3): 0.333333333333
(7, 10.0, 10.0, 0.2): 0.0666666666667
(7, 10.0, 10.0, 0.225): 0.0666666666667
(7, 10.0, 10.0, 0.25): 0.0
(7, 10.0, 10.0, 0.275): 0.333333333333
(7, 10.0, 10.0, 0.3): 0.333333333333
(7, 100.0, 100.0, 0.2): 0.8
(7, 100.0, 100.0, 0.225): 0.0666666666667
(7, 100.0, 100.0, 0.25): 0.0
(7, 100.0, 100.0, 0.275): 0.333333333333
(7, 100.0, 100.0, 0.3): 0.333333333333
(8, 1.0, 1.0, 0.2): 0.2
(8, 1.0, 1.0, 0.225): 0.0
(8, 1.0, 1.0, 0.25): 0.0666666666667
(8, 1.0, 1.0, 0.275): 0.2
(8, 1.0, 1.0, 0.3): 0.0666666666667
(8, 10.0, 10.0, 0.2): 0.133333333333
(8, 10.0, 10.0, 0.225): 0.0
(8, 10.0, 10.0, 0.25): 0.0666666666667
(8, 10.0, 10.0, 0.275): 0.2
(8, 10.0, 10.0, 0.3): 0.0666666666667
(8, 100.0, 100.0, 0.2): 0.2
(8, 100.0, 100.0, 0.225): 0.0
(8, 100.0, 100.0, 0.25): 0.0666666666667
(8, 100.0, 100.0, 0.275): 0.0666666666667
(8, 100.0, 100.0, 0.3): 0.0666666666667
(9, 1.0, 1.0, 0.2): 0.266666666667
(9, 1.0, 1.0, 0.225): 0.133333333333
(9, 1.0, 1.0, 0.25): 0.4
(9, 1.0, 1.0, 0.275): 0.266666666667
(9, 1.0, 1.0, 0.3): 0.4
(9, 10.0, 10.0, 0.225): 0.133333333333
(9, 10.0, 10.0, 0.25): 0.4
(9, 10.0, 10.0, 0.275): 0.266666666667
(9, 10.0, 10.0, 0.3): 0.4
(9, 100.0, 100.0, 0.2): 0.6
(9, 100.0, 100.0, 0.225): 0.133333333333
(9, 100.0, 100.0, 0.25): 0.4
(9, 100.0, 100.0, 0.275): 0.266666666667
(9, 100.0, 100.0, 0.3): 0.4

Accuracy mean :0.7226851851851852
Std deviation :0.19994801707845888
Loss mean :0.2773148148148148
Std deviation :0.19994801707845888



QuantileConstPiecewise_3dim, number of iterations: 10

Parameters info
Tradeoffs parameter: [  0.1   1.   10.  100. ]
Using same parameters for all the clusterization: True
Gaussian kernel sigmas: [0.2   0.225 0.25  0.275 0.3  ]
Number of principal dimension considerated: 3
Dataset length: 150

Clusterization info
Minimum size of a cluster: in perc: 0.01, in int: 2
Type of mu: Binary Muzzifier
Fuzzifier: QuantileConstPiecewise
Cluster graph uses all connections: False
Cluster to label info
Force the number of cluster to be the number of different labels: False
Force the labels to be always represent by a cluster: False

Validation info
Conflict resolution: random
Number of cluster considerated for validation (top_k): None


RESULTS

On TEST set

Accuracy on test set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 100.0, 100.0, 0.3): 0.733333333333
(1, 100.0, 100.0, 0.3): 0.266666666667
(2, 10.0, 10.0, 0.3): 0.4
(3, 100.0, 100.0, 0.225): 0.266666666667
(4, 10.0, 10.0, 0.3): 0.733333333333
(5, 10.0, 10.0, 0.3): 0.466666666667
(6, 10.0, 10.0, 0.25): 0.266666666667
(7, 0.1, 0.1, 0.3): 0.533333333333
(8, 100.0, 100.0, 0.275): 0.333333333333
(9, 10.0, 10.0, 0.25): 0.4

Loss on test set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 100.0, 100.0, 0.3): 0.266666666667
(1, 100.0, 100.0, 0.3): 0.733333333333
(2, 10.0, 10.0, 0.3): 0.6
(3, 100.0, 100.0, 0.225): 0.733333333333
(4, 10.0, 10.0, 0.3): 0.266666666667
(5, 10.0, 10.0, 0.3): 0.533333333333
(6, 10.0, 10.0, 0.25): 0.733333333333
(7, 0.1, 0.1, 0.3): 0.466666666667
(8, 100.0, 100.0, 0.275): 0.666666666667
(9, 10.0, 10.0, 0.25): 0.6

Accuracy mean :0.44000000000000006
Std deviation :0.16918103387266026
Loss mean :0.5599999999999999
Std deviation :0.16918103387266023

On TRAINING set

Accuracy on training set for every iteration (n_of_the_iter, c, sigma):
(0, 100.0, 100.0, 0.3): 0.659259259259
(1, 100.0, 100.0, 0.3): 0.340740740741
(2, 10.0, 10.0, 0.3): 0.562962962963
(3, 100.0, 100.0, 0.225): 0.340740740741
(4, 10.0, 10.0, 0.3): 0.585185185185
(5, 10.0, 10.0, 0.3): 0.585185185185
(6, 10.0, 10.0, 0.25): 0.474074074074
(7, 0.1, 0.1, 0.3): 0.592592592593
(8, 100.0, 100.0, 0.275): 0.466666666667
(9, 10.0, 10.0, 0.25): 0.333333333333
Loss on training set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 100.0, 100.0, 0.3): 0.340740740741
(1, 100.0, 100.0, 0.3): 0.659259259259
(2, 10.0, 10.0, 0.3): 0.437037037037
(3, 100.0, 100.0, 0.225): 0.659259259259
(4, 10.0, 10.0, 0.3): 0.414814814815
(5, 10.0, 10.0, 0.3): 0.414814814815
(6, 10.0, 10.0, 0.25): 0.525925925926
(7, 0.1, 0.1, 0.3): 0.407407407407
(8, 100.0, 100.0, 0.275): 0.533333333333
(9, 10.0, 10.0, 0.25): 0.666666666667

Accuracy mean :0.494074074074074
Std deviation :0.11504397680052424
Loss mean :0.5059259259259259
Std deviation :0.11504397680052424

On ALL the sets

Accuracy on all the set for every iteration, for every couple c,sigma (n_of_the_iter, c, sigma):
(0, 0.1, 0.1, 0.3): 0.466666666667
(0, 1.0, 1.0, 0.2): 0.266666666667
(0, 1.0, 1.0, 0.225): 0.133333333333
(0, 1.0, 1.0, 0.25): 0.266666666667
(0, 1.0, 1.0, 0.275): 0.266666666667
(0, 1.0, 1.0, 0.3): 0.533333333333
(0, 10.0, 10.0, 0.2): 0.133333333333
(0, 10.0, 10.0, 0.225): 0.133333333333
(0, 10.0, 10.0, 0.25): 0.2
(0, 10.0, 10.0, 0.275): 0.4
(0, 10.0, 10.0, 0.3): 0.4
(0, 100.0, 100.0, 0.2): 0.2
(0, 100.0, 100.0, 0.225): 0.133333333333
(0, 100.0, 100.0, 0.25): 0.2
(0, 100.0, 100.0, 0.275): 0.333333333333
(0, 100.0, 100.0, 0.3): 0.6
(1, 1.0, 1.0, 0.2): 0.2
(1, 1.0, 1.0, 0.225): 0.466666666667
(1, 1.0, 1.0, 0.25): 0.533333333333
(1, 1.0, 1.0, 0.275): 0.333333333333
(1, 1.0, 1.0, 0.3): 0.333333333333
(1, 10.0, 10.0, 0.2): 0.533333333333
(1, 10.0, 10.0, 0.225): 0.0666666666667
(1, 10.0, 10.0, 0.25): 0.2
(1, 10.0, 10.0, 0.275): 0.333333333333
(1, 10.0, 10.0, 0.3): 0.333333333333
(1, 100.0, 100.0, 0.2): 0.266666666667
(1, 100.0, 100.0, 0.225): 0.2
(1, 100.0, 100.0, 0.25): 0.533333333333
(1, 100.0, 100.0, 0.275): 0.333333333333
(1, 100.0, 100.0, 0.3): 0.666666666667
(2, 0.1, 0.1, 0.275): 0.4
(2, 1.0, 1.0, 0.2): 0.466666666667
(2, 1.0, 1.0, 0.225): 0.266666666667
(2, 1.0, 1.0, 0.25): 0.533333333333
(2, 1.0, 1.0, 0.275): 0.4
(2, 1.0, 1.0, 0.3): 0.6
(2, 10.0, 10.0, 0.2): 0.266666666667
(2, 10.0, 10.0, 0.225): 0.466666666667
(2, 10.0, 10.0, 0.25): 0.666666666667
(2, 10.0, 10.0, 0.275): 0.466666666667
(2, 10.0, 10.0, 0.3): 0.666666666667
(2, 100.0, 100.0, 0.2): 0.333333333333
(2, 100.0, 100.0, 0.225): 0.333333333333
(2, 100.0, 100.0, 0.25): 0.2
(2, 100.0, 100.0, 0.275): 0.466666666667
(2, 100.0, 100.0, 0.3): 0.6
(3, 1.0, 1.0, 0.2): 0.266666666667
(3, 1.0, 1.0, 0.225): 0.333333333333
(3, 1.0, 1.0, 0.25): 0.266666666667
(3, 1.0, 1.0, 0.275): 0.4
(3, 1.0, 1.0, 0.3): 0.333333333333
(3, 10.0, 10.0, 0.2): 0.2
(3, 10.0, 10.0, 0.225): 0.266666666667
(3, 10.0, 10.0, 0.25): 0.266666666667
(3, 10.0, 10.0, 0.275): 0.4
(3, 10.0, 10.0, 0.3): 0.333333333333
(3, 100.0, 100.0, 0.2): 0.333333333333
(3, 100.0, 100.0, 0.225): 0.466666666667
(3, 100.0, 100.0, 0.25): 0.266666666667
(3, 100.0, 100.0, 0.275): 0.2
(3, 100.0, 100.0, 0.3): 0.333333333333
(4, 1.0, 1.0, 0.2): 0.333333333333
(4, 1.0, 1.0, 0.225): 0.333333333333
(4, 1.0, 1.0, 0.25): 0.2
(4, 1.0, 1.0, 0.275): 0.6
(4, 1.0, 1.0, 0.3): 0.2
(4, 10.0, 10.0, 0.2): 0.533333333333
(4, 10.0, 10.0, 0.225): 0.6
(4, 10.0, 10.0, 0.25): 0.333333333333
(4, 10.0, 10.0, 0.275): 0.2
(4, 10.0, 10.0, 0.3): 0.666666666667
(4, 100.0, 100.0, 0.2): 0.466666666667
(4, 100.0, 100.0, 0.225): 0.466666666667
(4, 100.0, 100.0, 0.25): 0.2
(4, 100.0, 100.0, 0.275): 0.2
(4, 100.0, 100.0, 0.3): 0.266666666667
(5, 0.1, 0.1, 0.3): 0.666666666667
(5, 1.0, 1.0, 0.2): 0.133333333333
(5, 1.0, 1.0, 0.225): 0.4
(5, 1.0, 1.0, 0.25): 0.533333333333
(5, 1.0, 1.0, 0.275): 0.466666666667
(5, 1.0, 1.0, 0.3): 0.733333333333
(5, 10.0, 10.0, 0.2): 0.533333333333
(5, 10.0, 10.0, 0.225): 0.333333333333
(5, 10.0, 10.0, 0.25): 0.133333333333
(5, 10.0, 10.0, 0.275): 0.6
(5, 10.0, 10.0, 0.3): 0.8
(5, 100.0, 100.0, 0.225): 0.266666666667
(5, 100.0, 100.0, 0.25): 0.6
(5, 100.0, 100.0, 0.275): 0.4
(5, 100.0, 100.0, 0.3): 0.666666666667
(6, 0.1, 0.1, 0.25): 0.533333333333
(6, 0.1, 0.1, 0.3): 0.466666666667
(6, 1.0, 1.0, 0.2): 0.266666666667
(6, 1.0, 1.0, 0.225): 0.6
(6, 1.0, 1.0, 0.25): 0.333333333333
(6, 1.0, 1.0, 0.275): 0.266666666667
(6, 1.0, 1.0, 0.3): 0.466666666667
(6, 10.0, 10.0, 0.2): 0.4
(6, 10.0, 10.0, 0.225): 0.266666666667
(6, 10.0, 10.0, 0.25): 0.6
(6, 10.0, 10.0, 0.275): 0.266666666667
(6, 10.0, 10.0, 0.3): 0.6
(6, 100.0, 100.0, 0.2): 0.133333333333
(6, 100.0, 100.0, 0.225): 0.466666666667
(6, 100.0, 100.0, 0.25): 0.333333333333
(6, 100.0, 100.0, 0.275): 0.333333333333
(6, 100.0, 100.0, 0.3): 0.533333333333
(7, 0.1, 0.1, 0.3): 0.8
(7, 1.0, 1.0, 0.2): 0.4
(7, 1.0, 1.0, 0.225): 0.2
(7, 1.0, 1.0, 0.25): 0.466666666667
(7, 1.0, 1.0, 0.275): 0.533333333333
(7, 1.0, 1.0, 0.3): 0.533333333333
(7, 10.0, 10.0, 0.2): 0.2
(7, 10.0, 10.0, 0.225): 0.2
(7, 10.0, 10.0, 0.25): 0.533333333333
(7, 10.0, 10.0, 0.275): 0.533333333333
(7, 10.0, 10.0, 0.3): 0.666666666667
(7, 100.0, 100.0, 0.2): 0.333333333333
(7, 100.0, 100.0, 0.225): 0.2
(7, 100.0, 100.0, 0.25): 0.4
(7, 100.0, 100.0, 0.275): 0.666666666667
(7, 100.0, 100.0, 0.3): 0.533333333333
(8, 1.0, 1.0, 0.2): 0.2
(8, 1.0, 1.0, 0.225): 0.466666666667
(8, 1.0, 1.0, 0.25): 0.2
(8, 1.0, 1.0, 0.275): 0.266666666667
(8, 1.0, 1.0, 0.3): 0.6
(8, 10.0, 10.0, 0.2): 0.266666666667
(8, 10.0, 10.0, 0.225): 0.266666666667
(8, 10.0, 10.0, 0.25): 0.2
(8, 10.0, 10.0, 0.275): 0.2
(8, 10.0, 10.0, 0.3): 0.333333333333
(8, 100.0, 100.0, 0.2): 0.133333333333
(8, 100.0, 100.0, 0.225): 0.4
(8, 100.0, 100.0, 0.25): 0.466666666667
(8, 100.0, 100.0, 0.275): 0.6
(8, 100.0, 100.0, 0.3): 0.4
(9, 1.0, 1.0, 0.2): 0.466666666667
(9, 1.0, 1.0, 0.225): 0.333333333333
(9, 1.0, 1.0, 0.25): 0.466666666667
(9, 1.0, 1.0, 0.275): 0.533333333333
(9, 1.0, 1.0, 0.3): 0.466666666667
(9, 10.0, 10.0, 0.2): 0.4
(9, 10.0, 10.0, 0.225): 0.2
(9, 10.0, 10.0, 0.25): 0.6
(9, 10.0, 10.0, 0.275): 0.466666666667
(9, 10.0, 10.0, 0.3): 0.4
(9, 100.0, 100.0, 0.2): 0.333333333333
(9, 100.0, 100.0, 0.225): 0.4
(9, 100.0, 100.0, 0.25): 0.533333333333
(9, 100.0, 100.0, 0.275): 0.533333333333
(9, 100.0, 100.0, 0.3): 0.4

Loss on all the set for every iteration, for every couple c,sigma (n_of_the_iter, best_c, best_sigma):
(0, 0.1, 0.1, 0.3): 0.533333333333
(0, 1.0, 1.0, 0.2): 0.733333333333
(0, 1.0, 1.0, 0.225): 0.866666666667
(0, 1.0, 1.0, 0.25): 0.733333333333
(0, 1.0, 1.0, 0.275): 0.733333333333
(0, 1.0, 1.0, 0.3): 0.466666666667
(0, 10.0, 10.0, 0.2): 0.866666666667
(0, 10.0, 10.0, 0.225): 0.866666666667
(0, 10.0, 10.0, 0.25): 0.8
(0, 10.0, 10.0, 0.275): 0.6
(0, 10.0, 10.0, 0.3): 0.6
(0, 100.0, 100.0, 0.2): 0.8
(0, 100.0, 100.0, 0.225): 0.866666666667
(0, 100.0, 100.0, 0.25): 0.8
(0, 100.0, 100.0, 0.275): 0.666666666667
(0, 100.0, 100.0, 0.3): 0.4
(1, 1.0, 1.0, 0.2): 0.8
(1, 1.0, 1.0, 0.225): 0.533333333333
(1, 1.0, 1.0, 0.25): 0.466666666667
(1, 1.0, 1.0, 0.275): 0.666666666667
(1, 1.0, 1.0, 0.3): 0.666666666667
(1, 10.0, 10.0, 0.2): 0.466666666667
(1, 10.0, 10.0, 0.225): 0.933333333333
(1, 10.0, 10.0, 0.25): 0.8
(1, 10.0, 10.0, 0.275): 0.666666666667
(1, 10.0, 10.0, 0.3): 0.666666666667
(1, 100.0, 100.0, 0.2): 0.733333333333
(1, 100.0, 100.0, 0.225): 0.8
(1, 100.0, 100.0, 0.25): 0.466666666667
(1, 100.0, 100.0, 0.275): 0.666666666667
(1, 100.0, 100.0, 0.3): 0.333333333333
(2, 0.1, 0.1, 0.275): 0.6
(2, 1.0, 1.0, 0.2): 0.533333333333
(2, 1.0, 1.0, 0.225): 0.733333333333
(2, 1.0, 1.0, 0.25): 0.466666666667
(2, 1.0, 1.0, 0.275): 0.6
(2, 1.0, 1.0, 0.3): 0.4
(2, 10.0, 10.0, 0.2): 0.733333333333
(2, 10.0, 10.0, 0.225): 0.533333333333
(2, 10.0, 10.0, 0.25): 0.333333333333
(2, 10.0, 10.0, 0.275): 0.533333333333
(2, 10.0, 10.0, 0.3): 0.333333333333
(2, 100.0, 100.0, 0.2): 0.666666666667
(2, 100.0, 100.0, 0.225): 0.666666666667
(2, 100.0, 100.0, 0.25): 0.8
(2, 100.0, 100.0, 0.275): 0.533333333333
(2, 100.0, 100.0, 0.3): 0.4
(3, 1.0, 1.0, 0.2): 0.733333333333
(3, 1.0, 1.0, 0.225): 0.666666666667
(3, 1.0, 1.0, 0.25): 0.733333333333
(3, 1.0, 1.0, 0.275): 0.6
(3, 1.0, 1.0, 0.3): 0.666666666667
(3, 10.0, 10.0, 0.2): 0.8
(3, 10.0, 10.0, 0.225): 0.733333333333
(3, 10.0, 10.0, 0.25): 0.733333333333
(3, 10.0, 10.0, 0.275): 0.6
(3, 10.0, 10.0, 0.3): 0.666666666667
(3, 100.0, 100.0, 0.2): 0.666666666667
(3, 100.0, 100.0, 0.225): 0.533333333333
(3, 100.0, 100.0, 0.25): 0.733333333333
(3, 100.0, 100.0, 0.275): 0.8
(3, 100.0, 100.0, 0.3): 0.666666666667
(4, 1.0, 1.0, 0.2): 0.666666666667
(4, 1.0, 1.0, 0.225): 0.666666666667
(4, 1.0, 1.0, 0.25): 0.8
(4, 1.0, 1.0, 0.275): 0.4
(4, 1.0, 1.0, 0.3): 0.8
(4, 10.0, 10.0, 0.2): 0.466666666667
(4, 10.0, 10.0, 0.225): 0.4
(4, 10.0, 10.0, 0.25): 0.666666666667
(4, 10.0, 10.0, 0.275): 0.8
(4, 10.0, 10.0, 0.3): 0.333333333333
(4, 100.0, 100.0, 0.2): 0.533333333333
(4, 100.0, 100.0, 0.225): 0.533333333333
(4, 100.0, 100.0, 0.25): 0.8
(4, 100.0, 100.0, 0.275): 0.8
(4, 100.0, 100.0, 0.3): 0.733333333333
(5, 0.1, 0.1, 0.3): 0.333333333333
(5, 1.0, 1.0, 0.2): 0.866666666667
(5, 1.0, 1.0, 0.225): 0.6
(5, 1.0, 1.0, 0.25): 0.466666666667
(5, 1.0, 1.0, 0.275): 0.533333333333
(5, 1.0, 1.0, 0.3): 0.266666666667
(5, 10.0, 10.0, 0.2): 0.466666666667
(5, 10.0, 10.0, 0.225): 0.666666666667
(5, 10.0, 10.0, 0.25): 0.866666666667
(5, 10.0, 10.0, 0.275): 0.4
(5, 10.0, 10.0, 0.3): 0.2
(5, 100.0, 100.0, 0.225): 0.733333333333
(5, 100.0, 100.0, 0.25): 0.4
(5, 100.0, 100.0, 0.275): 0.6
(5, 100.0, 100.0, 0.3): 0.333333333333
(6, 0.1, 0.1, 0.25): 0.466666666667
(6, 0.1, 0.1, 0.3): 0.533333333333
(6, 1.0, 1.0, 0.2): 0.733333333333
(6, 1.0, 1.0, 0.225): 0.4
(6, 1.0, 1.0, 0.25): 0.666666666667
(6, 1.0, 1.0, 0.275): 0.733333333333
(6, 1.0, 1.0, 0.3): 0.533333333333
(6, 10.0, 10.0, 0.2): 0.6
(6, 10.0, 10.0, 0.225): 0.733333333333
(6, 10.0, 10.0, 0.25): 0.4
(6, 10.0, 10.0, 0.275): 0.733333333333
(6, 10.0, 10.0, 0.3): 0.4
(6, 100.0, 100.0, 0.2): 0.866666666667
(6, 100.0, 100.0, 0.225): 0.533333333333
(6, 100.0, 100.0, 0.25): 0.666666666667
(6, 100.0, 100.0, 0.275): 0.666666666667
(6, 100.0, 100.0, 0.3): 0.466666666667
(7, 0.1, 0.1, 0.3): 0.2
(7, 1.0, 1.0, 0.2): 0.6
(7, 1.0, 1.0, 0.225): 0.8
(7, 1.0, 1.0, 0.25): 0.533333333333
(7, 1.0, 1.0, 0.275): 0.466666666667
(7, 1.0, 1.0, 0.3): 0.466666666667
(7, 10.0, 10.0, 0.2): 0.8
(7, 10.0, 10.0, 0.225): 0.8
(7, 10.0, 10.0, 0.25): 0.466666666667
(7, 10.0, 10.0, 0.275): 0.466666666667
(7, 10.0, 10.0, 0.3): 0.333333333333
(7, 100.0, 100.0, 0.2): 0.666666666667
(7, 100.0, 100.0, 0.225): 0.8
(7, 100.0, 100.0, 0.25): 0.6
(7, 100.0, 100.0, 0.275): 0.333333333333
(7, 100.0, 100.0, 0.3): 0.466666666667
(8, 1.0, 1.0, 0.2): 0.8
(8, 1.0, 1.0, 0.225): 0.533333333333
(8, 1.0, 1.0, 0.25): 0.8
(8, 1.0, 1.0, 0.275): 0.733333333333
(8, 1.0, 1.0, 0.3): 0.4
(8, 10.0, 10.0, 0.2): 0.733333333333
(8, 10.0, 10.0, 0.225): 0.733333333333
(8, 10.0, 10.0, 0.25): 0.8
(8, 10.0, 10.0, 0.275): 0.8
(8, 10.0, 10.0, 0.3): 0.666666666667
(8, 100.0, 100.0, 0.2): 0.866666666667
(8, 100.0, 100.0, 0.225): 0.6
(8, 100.0, 100.0, 0.25): 0.533333333333
(8, 100.0, 100.0, 0.275): 0.4
(8, 100.0, 100.0, 0.3): 0.6
(9, 1.0, 1.0, 0.2): 0.533333333333
(9, 1.0, 1.0, 0.225): 0.666666666667
(9, 1.0, 1.0, 0.25): 0.533333333333
(9, 1.0, 1.0, 0.275): 0.466666666667
(9, 1.0, 1.0, 0.3): 0.533333333333
(9, 10.0, 10.0, 0.2): 0.6
(9, 10.0, 10.0, 0.225): 0.8
(9, 10.0, 10.0, 0.25): 0.4
(9, 10.0, 10.0, 0.275): 0.533333333333
(9, 10.0, 10.0, 0.3): 0.6
(9, 100.0, 100.0, 0.2): 0.666666666667
(9, 100.0, 100.0, 0.225): 0.6
(9, 100.0, 100.0, 0.25): 0.466666666667
(9, 100.0, 100.0, 0.275): 0.466666666667
(9, 100.0, 100.0, 0.3): 0.6

Accuracy mean :0.38881720430107525
Std deviation :0.16007513555517747
Loss mean :0.6111827956989246
Std deviation :0.16007513555517747



QuantileLinPiecewise_4dim, number of iterations: 10

Parameters info
Tradeoffs parameter: [  0.1   1.   10.  100. ]
Using same parameters for all the clusterization: True
Gaussian kernel sigmas: [0.2   0.225 0.25  0.275 0.3  ]
Number of principal dimension considerated: 4
Dataset length: 150

Clusterization info
Minimum size of a cluster: in perc: 0.01, in int: 2
Type of mu: Binary Muzzifier
Fuzzifier: QuantileLinPiecewise
Cluster graph uses all connections: False
Cluster to label info
Force the number of cluster to be the number of different labels: False
Force the labels to be always represent by a cluster: False

Validation info
Conflict resolution: random
Number of cluster considerated for validation (top_k): None


RESULTS

On TEST set

Accuracy on test set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 10.0, 10.0, 0.225): 0.733333333333
(1, 100.0, 100.0, 0.225): 0.933333333333
(2, 10.0, 10.0, 0.225): 0.666666666667
(3, 1.0, 1.0, 0.225): 0.933333333333
(4, 0.1, 0.1, 0.25): 0.466666666667
(5, 100.0, 100.0, 0.2): 0.666666666667
(6, 1.0, 1.0, 0.225): 0.666666666667
(7, 10.0, 10.0, 0.225): 0.8
(8, 1.0, 1.0, 0.25): 0.533333333333
(9, 1.0, 1.0, 0.275): 0.2

Loss on test set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 10.0, 10.0, 0.225): 0.266666666667
(1, 100.0, 100.0, 0.225): 0.0666666666667
(2, 10.0, 10.0, 0.225): 0.333333333333
(3, 1.0, 1.0, 0.225): 0.0666666666667
(4, 0.1, 0.1, 0.25): 0.533333333333
(5, 100.0, 100.0, 0.2): 0.333333333333
(6, 1.0, 1.0, 0.225): 0.333333333333
(7, 10.0, 10.0, 0.225): 0.2
(8, 1.0, 1.0, 0.25): 0.466666666667
(9, 1.0, 1.0, 0.275): 0.8

Accuracy mean :0.66
Std deviation :0.2096558025802185
Loss mean :0.33999999999999997
Std deviation :0.20965580258021854

On TRAINING set

Accuracy on training set for every iteration (n_of_the_iter, c, sigma):
(0, 10.0, 10.0, 0.225): 0.792592592593
(1, 100.0, 100.0, 0.225): 0.822222222222
(2, 10.0, 10.0, 0.225): 0.666666666667
(3, 1.0, 1.0, 0.225): 0.859259259259
(4, 0.1, 0.1, 0.25): 0.688888888889
(5, 100.0, 100.0, 0.2): 0.666666666667
(6, 1.0, 1.0, 0.225): 0.659259259259
(7, 10.0, 10.0, 0.225): 0.874074074074
(8, 1.0, 1.0, 0.25): 0.681481481481
(9, 1.0, 1.0, 0.275): 0.348148148148
Loss on training set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 10.0, 10.0, 0.225): 0.207407407407
(1, 100.0, 100.0, 0.225): 0.177777777778
(2, 10.0, 10.0, 0.225): 0.333333333333
(3, 1.0, 1.0, 0.225): 0.140740740741
(4, 0.1, 0.1, 0.25): 0.311111111111
(5, 100.0, 100.0, 0.2): 0.333333333333
(6, 1.0, 1.0, 0.225): 0.340740740741
(7, 10.0, 10.0, 0.225): 0.125925925926
(8, 1.0, 1.0, 0.25): 0.318518518519
(9, 1.0, 1.0, 0.275): 0.651851851852

Accuracy mean :0.705925925925926
Std deviation :0.14386588786083476
Loss mean :0.29407407407407404
Std deviation :0.1438658878608348

On ALL the sets

Accuracy on all the set for every iteration, for every couple c,sigma (n_of_the_iter, c, sigma):
(0, 0.1, 0.1, 0.3): 0.6
(0, 1.0, 1.0, 0.2): 0.466666666667
(0, 1.0, 1.0, 0.225): 0.8
(0, 1.0, 1.0, 0.25): 0.2
(0, 1.0, 1.0, 0.275): 0.6
(0, 1.0, 1.0, 0.3): 0.6
(0, 10.0, 10.0, 0.2): 0.466666666667
(0, 10.0, 10.0, 0.225): 0.8
(0, 10.0, 10.0, 0.25): 0.6
(0, 10.0, 10.0, 0.275): 0.2
(0, 10.0, 10.0, 0.3): 0.6
(0, 100.0, 100.0, 0.2): 0.6
(0, 100.0, 100.0, 0.225): 0.266666666667
(0, 100.0, 100.0, 0.25): 0.2
(0, 100.0, 100.0, 0.275): 0.2
(0, 100.0, 100.0, 0.3): 0.6
(1, 0.1, 0.1, 0.25): 0.666666666667
(1, 0.1, 0.1, 0.275): 0.666666666667
(1, 0.1, 0.1, 0.3): 0.666666666667
(1, 1.0, 1.0, 0.2): 0.533333333333
(1, 1.0, 1.0, 0.225): 0.866666666667
(1, 1.0, 1.0, 0.25): 0.666666666667
(1, 1.0, 1.0, 0.275): 0.666666666667
(1, 1.0, 1.0, 0.3): 0.666666666667
(1, 10.0, 10.0, 0.2): 0.466666666667
(1, 10.0, 10.0, 0.225): 0.866666666667
(1, 10.0, 10.0, 0.25): 0.666666666667
(1, 10.0, 10.0, 0.275): 0.666666666667
(1, 10.0, 10.0, 0.3): 0.666666666667
(1, 100.0, 100.0, 0.2): 0.466666666667
(1, 100.0, 100.0, 0.225): 0.866666666667
(1, 100.0, 100.0, 0.25): 0.666666666667
(1, 100.0, 100.0, 0.275): 0.666666666667
(1, 100.0, 100.0, 0.3): 0.666666666667
(2, 0.1, 0.1, 0.3): 0.666666666667
(2, 1.0, 1.0, 0.2): 0.6
(2, 1.0, 1.0, 0.225): 0.733333333333
(2, 1.0, 1.0, 0.25): 0.4
(2, 1.0, 1.0, 0.275): 0.4
(2, 1.0, 1.0, 0.3): 0.666666666667
(2, 10.0, 10.0, 0.2): 0.6
(2, 10.0, 10.0, 0.225): 0.733333333333
(2, 10.0, 10.0, 0.25): 0.666666666667
(2, 10.0, 10.0, 0.275): 0.4
(2, 10.0, 10.0, 0.3): 0.666666666667
(2, 100.0, 100.0, 0.2): 0.6
(2, 100.0, 100.0, 0.225): 0.733333333333
(2, 100.0, 100.0, 0.25): 0.4
(2, 100.0, 100.0, 0.275): 0.6
(2, 100.0, 100.0, 0.3): 0.666666666667
(3, 0.1, 0.1, 0.275): 0.666666666667
(3, 0.1, 0.1, 0.3): 0.666666666667
(3, 1.0, 1.0, 0.2): 0.733333333333
(3, 1.0, 1.0, 0.225): 0.8
(3, 1.0, 1.0, 0.25): 0.666666666667
(3, 1.0, 1.0, 0.275): 0.666666666667
(3, 1.0, 1.0, 0.3): 0.666666666667
(3, 10.0, 10.0, 0.2): 0.666666666667
(3, 10.0, 10.0, 0.225): 0.733333333333
(3, 10.0, 10.0, 0.25): 0.666666666667
(3, 10.0, 10.0, 0.275): 0.666666666667
(3, 10.0, 10.0, 0.3): 0.666666666667
(3, 100.0, 100.0, 0.2): 0.733333333333
(3, 100.0, 100.0, 0.225): 0.733333333333
(3, 100.0, 100.0, 0.25): 0.666666666667
(3, 100.0, 100.0, 0.275): 0.666666666667
(3, 100.0, 100.0, 0.3): 0.666666666667
(4, 0.1, 0.1, 0.25): 0.8
(4, 0.1, 0.1, 0.275): 0.733333333333
(4, 0.1, 0.1, 0.3): 0.733333333333
(4, 1.0, 1.0, 0.2): 0.733333333333
(4, 1.0, 1.0, 0.225): 0.666666666667
(4, 1.0, 1.0, 0.25): 0.8
(4, 1.0, 1.0, 0.275): 0.733333333333
(4, 1.0, 1.0, 0.3): 0.733333333333
(4, 10.0, 10.0, 0.2): 0.733333333333
(4, 10.0, 10.0, 0.225): 0.666666666667
(4, 10.0, 10.0, 0.25): 0.8
(4, 10.0, 10.0, 0.275): 0.733333333333
(4, 10.0, 10.0, 0.3): 0.733333333333
(4, 100.0, 100.0, 0.2): 0.733333333333
(4, 100.0, 100.0, 0.225): 0.733333333333
(4, 100.0, 100.0, 0.25): 0.8
(4, 100.0, 100.0, 0.275): 0.733333333333
(4, 100.0, 100.0, 0.3): 0.733333333333
(5, 0.1, 0.1, 0.275): 0.466666666667
(5, 0.1, 0.1, 0.3): 0.466666666667
(5, 1.0, 1.0, 0.2): 0.466666666667
(5, 1.0, 1.0, 0.225): 0.466666666667
(5, 1.0, 1.0, 0.25): 0.466666666667
(5, 1.0, 1.0, 0.275): 0.466666666667
(5, 1.0, 1.0, 0.3): 0.466666666667
(5, 10.0, 10.0, 0.2): 0.466666666667
(5, 10.0, 10.0, 0.225): 0.466666666667
(5, 10.0, 10.0, 0.25): 0.466666666667
(5, 10.0, 10.0, 0.275): 0.466666666667
(5, 10.0, 10.0, 0.3): 0.466666666667
(5, 100.0, 100.0, 0.2): 0.466666666667
(5, 100.0, 100.0, 0.225): 0.466666666667
(5, 100.0, 100.0, 0.25): 0.466666666667
(5, 100.0, 100.0, 0.275): 0.466666666667
(5, 100.0, 100.0, 0.3): 0.466666666667
(6, 0.1, 0.1, 0.225): 0.666666666667
(6, 0.1, 0.1, 0.25): 0.666666666667
(6, 0.1, 0.1, 0.275): 0.666666666667
(6, 0.1, 0.1, 0.3): 0.333333333333
(6, 1.0, 1.0, 0.2): 0.666666666667
(6, 1.0, 1.0, 0.225): 0.666666666667
(6, 1.0, 1.0, 0.25): 0.666666666667
(6, 1.0, 1.0, 0.275): 0.666666666667
(6, 1.0, 1.0, 0.3): 0.666666666667
(6, 10.0, 10.0, 0.2): 0.6
(6, 10.0, 10.0, 0.225): 0.666666666667
(6, 10.0, 10.0, 0.25): 0.666666666667
(6, 10.0, 10.0, 0.275): 0.666666666667
(6, 10.0, 10.0, 0.3): 0.666666666667
(6, 100.0, 100.0, 0.2): 0.666666666667
(6, 100.0, 100.0, 0.225): 0.666666666667
(6, 100.0, 100.0, 0.25): 0.666666666667
(6, 100.0, 100.0, 0.275): 0.666666666667
(6, 100.0, 100.0, 0.3): 0.666666666667
(7, 0.1, 0.1, 0.2): 0.2
(7, 0.1, 0.1, 0.275): 0.6
(7, 1.0, 1.0, 0.2): 0.2
(7, 1.0, 1.0, 0.225): 0.8
(7, 1.0, 1.0, 0.25): 0.6
(7, 1.0, 1.0, 0.275): 0.6
(7, 1.0, 1.0, 0.3): 0.2
(7, 10.0, 10.0, 0.2): 0.2
(7, 10.0, 10.0, 0.225): 0.8
(7, 10.0, 10.0, 0.25): 0.2
(7, 10.0, 10.0, 0.275): 0.6
(7, 10.0, 10.0, 0.3): 0.2
(7, 100.0, 100.0, 0.2): 0.2
(7, 100.0, 100.0, 0.225): 0.8
(7, 100.0, 100.0, 0.25): 0.2
(7, 100.0, 100.0, 0.275): 0.6
(7, 100.0, 100.0, 0.3): 0.2
(8, 0.1, 0.1, 0.275): 0.8
(8, 0.1, 0.1, 0.3): 0.533333333333
(8, 1.0, 1.0, 0.2): 0.8
(8, 1.0, 1.0, 0.25): 0.933333333333
(8, 1.0, 1.0, 0.275): 0.8
(8, 1.0, 1.0, 0.3): 0.533333333333
(8, 10.0, 10.0, 0.2): 0.733333333333
(8, 10.0, 10.0, 0.25): 0.933333333333
(8, 10.0, 10.0, 0.275): 0.8
(8, 10.0, 10.0, 0.3): 0.533333333333
(8, 100.0, 100.0, 0.2): 0.733333333333
(8, 100.0, 100.0, 0.225): 0.533333333333
(8, 100.0, 100.0, 0.25): 0.933333333333
(8, 100.0, 100.0, 0.275): 0.8
(8, 100.0, 100.0, 0.3): 0.533333333333
(9, 0.1, 0.1, 0.25): 0.666666666667
(9, 1.0, 1.0, 0.2): 0.266666666667
(9, 1.0, 1.0, 0.225): 0.666666666667
(9, 1.0, 1.0, 0.25): 0.666666666667
(9, 1.0, 1.0, 0.275): 0.933333333333
(9, 1.0, 1.0, 0.3): 0.666666666667
(9, 10.0, 10.0, 0.2): 0.2
(9, 10.0, 10.0, 0.225): 0.666666666667
(9, 10.0, 10.0, 0.25): 0.666666666667
(9, 10.0, 10.0, 0.275): 0.933333333333
(9, 10.0, 10.0, 0.3): 0.666666666667
(9, 100.0, 100.0, 0.2): 0.2
(9, 100.0, 100.0, 0.225): 0.666666666667
(9, 100.0, 100.0, 0.25): 0.666666666667
(9, 100.0, 100.0, 0.275): 0.933333333333
(9, 100.0, 100.0, 0.3): 0.666666666667

Loss on all the set for every iteration, for every couple c,sigma (n_of_the_iter, best_c, best_sigma):
(0, 0.1, 0.1, 0.3): 0.4
(0, 1.0, 1.0, 0.2): 0.533333333333
(0, 1.0, 1.0, 0.225): 0.2
(0, 1.0, 1.0, 0.25): 0.8
(0, 1.0, 1.0, 0.275): 0.4
(0, 1.0, 1.0, 0.3): 0.4
(0, 10.0, 10.0, 0.2): 0.533333333333
(0, 10.0, 10.0, 0.225): 0.2
(0, 10.0, 10.0, 0.25): 0.4
(0, 10.0, 10.0, 0.275): 0.8
(0, 10.0, 10.0, 0.3): 0.4
(0, 100.0, 100.0, 0.2): 0.4
(0, 100.0, 100.0, 0.225): 0.733333333333
(0, 100.0, 100.0, 0.25): 0.8
(0, 100.0, 100.0, 0.275): 0.8
(0, 100.0, 100.0, 0.3): 0.4
(1, 0.1, 0.1, 0.25): 0.333333333333
(1, 0.1, 0.1, 0.275): 0.333333333333
(1, 0.1, 0.1, 0.3): 0.333333333333
(1, 1.0, 1.0, 0.2): 0.466666666667
(1, 1.0, 1.0, 0.225): 0.133333333333
(1, 1.0, 1.0, 0.25): 0.333333333333
(1, 1.0, 1.0, 0.275): 0.333333333333
(1, 1.0, 1.0, 0.3): 0.333333333333
(1, 10.0, 10.0, 0.2): 0.533333333333
(1, 10.0, 10.0, 0.225): 0.133333333333
(1, 10.0, 10.0, 0.25): 0.333333333333
(1, 10.0, 10.0, 0.275): 0.333333333333
(1, 10.0, 10.0, 0.3): 0.333333333333
(1, 100.0, 100.0, 0.2): 0.533333333333
(1, 100.0, 100.0, 0.225): 0.133333333333
(1, 100.0, 100.0, 0.25): 0.333333333333
(1, 100.0, 100.0, 0.275): 0.333333333333
(1, 100.0, 100.0, 0.3): 0.333333333333
(2, 0.1, 0.1, 0.3): 0.333333333333
(2, 1.0, 1.0, 0.2): 0.4
(2, 1.0, 1.0, 0.225): 0.266666666667
(2, 1.0, 1.0, 0.25): 0.6
(2, 1.0, 1.0, 0.275): 0.6
(2, 1.0, 1.0, 0.3): 0.333333333333
(2, 10.0, 10.0, 0.2): 0.4
(2, 10.0, 10.0, 0.225): 0.266666666667
(2, 10.0, 10.0, 0.25): 0.333333333333
(2, 10.0, 10.0, 0.275): 0.6
(2, 10.0, 10.0, 0.3): 0.333333333333
(2, 100.0, 100.0, 0.2): 0.4
(2, 100.0, 100.0, 0.225): 0.266666666667
(2, 100.0, 100.0, 0.25): 0.6
(2, 100.0, 100.0, 0.275): 0.4
(2, 100.0, 100.0, 0.3): 0.333333333333
(3, 0.1, 0.1, 0.275): 0.333333333333
(3, 0.1, 0.1, 0.3): 0.333333333333
(3, 1.0, 1.0, 0.2): 0.266666666667
(3, 1.0, 1.0, 0.225): 0.2
(3, 1.0, 1.0, 0.25): 0.333333333333
(3, 1.0, 1.0, 0.275): 0.333333333333
(3, 1.0, 1.0, 0.3): 0.333333333333
(3, 10.0, 10.0, 0.2): 0.333333333333
(3, 10.0, 10.0, 0.225): 0.266666666667
(3, 10.0, 10.0, 0.25): 0.333333333333
(3, 10.0, 10.0, 0.275): 0.333333333333
(3, 10.0, 10.0, 0.3): 0.333333333333
(3, 100.0, 100.0, 0.2): 0.266666666667
(3, 100.0, 100.0, 0.225): 0.266666666667
(3, 100.0, 100.0, 0.25): 0.333333333333
(3, 100.0, 100.0, 0.275): 0.333333333333
(3, 100.0, 100.0, 0.3): 0.333333333333
(4, 0.1, 0.1, 0.25): 0.2
(4, 0.1, 0.1, 0.275): 0.266666666667
(4, 0.1, 0.1, 0.3): 0.266666666667
(4, 1.0, 1.0, 0.2): 0.266666666667
(4, 1.0, 1.0, 0.225): 0.333333333333
(4, 1.0, 1.0, 0.25): 0.2
(4, 1.0, 1.0, 0.275): 0.266666666667
(4, 1.0, 1.0, 0.3): 0.266666666667
(4, 10.0, 10.0, 0.2): 0.266666666667
(4, 10.0, 10.0, 0.225): 0.333333333333
(4, 10.0, 10.0, 0.25): 0.2
(4, 10.0, 10.0, 0.275): 0.266666666667
(4, 10.0, 10.0, 0.3): 0.266666666667
(4, 100.0, 100.0, 0.2): 0.266666666667
(4, 100.0, 100.0, 0.225): 0.266666666667
(4, 100.0, 100.0, 0.25): 0.2
(4, 100.0, 100.0, 0.275): 0.266666666667
(4, 100.0, 100.0, 0.3): 0.266666666667
(5, 0.1, 0.1, 0.275): 0.533333333333
(5, 0.1, 0.1, 0.3): 0.533333333333
(5, 1.0, 1.0, 0.2): 0.533333333333
(5, 1.0, 1.0, 0.225): 0.533333333333
(5, 1.0, 1.0, 0.25): 0.533333333333
(5, 1.0, 1.0, 0.275): 0.533333333333
(5, 1.0, 1.0, 0.3): 0.533333333333
(5, 10.0, 10.0, 0.2): 0.533333333333
(5, 10.0, 10.0, 0.225): 0.533333333333
(5, 10.0, 10.0, 0.25): 0.533333333333
(5, 10.0, 10.0, 0.275): 0.533333333333
(5, 10.0, 10.0, 0.3): 0.533333333333
(5, 100.0, 100.0, 0.2): 0.533333333333
(5, 100.0, 100.0, 0.225): 0.533333333333
(5, 100.0, 100.0, 0.25): 0.533333333333
(5, 100.0, 100.0, 0.275): 0.533333333333
(5, 100.0, 100.0, 0.3): 0.533333333333
(6, 0.1, 0.1, 0.225): 0.333333333333
(6, 0.1, 0.1, 0.25): 0.333333333333
(6, 0.1, 0.1, 0.275): 0.333333333333
(6, 0.1, 0.1, 0.3): 0.666666666667
(6, 1.0, 1.0, 0.2): 0.333333333333
(6, 1.0, 1.0, 0.225): 0.333333333333
(6, 1.0, 1.0, 0.25): 0.333333333333
(6, 1.0, 1.0, 0.275): 0.333333333333
(6, 1.0, 1.0, 0.3): 0.333333333333
(6, 10.0, 10.0, 0.2): 0.4
(6, 10.0, 10.0, 0.225): 0.333333333333
(6, 10.0, 10.0, 0.25): 0.333333333333
(6, 10.0, 10.0, 0.275): 0.333333333333
(6, 10.0, 10.0, 0.3): 0.333333333333
(6, 100.0, 100.0, 0.2): 0.333333333333
(6, 100.0, 100.0, 0.225): 0.333333333333
(6, 100.0, 100.0, 0.25): 0.333333333333
(6, 100.0, 100.0, 0.275): 0.333333333333
(6, 100.0, 100.0, 0.3): 0.333333333333
(7, 0.1, 0.1, 0.2): 0.8
(7, 0.1, 0.1, 0.275): 0.4
(7, 1.0, 1.0, 0.2): 0.8
(7, 1.0, 1.0, 0.225): 0.2
(7, 1.0, 1.0, 0.25): 0.4
(7, 1.0, 1.0, 0.275): 0.4
(7, 1.0, 1.0, 0.3): 0.8
(7, 10.0, 10.0, 0.2): 0.8
(7, 10.0, 10.0, 0.225): 0.2
(7, 10.0, 10.0, 0.25): 0.8
(7, 10.0, 10.0, 0.275): 0.4
(7, 10.0, 10.0, 0.3): 0.8
(7, 100.0, 100.0, 0.2): 0.8
(7, 100.0, 100.0, 0.225): 0.2
(7, 100.0, 100.0, 0.25): 0.8
(7, 100.0, 100.0, 0.275): 0.4
(7, 100.0, 100.0, 0.3): 0.8
(8, 0.1, 0.1, 0.275): 0.2
(8, 0.1, 0.1, 0.3): 0.466666666667
(8, 1.0, 1.0, 0.2): 0.2
(8, 1.0, 1.0, 0.25): 0.0666666666667
(8, 1.0, 1.0, 0.275): 0.2
(8, 1.0, 1.0, 0.3): 0.466666666667
(8, 10.0, 10.0, 0.2): 0.266666666667
(8, 10.0, 10.0, 0.25): 0.0666666666667
(8, 10.0, 10.0, 0.275): 0.2
(8, 10.0, 10.0, 0.3): 0.466666666667
(8, 100.0, 100.0, 0.2): 0.266666666667
(8, 100.0, 100.0, 0.225): 0.466666666667
(8, 100.0, 100.0, 0.25): 0.0666666666667
(8, 100.0, 100.0, 0.275): 0.2
(8, 100.0, 100.0, 0.3): 0.466666666667
(9, 0.1, 0.1, 0.25): 0.333333333333
(9, 1.0, 1.0, 0.2): 0.733333333333
(9, 1.0, 1.0, 0.225): 0.333333333333
(9, 1.0, 1.0, 0.25): 0.333333333333
(9, 1.0, 1.0, 0.275): 0.0666666666667
(9, 1.0, 1.0, 0.3): 0.333333333333
(9, 10.0, 10.0, 0.2): 0.8
(9, 10.0, 10.0, 0.225): 0.333333333333
(9, 10.0, 10.0, 0.25): 0.333333333333
(9, 10.0, 10.0, 0.275): 0.0666666666667
(9, 10.0, 10.0, 0.3): 0.333333333333
(9, 100.0, 100.0, 0.2): 0.8
(9, 100.0, 100.0, 0.225): 0.333333333333
(9, 100.0, 100.0, 0.25): 0.333333333333
(9, 100.0, 100.0, 0.275): 0.0666666666667
(9, 100.0, 100.0, 0.3): 0.333333333333

Accuracy mean :0.6090729783037475
Std deviation :0.17793244752966678
Loss mean :0.39092702169625243
Std deviation :0.17793244752966678



Crisp_4dim, number of iterations: 10

Parameters info
Tradeoffs parameter: [  0.1   1.   10.  100. ]
Using same parameters for all the clusterization: True
Gaussian kernel sigmas: [0.2   0.225 0.25  0.275 0.3  ]
Number of principal dimension considerated: 4
Dataset length: 150

Clusterization info
Minimum size of a cluster: in perc: 0.01, in int: 2
Type of mu: Binary Muzzifier
Fuzzifier: Crisp
Cluster graph uses all connections: False
Cluster to label info
Force the number of cluster to be the number of different labels: False
Force the labels to be always represent by a cluster: False

Validation info
Conflict resolution: random
Number of cluster considerated for validation (top_k): None


RESULTS

On TEST set

Accuracy on test set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 10.0, 10.0, 0.25): 0.2
(1, 100.0, 100.0, 0.275): 0.333333333333
(2, 1.0, 1.0, 0.225): 0.266666666667
(3, 10.0, 10.0, 0.3): 0.2
(4, 1.0, 1.0, 0.3): 0.333333333333
(5, 1.0, 1.0, 0.25): 0.4
(6, 100.0, 100.0, 0.275): 0.4
(7, 1.0, 1.0, 0.25): 0.533333333333
(8, 0.1, 0.1, 0.275): 0.4
(9, 100.0, 100.0, 0.3): 0.4

Loss on test set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 10.0, 10.0, 0.25): 0.8
(1, 100.0, 100.0, 0.275): 0.666666666667
(2, 1.0, 1.0, 0.225): 0.733333333333
(3, 10.0, 10.0, 0.3): 0.8
(4, 1.0, 1.0, 0.3): 0.666666666667
(5, 1.0, 1.0, 0.25): 0.6
(6, 100.0, 100.0, 0.275): 0.6
(7, 1.0, 1.0, 0.25): 0.466666666667
(8, 0.1, 0.1, 0.275): 0.6
(9, 100.0, 100.0, 0.3): 0.6

Accuracy mean :0.34666666666666673
Std deviation :0.09797958971132713
Loss mean :0.6533333333333333
Std deviation :0.09797958971132713

On TRAINING set

Accuracy on training set for every iteration (n_of_the_iter, c, sigma):
(0, 10.0, 10.0, 0.25): 0.533333333333
(1, 100.0, 100.0, 0.275): 0.518518518519
(2, 1.0, 1.0, 0.225): 0.42962962963
(3, 10.0, 10.0, 0.3): 0.548148148148
(4, 1.0, 1.0, 0.3): 0.6
(5, 1.0, 1.0, 0.25): 0.377777777778
(6, 100.0, 100.0, 0.275): 0.4
(7, 1.0, 1.0, 0.25): 0.437037037037
(8, 0.1, 0.1, 0.275): 0.585185185185
(9, 100.0, 100.0, 0.3): 0.422222222222
Loss on training set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 10.0, 10.0, 0.25): 0.466666666667
(1, 100.0, 100.0, 0.275): 0.481481481481
(2, 1.0, 1.0, 0.225): 0.57037037037
(3, 10.0, 10.0, 0.3): 0.451851851852
(4, 1.0, 1.0, 0.3): 0.4
(5, 1.0, 1.0, 0.25): 0.622222222222
(6, 100.0, 100.0, 0.275): 0.6
(7, 1.0, 1.0, 0.25): 0.562962962963
(8, 0.1, 0.1, 0.275): 0.414814814815
(9, 100.0, 100.0, 0.3): 0.577777777778

Accuracy mean :0.4851851851851851
Std deviation :0.07664071845730294
Loss mean :0.5148148148148148
Std deviation :0.07664071845730296

On ALL the sets

Accuracy on all the set for every iteration, for every couple c,sigma (n_of_the_iter, c, sigma):
(0, 0.1, 0.1, 0.225): 0.4
(0, 0.1, 0.1, 0.275): 0.4
(0, 0.1, 0.1, 0.3): 0.333333333333
(0, 1.0, 1.0, 0.2): 0.333333333333
(0, 1.0, 1.0, 0.225): 0.333333333333
(0, 1.0, 1.0, 0.25): 0.466666666667
(0, 1.0, 1.0, 0.275): 0.333333333333
(0, 1.0, 1.0, 0.3): 0.133333333333
(0, 10.0, 10.0, 0.2): 0.266666666667
(0, 10.0, 10.0, 0.225): 0.466666666667
(0, 10.0, 10.0, 0.25): 0.533333333333
(0, 10.0, 10.0, 0.275): 0.0666666666667
(0, 10.0, 10.0, 0.3): 0.0666666666667
(0, 100.0, 100.0, 0.2): 0.4
(0, 100.0, 100.0, 0.225): 0.466666666667
(0, 100.0, 100.0, 0.25): 0.533333333333
(0, 100.0, 100.0, 0.275): 0.466666666667
(0, 100.0, 100.0, 0.3): 0.333333333333
(1, 0.1, 0.1, 0.3): 0.4
(1, 1.0, 1.0, 0.2): 0.133333333333
(1, 1.0, 1.0, 0.225): 0.2
(1, 1.0, 1.0, 0.25): 0.2
(1, 1.0, 1.0, 0.275): 0.466666666667
(1, 1.0, 1.0, 0.3): 0.333333333333
(1, 10.0, 10.0, 0.2): 0.333333333333
(1, 10.0, 10.0, 0.225): 0.266666666667
(1, 10.0, 10.0, 0.25): 0.2
(1, 10.0, 10.0, 0.275): 0.466666666667
(1, 10.0, 10.0, 0.3): 0.266666666667
(1, 100.0, 100.0, 0.2): 0.0666666666667
(1, 100.0, 100.0, 0.225): 0.266666666667
(1, 100.0, 100.0, 0.25): 0.266666666667
(1, 100.0, 100.0, 0.275): 0.533333333333
(1, 100.0, 100.0, 0.3): 0.4
(2, 0.1, 0.1, 0.3): 0.4
(2, 1.0, 1.0, 0.2): 0.266666666667
(2, 1.0, 1.0, 0.225): 0.533333333333
(2, 1.0, 1.0, 0.25): 0.333333333333
(2, 1.0, 1.0, 0.275): 0.4
(2, 1.0, 1.0, 0.3): 0.266666666667
(2, 10.0, 10.0, 0.2): 0.333333333333
(2, 10.0, 10.0, 0.225): 0.533333333333
(2, 10.0, 10.0, 0.25): 0.266666666667
(2, 10.0, 10.0, 0.275): 0.466666666667
(2, 10.0, 10.0, 0.3): 0.333333333333
(2, 100.0, 100.0, 0.2): 0.2
(2, 100.0, 100.0, 0.225): 0.333333333333
(2, 100.0, 100.0, 0.25): 0.333333333333
(2, 100.0, 100.0, 0.275): 0.466666666667
(2, 100.0, 100.0, 0.3): 0.266666666667
(3, 0.1, 0.1, 0.225): 0.333333333333
(3, 0.1, 0.1, 0.25): 0.333333333333
(3, 0.1, 0.1, 0.3): 0.333333333333
(3, 1.0, 1.0, 0.2): 0.333333333333
(3, 1.0, 1.0, 0.225): 0.333333333333
(3, 1.0, 1.0, 0.25): 0.4
(3, 1.0, 1.0, 0.275): 0.333333333333
(3, 1.0, 1.0, 0.3): 0.4
(3, 10.0, 10.0, 0.2): 0.333333333333
(3, 10.0, 10.0, 0.225): 0.333333333333
(3, 10.0, 10.0, 0.25): 0.333333333333
(3, 10.0, 10.0, 0.275): 0.333333333333
(3, 10.0, 10.0, 0.3): 0.466666666667
(3, 100.0, 100.0, 0.2): 0.333333333333
(3, 100.0, 100.0, 0.225): 0.333333333333
(3, 100.0, 100.0, 0.25): 0.466666666667
(3, 100.0, 100.0, 0.275): 0.333333333333
(3, 100.0, 100.0, 0.3): 0.266666666667
(4, 0.1, 0.1, 0.2): 0.333333333333
(4, 1.0, 1.0, 0.2): 0.266666666667
(4, 1.0, 1.0, 0.225): 0.333333333333
(4, 1.0, 1.0, 0.25): 0.266666666667
(4, 1.0, 1.0, 0.275): 0.333333333333
(4, 1.0, 1.0, 0.3): 0.6
(4, 10.0, 10.0, 0.2): 0.2
(4, 10.0, 10.0, 0.225): 0.333333333333
(4, 10.0, 10.0, 0.25): 0.466666666667
(4, 10.0, 10.0, 0.275): 0.466666666667
(4, 10.0, 10.0, 0.3): 0.333333333333
(4, 100.0, 100.0, 0.2): 0.2
(4, 100.0, 100.0, 0.225): 0.333333333333
(4, 100.0, 100.0, 0.25): 0.466666666667
(4, 100.0, 100.0, 0.275): 0.333333333333
(4, 100.0, 100.0, 0.3): 0.2
(5, 0.1, 0.1, 0.25): 0.533333333333
(5, 0.1, 0.1, 0.275): 0.533333333333
(5, 0.1, 0.1, 0.3): 0.466666666667
(5, 1.0, 1.0, 0.2): 0.4
(5, 1.0, 1.0, 0.225): 0.133333333333
(5, 1.0, 1.0, 0.25): 0.666666666667
(5, 1.0, 1.0, 0.275): 0.266666666667
(5, 1.0, 1.0, 0.3): 0.4
(5, 10.0, 10.0, 0.2): 0.4
(5, 10.0, 10.0, 0.225): 0.4
(5, 10.0, 10.0, 0.25): 0.466666666667
(5, 10.0, 10.0, 0.275): 0.466666666667
(5, 10.0, 10.0, 0.3): 0.533333333333
(5, 100.0, 100.0, 0.2): 0.333333333333
(5, 100.0, 100.0, 0.225): 0.333333333333
(5, 100.0, 100.0, 0.25): 0.333333333333
(5, 100.0, 100.0, 0.275): 0.466666666667
(5, 100.0, 100.0, 0.3): 0.533333333333
(6, 0.1, 0.1, 0.25): 0.333333333333
(6, 0.1, 0.1, 0.275): 0.333333333333
(6, 0.1, 0.1, 0.3): 0.533333333333
(6, 1.0, 1.0, 0.2): 0.333333333333
(6, 1.0, 1.0, 0.225): 0.266666666667
(6, 1.0, 1.0, 0.25): 0.4
(6, 1.0, 1.0, 0.275): 0.533333333333
(6, 1.0, 1.0, 0.3): 0.4
(6, 10.0, 10.0, 0.2): 0.6
(6, 10.0, 10.0, 0.225): 0.466666666667
(6, 10.0, 10.0, 0.25): 0.266666666667
(6, 10.0, 10.0, 0.275): 0.333333333333
(6, 10.0, 10.0, 0.3): 0.466666666667
(6, 100.0, 100.0, 0.2): 0.333333333333
(6, 100.0, 100.0, 0.225): 0.266666666667
(6, 100.0, 100.0, 0.25): 0.466666666667
(6, 100.0, 100.0, 0.275): 0.6
(6, 100.0, 100.0, 0.3): 0.466666666667
(7, 0.1, 0.1, 0.25): 0.466666666667
(7, 0.1, 0.1, 0.275): 0.466666666667
(7, 0.1, 0.1, 0.3): 0.333333333333
(7, 1.0, 1.0, 0.2): 0.333333333333
(7, 1.0, 1.0, 0.225): 0.266666666667
(7, 1.0, 1.0, 0.25): 0.666666666667
(7, 1.0, 1.0, 0.275): 0.4
(7, 1.0, 1.0, 0.3): 0.333333333333
(7, 10.0, 10.0, 0.2): 0.266666666667
(7, 10.0, 10.0, 0.225): 0.2
(7, 10.0, 10.0, 0.25): 0.333333333333
(7, 10.0, 10.0, 0.275): 0.133333333333
(7, 10.0, 10.0, 0.3): 0.4
(7, 100.0, 100.0, 0.2): 0.466666666667
(7, 100.0, 100.0, 0.225): 0.266666666667
(7, 100.0, 100.0, 0.25): 0.333333333333
(7, 100.0, 100.0, 0.275): 0.2
(7, 100.0, 100.0, 0.3): 0.266666666667
(8, 0.1, 0.1, 0.275): 0.6
(8, 0.1, 0.1, 0.3): 0.333333333333
(8, 1.0, 1.0, 0.2): 0.4
(8, 1.0, 1.0, 0.225): 0.266666666667
(8, 1.0, 1.0, 0.25): 0.4
(8, 1.0, 1.0, 0.275): 0.333333333333
(8, 1.0, 1.0, 0.3): 0.333333333333
(8, 10.0, 10.0, 0.2): 0.4
(8, 10.0, 10.0, 0.225): 0.333333333333
(8, 10.0, 10.0, 0.25): 0.466666666667
(8, 10.0, 10.0, 0.275): 0.4
(8, 10.0, 10.0, 0.3): 0.333333333333
(8, 100.0, 100.0, 0.2): 0.4
(8, 100.0, 100.0, 0.225): 0.133333333333
(8, 100.0, 100.0, 0.25): 0.466666666667
(8, 100.0, 100.0, 0.275): 0.4
(8, 100.0, 100.0, 0.3): 0.4
(9, 0.1, 0.1, 0.3): 0.4
(9, 1.0, 1.0, 0.2): 0.266666666667
(9, 1.0, 1.0, 0.225): 0.4
(9, 1.0, 1.0, 0.25): 0.266666666667
(9, 1.0, 1.0, 0.275): 0.4
(9, 1.0, 1.0, 0.3): 0.4
(9, 10.0, 10.0, 0.2): 0.2
(9, 10.0, 10.0, 0.225): 0.333333333333
(9, 10.0, 10.0, 0.25): 0.466666666667
(9, 10.0, 10.0, 0.275): 0.266666666667
(9, 10.0, 10.0, 0.3): 0.333333333333
(9, 100.0, 100.0, 0.2): 0.2
(9, 100.0, 100.0, 0.225): 0.533333333333
(9, 100.0, 100.0, 0.25): 0.266666666667
(9, 100.0, 100.0, 0.275): 0.266666666667
(9, 100.0, 100.0, 0.3): 0.533333333333

Loss on all the set for every iteration, for every couple c,sigma (n_of_the_iter, best_c, best_sigma):
(0, 0.1, 0.1, 0.225): 0.6
(0, 0.1, 0.1, 0.275): 0.6
(0, 0.1, 0.1, 0.3): 0.666666666667
(0, 1.0, 1.0, 0.2): 0.666666666667
(0, 1.0, 1.0, 0.225): 0.666666666667
(0, 1.0, 1.0, 0.25): 0.533333333333
(0, 1.0, 1.0, 0.275): 0.666666666667
(0, 1.0, 1.0, 0.3): 0.866666666667
(0, 10.0, 10.0, 0.2): 0.733333333333
(0, 10.0, 10.0, 0.225): 0.533333333333
(0, 10.0, 10.0, 0.25): 0.466666666667
(0, 10.0, 10.0, 0.275): 0.933333333333
(0, 10.0, 10.0, 0.3): 0.933333333333
(0, 100.0, 100.0, 0.2): 0.6
(0, 100.0, 100.0, 0.225): 0.533333333333
(0, 100.0, 100.0, 0.25): 0.466666666667
(0, 100.0, 100.0, 0.275): 0.533333333333
(0, 100.0, 100.0, 0.3): 0.666666666667
(1, 0.1, 0.1, 0.3): 0.6
(1, 1.0, 1.0, 0.2): 0.866666666667
(1, 1.0, 1.0, 0.225): 0.8
(1, 1.0, 1.0, 0.25): 0.8
(1, 1.0, 1.0, 0.275): 0.533333333333
(1, 1.0, 1.0, 0.3): 0.666666666667
(1, 10.0, 10.0, 0.2): 0.666666666667
(1, 10.0, 10.0, 0.225): 0.733333333333
(1, 10.0, 10.0, 0.25): 0.8
(1, 10.0, 10.0, 0.275): 0.533333333333
(1, 10.0, 10.0, 0.3): 0.733333333333
(1, 100.0, 100.0, 0.2): 0.933333333333
(1, 100.0, 100.0, 0.225): 0.733333333333
(1, 100.0, 100.0, 0.25): 0.733333333333
(1, 100.0, 100.0, 0.275): 0.466666666667
(1, 100.0, 100.0, 0.3): 0.6
(2, 0.1, 0.1, 0.3): 0.6
(2, 1.0, 1.0, 0.2): 0.733333333333
(2, 1.0, 1.0, 0.225): 0.466666666667
(2, 1.0, 1.0, 0.25): 0.666666666667
(2, 1.0, 1.0, 0.275): 0.6
(2, 1.0, 1.0, 0.3): 0.733333333333
(2, 10.0, 10.0, 0.2): 0.666666666667
(2, 10.0, 10.0, 0.225): 0.466666666667
(2, 10.0, 10.0, 0.25): 0.733333333333
(2, 10.0, 10.0, 0.275): 0.533333333333
(2, 10.0, 10.0, 0.3): 0.666666666667
(2, 100.0, 100.0, 0.2): 0.8
(2, 100.0, 100.0, 0.225): 0.666666666667
(2, 100.0, 100.0, 0.25): 0.666666666667
(2, 100.0, 100.0, 0.275): 0.533333333333
(2, 100.0, 100.0, 0.3): 0.733333333333
(3, 0.1, 0.1, 0.225): 0.666666666667
(3, 0.1, 0.1, 0.25): 0.666666666667
(3, 0.1, 0.1, 0.3): 0.666666666667
(3, 1.0, 1.0, 0.2): 0.666666666667
(3, 1.0, 1.0, 0.225): 0.666666666667
(3, 1.0, 1.0, 0.25): 0.6
(3, 1.0, 1.0, 0.275): 0.666666666667
(3, 1.0, 1.0, 0.3): 0.6
(3, 10.0, 10.0, 0.2): 0.666666666667
(3, 10.0, 10.0, 0.225): 0.666666666667
(3, 10.0, 10.0, 0.25): 0.666666666667
(3, 10.0, 10.0, 0.275): 0.666666666667
(3, 10.0, 10.0, 0.3): 0.533333333333
(3, 100.0, 100.0, 0.2): 0.666666666667
(3, 100.0, 100.0, 0.225): 0.666666666667
(3, 100.0, 100.0, 0.25): 0.533333333333
(3, 100.0, 100.0, 0.275): 0.666666666667
(3, 100.0, 100.0, 0.3): 0.733333333333
(4, 0.1, 0.1, 0.2): 0.666666666667
(4, 1.0, 1.0, 0.2): 0.733333333333
(4, 1.0, 1.0, 0.225): 0.666666666667
(4, 1.0, 1.0, 0.25): 0.733333333333
(4, 1.0, 1.0, 0.275): 0.666666666667
(4, 1.0, 1.0, 0.3): 0.4
(4, 10.0, 10.0, 0.2): 0.8
(4, 10.0, 10.0, 0.225): 0.666666666667
(4, 10.0, 10.0, 0.25): 0.533333333333
(4, 10.0, 10.0, 0.275): 0.533333333333
(4, 10.0, 10.0, 0.3): 0.666666666667
(4, 100.0, 100.0, 0.2): 0.8
(4, 100.0, 100.0, 0.225): 0.666666666667
(4, 100.0, 100.0, 0.25): 0.533333333333
(4, 100.0, 100.0, 0.275): 0.666666666667
(4, 100.0, 100.0, 0.3): 0.8
(5, 0.1, 0.1, 0.25): 0.466666666667
(5, 0.1, 0.1, 0.275): 0.466666666667
(5, 0.1, 0.1, 0.3): 0.533333333333
(5, 1.0, 1.0, 0.2): 0.6
(5, 1.0, 1.0, 0.225): 0.866666666667
(5, 1.0, 1.0, 0.25): 0.333333333333
(5, 1.0, 1.0, 0.275): 0.733333333333
(5, 1.0, 1.0, 0.3): 0.6
(5, 10.0, 10.0, 0.2): 0.6
(5, 10.0, 10.0, 0.225): 0.6
(5, 10.0, 10.0, 0.25): 0.533333333333
(5, 10.0, 10.0, 0.275): 0.533333333333
(5, 10.0, 10.0, 0.3): 0.466666666667
(5, 100.0, 100.0, 0.2): 0.666666666667
(5, 100.0, 100.0, 0.225): 0.666666666667
(5, 100.0, 100.0, 0.25): 0.666666666667
(5, 100.0, 100.0, 0.275): 0.533333333333
(5, 100.0, 100.0, 0.3): 0.466666666667
(6, 0.1, 0.1, 0.25): 0.666666666667
(6, 0.1, 0.1, 0.275): 0.666666666667
(6, 0.1, 0.1, 0.3): 0.466666666667
(6, 1.0, 1.0, 0.2): 0.666666666667
(6, 1.0, 1.0, 0.225): 0.733333333333
(6, 1.0, 1.0, 0.25): 0.6
(6, 1.0, 1.0, 0.275): 0.466666666667
(6, 1.0, 1.0, 0.3): 0.6
(6, 10.0, 10.0, 0.2): 0.4
(6, 10.0, 10.0, 0.225): 0.533333333333
(6, 10.0, 10.0, 0.25): 0.733333333333
(6, 10.0, 10.0, 0.275): 0.666666666667
(6, 10.0, 10.0, 0.3): 0.533333333333
(6, 100.0, 100.0, 0.2): 0.666666666667
(6, 100.0, 100.0, 0.225): 0.733333333333
(6, 100.0, 100.0, 0.25): 0.533333333333
(6, 100.0, 100.0, 0.275): 0.4
(6, 100.0, 100.0, 0.3): 0.533333333333
(7, 0.1, 0.1, 0.25): 0.533333333333
(7, 0.1, 0.1, 0.275): 0.533333333333
(7, 0.1, 0.1, 0.3): 0.666666666667
(7, 1.0, 1.0, 0.2): 0.666666666667
(7, 1.0, 1.0, 0.225): 0.733333333333
(7, 1.0, 1.0, 0.25): 0.333333333333
(7, 1.0, 1.0, 0.275): 0.6
(7, 1.0, 1.0, 0.3): 0.666666666667
(7, 10.0, 10.0, 0.2): 0.733333333333
(7, 10.0, 10.0, 0.225): 0.8
(7, 10.0, 10.0, 0.25): 0.666666666667
(7, 10.0, 10.0, 0.275): 0.866666666667
(7, 10.0, 10.0, 0.3): 0.6
(7, 100.0, 100.0, 0.2): 0.533333333333
(7, 100.0, 100.0, 0.225): 0.733333333333
(7, 100.0, 100.0, 0.25): 0.666666666667
(7, 100.0, 100.0, 0.275): 0.8
(7, 100.0, 100.0, 0.3): 0.733333333333
(8, 0.1, 0.1, 0.275): 0.4
(8, 0.1, 0.1, 0.3): 0.666666666667
(8, 1.0, 1.0, 0.2): 0.6
(8, 1.0, 1.0, 0.225): 0.733333333333
(8, 1.0, 1.0, 0.25): 0.6
(8, 1.0, 1.0, 0.275): 0.666666666667
(8, 1.0, 1.0, 0.3): 0.666666666667
(8, 10.0, 10.0, 0.2): 0.6
(8, 10.0, 10.0, 0.225): 0.666666666667
(8, 10.0, 10.0, 0.25): 0.533333333333
(8, 10.0, 10.0, 0.275): 0.6
(8, 10.0, 10.0, 0.3): 0.666666666667
(8, 100.0, 100.0, 0.2): 0.6
(8, 100.0, 100.0, 0.225): 0.866666666667
(8, 100.0, 100.0, 0.25): 0.533333333333
(8, 100.0, 100.0, 0.275): 0.6
(8, 100.0, 100.0, 0.3): 0.6
(9, 0.1, 0.1, 0.3): 0.6
(9, 1.0, 1.0, 0.2): 0.733333333333
(9, 1.0, 1.0, 0.225): 0.6
(9, 1.0, 1.0, 0.25): 0.733333333333
(9, 1.0, 1.0, 0.275): 0.6
(9, 1.0, 1.0, 0.3): 0.6
(9, 10.0, 10.0, 0.2): 0.8
(9, 10.0, 10.0, 0.225): 0.666666666667
(9, 10.0, 10.0, 0.25): 0.533333333333
(9, 10.0, 10.0, 0.275): 0.733333333333
(9, 10.0, 10.0, 0.3): 0.666666666667
(9, 100.0, 100.0, 0.2): 0.8
(9, 100.0, 100.0, 0.225): 0.466666666667
(9, 100.0, 100.0, 0.25): 0.733333333333
(9, 100.0, 100.0, 0.275): 0.733333333333
(9, 100.0, 100.0, 0.3): 0.466666666667

Accuracy mean :0.36140350877192984
Std deviation :0.1139615897498179
Loss mean :0.6385964912280702
Std deviation :0.1139615897498179



Linear_4dim, number of iterations: 10

Parameters info
Tradeoffs parameter: [  0.1   1.   10.  100. ]
Using same parameters for all the clusterization: True
Gaussian kernel sigmas: [0.2   0.225 0.25  0.275 0.3  ]
Number of principal dimension considerated: 4
Dataset length: 150

Clusterization info
Minimum size of a cluster: in perc: 0.01, in int: 2
Type of mu: Binary Muzzifier
Fuzzifier: Linear
Cluster graph uses all connections: False
Cluster to label info
Force the number of cluster to be the number of different labels: False
Force the labels to be always represent by a cluster: False

Validation info
Conflict resolution: random
Number of cluster considerated for validation (top_k): None


RESULTS

On TEST set

Accuracy on test set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 100.0, 100.0, 0.275): 0.666666666667
(1, 100.0, 100.0, 0.225): 0.666666666667
(2, 1.0, 1.0, 0.225): 1.0
(3, 100.0, 100.0, 0.25): 0.8
(4, 1.0, 1.0, 0.275): 0.6
(5, 100.0, 100.0, 0.25): 0.733333333333
(6, 10.0, 10.0, 0.225): 0.733333333333
(7, 100.0, 100.0, 0.25): 0.266666666667
(8, 10.0, 10.0, 0.25): 0.533333333333
(9, 0.1, 0.1, 0.25): 0.8

Loss on test set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 100.0, 100.0, 0.275): 0.333333333333
(1, 100.0, 100.0, 0.225): 0.333333333333
(2, 1.0, 1.0, 0.225): 0.0
(3, 100.0, 100.0, 0.25): 0.2
(4, 1.0, 1.0, 0.275): 0.4
(5, 100.0, 100.0, 0.25): 0.266666666667
(6, 10.0, 10.0, 0.225): 0.266666666667
(7, 100.0, 100.0, 0.25): 0.733333333333
(8, 10.0, 10.0, 0.25): 0.466666666667
(9, 0.1, 0.1, 0.25): 0.2

Accuracy mean :0.6799999999999999
Std deviation :0.18330302779823363
Loss mean :0.32000000000000006
Std deviation :0.1833030277982336

On TRAINING set

Accuracy on training set for every iteration (n_of_the_iter, c, sigma):
(0, 100.0, 100.0, 0.275): 0.666666666667
(1, 100.0, 100.0, 0.225): 0.666666666667
(2, 1.0, 1.0, 0.225): 0.82962962963
(3, 100.0, 100.0, 0.25): 0.925925925926
(4, 1.0, 1.0, 0.275): 0.674074074074
(5, 100.0, 100.0, 0.25): 0.659259259259
(6, 10.0, 10.0, 0.225): 0.896296296296
(7, 100.0, 100.0, 0.25): 0.711111111111
(8, 10.0, 10.0, 0.25): 0.733333333333
(9, 0.1, 0.1, 0.25): 0.903703703704
Loss on training set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 100.0, 100.0, 0.275): 0.333333333333
(1, 100.0, 100.0, 0.225): 0.333333333333
(2, 1.0, 1.0, 0.225): 0.17037037037
(3, 100.0, 100.0, 0.25): 0.0740740740741
(4, 1.0, 1.0, 0.275): 0.325925925926
(5, 100.0, 100.0, 0.25): 0.340740740741
(6, 10.0, 10.0, 0.225): 0.103703703704
(7, 100.0, 100.0, 0.25): 0.288888888889
(8, 10.0, 10.0, 0.25): 0.266666666667
(9, 0.1, 0.1, 0.25): 0.0962962962963

Accuracy mean :0.7666666666666667
Std deviation :0.10450746719535632
Loss mean :0.23333333333333334
Std deviation :0.10450746719535632

On ALL the sets

Accuracy on all the set for every iteration, for every couple c,sigma (n_of_the_iter, c, sigma):
(0, 0.1, 0.1, 0.25): 0.466666666667
(0, 0.1, 0.1, 0.3): 0.466666666667
(0, 1.0, 1.0, 0.2): 0.333333333333
(0, 1.0, 1.0, 0.225): 0.466666666667
(0, 1.0, 1.0, 0.25): 0.466666666667
(0, 1.0, 1.0, 0.275): 0.133333333333
(0, 1.0, 1.0, 0.3): 0.466666666667
(0, 10.0, 10.0, 0.2): 0.466666666667
(0, 10.0, 10.0, 0.225): 0.466666666667
(0, 10.0, 10.0, 0.25): 0.466666666667
(0, 10.0, 10.0, 0.275): 0.8
(0, 10.0, 10.0, 0.3): 0.6
(0, 100.0, 100.0, 0.2): 0.333333333333
(0, 100.0, 100.0, 0.225): 0.466666666667
(0, 100.0, 100.0, 0.25): 0.466666666667
(0, 100.0, 100.0, 0.275): 0.8
(0, 100.0, 100.0, 0.3): 0.6
(1, 0.1, 0.1, 0.25): 0.6
(1, 0.1, 0.1, 0.3): 0.6
(1, 1.0, 1.0, 0.2): 0.333333333333
(1, 1.0, 1.0, 0.225): 0.733333333333
(1, 1.0, 1.0, 0.25): 0.6
(1, 1.0, 1.0, 0.275): 0.6
(1, 1.0, 1.0, 0.3): 0.6
(1, 10.0, 10.0, 0.2): 0.333333333333
(1, 10.0, 10.0, 0.225): 0.733333333333
(1, 10.0, 10.0, 0.25): 0.6
(1, 10.0, 10.0, 0.275): 0.6
(1, 10.0, 10.0, 0.3): 0.6
(1, 100.0, 100.0, 0.2): 0.333333333333
(1, 100.0, 100.0, 0.225): 0.733333333333
(1, 100.0, 100.0, 0.25): 0.6
(1, 100.0, 100.0, 0.275): 0.6
(1, 100.0, 100.0, 0.3): 0.6
(2, 1.0, 1.0, 0.2): 0.4
(2, 1.0, 1.0, 0.225): 0.933333333333
(2, 1.0, 1.0, 0.25): 0.866666666667
(2, 1.0, 1.0, 0.275): 0.866666666667
(2, 1.0, 1.0, 0.3): 0.6
(2, 10.0, 10.0, 0.2): 0.4
(2, 10.0, 10.0, 0.225): 0.933333333333
(2, 10.0, 10.0, 0.25): 0.866666666667
(2, 10.0, 10.0, 0.275): 0.933333333333
(2, 10.0, 10.0, 0.3): 0.6
(2, 100.0, 100.0, 0.2): 0.4
(2, 100.0, 100.0, 0.225): 0.933333333333
(2, 100.0, 100.0, 0.25): 0.866666666667
(2, 100.0, 100.0, 0.275): 0.866666666667
(2, 100.0, 100.0, 0.3): 0.6
(3, 0.1, 0.1, 0.275): 0.933333333333
(3, 1.0, 1.0, 0.225): 0.266666666667
(3, 1.0, 1.0, 0.25): 1.0
(3, 1.0, 1.0, 0.275): 0.933333333333
(3, 1.0, 1.0, 0.3): 0.733333333333
(3, 10.0, 10.0, 0.225): 0.266666666667
(3, 10.0, 10.0, 0.25): 1.0
(3, 10.0, 10.0, 0.275): 1.0
(3, 10.0, 10.0, 0.3): 0.733333333333
(3, 100.0, 100.0, 0.2): 0.333333333333
(3, 100.0, 100.0, 0.225): 0.266666666667
(3, 100.0, 100.0, 0.25): 1.0
(3, 100.0, 100.0, 0.275): 0.933333333333
(3, 100.0, 100.0, 0.3): 0.733333333333
(4, 0.1, 0.1, 0.3): 0.733333333333
(4, 1.0, 1.0, 0.2): 0.4
(4, 1.0, 1.0, 0.275): 0.933333333333
(4, 1.0, 1.0, 0.3): 0.733333333333
(4, 10.0, 10.0, 0.2): 0.466666666667
(4, 10.0, 10.0, 0.225): 0.8
(4, 10.0, 10.0, 0.275): 0.933333333333
(4, 10.0, 10.0, 0.3): 0.733333333333
(4, 100.0, 100.0, 0.2): 0.466666666667
(4, 100.0, 100.0, 0.225): 0.8
(4, 100.0, 100.0, 0.275): 0.933333333333
(4, 100.0, 100.0, 0.3): 0.733333333333
(5, 0.1, 0.1, 0.3): 0.466666666667
(5, 1.0, 1.0, 0.2): 0.0666666666667
(5, 1.0, 1.0, 0.225): 0.933333333333
(5, 1.0, 1.0, 0.25): 1.0
(5, 1.0, 1.0, 0.275): 0.466666666667
(5, 1.0, 1.0, 0.3): 0.466666666667
(5, 10.0, 10.0, 0.2): 0.0666666666667
(5, 10.0, 10.0, 0.225): 0.0666666666667
(5, 10.0, 10.0, 0.25): 1.0
(5, 10.0, 10.0, 0.275): 0.466666666667
(5, 10.0, 10.0, 0.3): 0.466666666667
(5, 100.0, 100.0, 0.2): 0.0666666666667
(5, 100.0, 100.0, 0.225): 0.0666666666667
(5, 100.0, 100.0, 0.25): 1.0
(5, 100.0, 100.0, 0.275): 0.466666666667
(5, 100.0, 100.0, 0.3): 0.466666666667
(6, 0.1, 0.1, 0.25): 0.733333333333
(6, 0.1, 0.1, 0.3): 0.733333333333
(6, 1.0, 1.0, 0.2): 0.6
(6, 1.0, 1.0, 0.225): 0.933333333333
(6, 1.0, 1.0, 0.25): 0.733333333333
(6, 1.0, 1.0, 0.275): 0.733333333333
(6, 1.0, 1.0, 0.3): 0.733333333333
(6, 10.0, 10.0, 0.2): 0.466666666667
(6, 10.0, 10.0, 0.225): 0.933333333333
(6, 10.0, 10.0, 0.25): 0.733333333333
(6, 10.0, 10.0, 0.275): 0.733333333333
(6, 10.0, 10.0, 0.3): 0.733333333333
(6, 100.0, 100.0, 0.225): 0.733333333333
(6, 100.0, 100.0, 0.25): 0.733333333333
(6, 100.0, 100.0, 0.3): 0.733333333333
(7, 0.1, 0.1, 0.25): 0.733333333333
(7, 0.1, 0.1, 0.275): 0.733333333333
(7, 0.1, 0.1, 0.3): 0.733333333333
(7, 1.0, 1.0, 0.2): 0.4
(7, 1.0, 1.0, 0.225): 0.6
(7, 1.0, 1.0, 0.25): 0.733333333333
(7, 1.0, 1.0, 0.275): 0.733333333333
(7, 1.0, 1.0, 0.3): 0.733333333333
(7, 10.0, 10.0, 0.2): 0.533333333333
(7, 10.0, 10.0, 0.225): 0.666666666667
(7, 10.0, 10.0, 0.25): 0.733333333333
(7, 10.0, 10.0, 0.275): 0.733333333333
(7, 10.0, 10.0, 0.3): 0.333333333333
(7, 100.0, 100.0, 0.2): 0.4
(7, 100.0, 100.0, 0.225): 0.6
(7, 100.0, 100.0, 0.25): 0.733333333333
(7, 100.0, 100.0, 0.275): 0.733333333333
(7, 100.0, 100.0, 0.3): 0.333333333333
(8, 0.1, 0.1, 0.275): 0.666666666667
(8, 0.1, 0.1, 0.3): 0.666666666667
(8, 1.0, 1.0, 0.2): 0.666666666667
(8, 1.0, 1.0, 0.225): 0.733333333333
(8, 1.0, 1.0, 0.25): 0.866666666667
(8, 1.0, 1.0, 0.275): 0.666666666667
(8, 1.0, 1.0, 0.3): 0.666666666667
(8, 10.0, 10.0, 0.2): 0.666666666667
(8, 10.0, 10.0, 0.225): 0.733333333333
(8, 10.0, 10.0, 0.25): 0.866666666667
(8, 10.0, 10.0, 0.275): 0.666666666667
(8, 10.0, 10.0, 0.3): 0.666666666667
(8, 100.0, 100.0, 0.2): 0.666666666667
(8, 100.0, 100.0, 0.225): 0.733333333333
(8, 100.0, 100.0, 0.25): 0.866666666667
(8, 100.0, 100.0, 0.275): 0.666666666667
(8, 100.0, 100.0, 0.3): 0.666666666667
(9, 0.1, 0.1, 0.25): 0.666666666667
(9, 0.1, 0.1, 0.275): 0.666666666667
(9, 0.1, 0.1, 0.3): 0.666666666667
(9, 1.0, 1.0, 0.2): 0.266666666667
(9, 1.0, 1.0, 0.225): 0.266666666667
(9, 1.0, 1.0, 0.25): 0.666666666667
(9, 1.0, 1.0, 0.275): 0.666666666667
(9, 1.0, 1.0, 0.3): 0.666666666667
(9, 10.0, 10.0, 0.2): 0.266666666667
(9, 10.0, 10.0, 0.225): 0.266666666667
(9, 10.0, 10.0, 0.25): 0.666666666667
(9, 10.0, 10.0, 0.275): 0.666666666667
(9, 10.0, 10.0, 0.3): 0.666666666667
(9, 100.0, 100.0, 0.2): 0.266666666667
(9, 100.0, 100.0, 0.225): 0.266666666667
(9, 100.0, 100.0, 0.25): 0.666666666667
(9, 100.0, 100.0, 0.275): 0.666666666667
(9, 100.0, 100.0, 0.3): 0.666666666667

Loss on all the set for every iteration, for every couple c,sigma (n_of_the_iter, best_c, best_sigma):
(0, 0.1, 0.1, 0.25): 0.533333333333
(0, 0.1, 0.1, 0.3): 0.533333333333
(0, 1.0, 1.0, 0.2): 0.666666666667
(0, 1.0, 1.0, 0.225): 0.533333333333
(0, 1.0, 1.0, 0.25): 0.533333333333
(0, 1.0, 1.0, 0.275): 0.866666666667
(0, 1.0, 1.0, 0.3): 0.533333333333
(0, 10.0, 10.0, 0.2): 0.533333333333
(0, 10.0, 10.0, 0.225): 0.533333333333
(0, 10.0, 10.0, 0.25): 0.533333333333
(0, 10.0, 10.0, 0.275): 0.2
(0, 10.0, 10.0, 0.3): 0.4
(0, 100.0, 100.0, 0.2): 0.666666666667
(0, 100.0, 100.0, 0.225): 0.533333333333
(0, 100.0, 100.0, 0.25): 0.533333333333
(0, 100.0, 100.0, 0.275): 0.2
(0, 100.0, 100.0, 0.3): 0.4
(1, 0.1, 0.1, 0.25): 0.4
(1, 0.1, 0.1, 0.3): 0.4
(1, 1.0, 1.0, 0.2): 0.666666666667
(1, 1.0, 1.0, 0.225): 0.266666666667
(1, 1.0, 1.0, 0.25): 0.4
(1, 1.0, 1.0, 0.275): 0.4
(1, 1.0, 1.0, 0.3): 0.4
(1, 10.0, 10.0, 0.2): 0.666666666667
(1, 10.0, 10.0, 0.225): 0.266666666667
(1, 10.0, 10.0, 0.25): 0.4
(1, 10.0, 10.0, 0.275): 0.4
(1, 10.0, 10.0, 0.3): 0.4
(1, 100.0, 100.0, 0.2): 0.666666666667
(1, 100.0, 100.0, 0.225): 0.266666666667
(1, 100.0, 100.0, 0.25): 0.4
(1, 100.0, 100.0, 0.275): 0.4
(1, 100.0, 100.0, 0.3): 0.4
(2, 1.0, 1.0, 0.2): 0.6
(2, 1.0, 1.0, 0.225): 0.0666666666667
(2, 1.0, 1.0, 0.25): 0.133333333333
(2, 1.0, 1.0, 0.275): 0.133333333333
(2, 1.0, 1.0, 0.3): 0.4
(2, 10.0, 10.0, 0.2): 0.6
(2, 10.0, 10.0, 0.225): 0.0666666666667
(2, 10.0, 10.0, 0.25): 0.133333333333
(2, 10.0, 10.0, 0.275): 0.0666666666667
(2, 10.0, 10.0, 0.3): 0.4
(2, 100.0, 100.0, 0.2): 0.6
(2, 100.0, 100.0, 0.225): 0.0666666666667
(2, 100.0, 100.0, 0.25): 0.133333333333
(2, 100.0, 100.0, 0.275): 0.133333333333
(2, 100.0, 100.0, 0.3): 0.4
(3, 0.1, 0.1, 0.275): 0.0666666666667
(3, 1.0, 1.0, 0.225): 0.733333333333
(3, 1.0, 1.0, 0.25): 0.0
(3, 1.0, 1.0, 0.275): 0.0666666666667
(3, 1.0, 1.0, 0.3): 0.266666666667
(3, 10.0, 10.0, 0.225): 0.733333333333
(3, 10.0, 10.0, 0.25): 0.0
(3, 10.0, 10.0, 0.275): 0.0
(3, 10.0, 10.0, 0.3): 0.266666666667
(3, 100.0, 100.0, 0.2): 0.666666666667
(3, 100.0, 100.0, 0.225): 0.733333333333
(3, 100.0, 100.0, 0.25): 0.0
(3, 100.0, 100.0, 0.275): 0.0666666666667
(3, 100.0, 100.0, 0.3): 0.266666666667
(4, 0.1, 0.1, 0.3): 0.266666666667
(4, 1.0, 1.0, 0.2): 0.6
(4, 1.0, 1.0, 0.275): 0.0666666666667
(4, 1.0, 1.0, 0.3): 0.266666666667
(4, 10.0, 10.0, 0.2): 0.533333333333
(4, 10.0, 10.0, 0.225): 0.2
(4, 10.0, 10.0, 0.275): 0.0666666666667
(4, 10.0, 10.0, 0.3): 0.266666666667
(4, 100.0, 100.0, 0.2): 0.533333333333
(4, 100.0, 100.0, 0.225): 0.2
(4, 100.0, 100.0, 0.275): 0.0666666666667
(4, 100.0, 100.0, 0.3): 0.266666666667
(5, 0.1, 0.1, 0.3): 0.533333333333
(5, 1.0, 1.0, 0.2): 0.933333333333
(5, 1.0, 1.0, 0.225): 0.0666666666667
(5, 1.0, 1.0, 0.25): 0.0
(5, 1.0, 1.0, 0.275): 0.533333333333
(5, 1.0, 1.0, 0.3): 0.533333333333
(5, 10.0, 10.0, 0.2): 0.933333333333
(5, 10.0, 10.0, 0.225): 0.933333333333
(5, 10.0, 10.0, 0.25): 0.0
(5, 10.0, 10.0, 0.275): 0.533333333333
(5, 10.0, 10.0, 0.3): 0.533333333333
(5, 100.0, 100.0, 0.2): 0.933333333333
(5, 100.0, 100.0, 0.225): 0.933333333333
(5, 100.0, 100.0, 0.25): 0.0
(5, 100.0, 100.0, 0.275): 0.533333333333
(5, 100.0, 100.0, 0.3): 0.533333333333
(6, 0.1, 0.1, 0.25): 0.266666666667
(6, 0.1, 0.1, 0.3): 0.266666666667
(6, 1.0, 1.0, 0.2): 0.4
(6, 1.0, 1.0, 0.225): 0.0666666666667
(6, 1.0, 1.0, 0.25): 0.266666666667
(6, 1.0, 1.0, 0.275): 0.266666666667
(6, 1.0, 1.0, 0.3): 0.266666666667
(6, 10.0, 10.0, 0.2): 0.533333333333
(6, 10.0, 10.0, 0.225): 0.0666666666667
(6, 10.0, 10.0, 0.25): 0.266666666667
(6, 10.0, 10.0, 0.275): 0.266666666667
(6, 10.0, 10.0, 0.3): 0.266666666667
(6, 100.0, 100.0, 0.225): 0.266666666667
(6, 100.0, 100.0, 0.25): 0.266666666667
(6, 100.0, 100.0, 0.3): 0.266666666667
(7, 0.1, 0.1, 0.25): 0.266666666667
(7, 0.1, 0.1, 0.275): 0.266666666667
(7, 0.1, 0.1, 0.3): 0.266666666667
(7, 1.0, 1.0, 0.2): 0.6
(7, 1.0, 1.0, 0.225): 0.4
(7, 1.0, 1.0, 0.25): 0.266666666667
(7, 1.0, 1.0, 0.275): 0.266666666667
(7, 1.0, 1.0, 0.3): 0.266666666667
(7, 10.0, 10.0, 0.2): 0.466666666667
(7, 10.0, 10.0, 0.225): 0.333333333333
(7, 10.0, 10.0, 0.25): 0.266666666667
(7, 10.0, 10.0, 0.275): 0.266666666667
(7, 10.0, 10.0, 0.3): 0.666666666667
(7, 100.0, 100.0, 0.2): 0.6
(7, 100.0, 100.0, 0.225): 0.4
(7, 100.0, 100.0, 0.25): 0.266666666667
(7, 100.0, 100.0, 0.275): 0.266666666667
(7, 100.0, 100.0, 0.3): 0.666666666667
(8, 0.1, 0.1, 0.275): 0.333333333333
(8, 0.1, 0.1, 0.3): 0.333333333333
(8, 1.0, 1.0, 0.2): 0.333333333333
(8, 1.0, 1.0, 0.225): 0.266666666667
(8, 1.0, 1.0, 0.25): 0.133333333333
(8, 1.0, 1.0, 0.275): 0.333333333333
(8, 1.0, 1.0, 0.3): 0.333333333333
(8, 10.0, 10.0, 0.2): 0.333333333333
(8, 10.0, 10.0, 0.225): 0.266666666667
(8, 10.0, 10.0, 0.25): 0.133333333333
(8, 10.0, 10.0, 0.275): 0.333333333333
(8, 10.0, 10.0, 0.3): 0.333333333333
(8, 100.0, 100.0, 0.2): 0.333333333333
(8, 100.0, 100.0, 0.225): 0.266666666667
(8, 100.0, 100.0, 0.25): 0.133333333333
(8, 100.0, 100.0, 0.275): 0.333333333333
(8, 100.0, 100.0, 0.3): 0.333333333333
(9, 0.1, 0.1, 0.25): 0.333333333333
(9, 0.1, 0.1, 0.275): 0.333333333333
(9, 0.1, 0.1, 0.3): 0.333333333333
(9, 1.0, 1.0, 0.2): 0.733333333333
(9, 1.0, 1.0, 0.225): 0.733333333333
(9, 1.0, 1.0, 0.25): 0.333333333333
(9, 1.0, 1.0, 0.275): 0.333333333333
(9, 1.0, 1.0, 0.3): 0.333333333333
(9, 10.0, 10.0, 0.2): 0.733333333333
(9, 10.0, 10.0, 0.225): 0.733333333333
(9, 10.0, 10.0, 0.25): 0.333333333333
(9, 10.0, 10.0, 0.275): 0.333333333333
(9, 10.0, 10.0, 0.3): 0.333333333333
(9, 100.0, 100.0, 0.2): 0.733333333333
(9, 100.0, 100.0, 0.225): 0.733333333333
(9, 100.0, 100.0, 0.25): 0.333333333333
(9, 100.0, 100.0, 0.275): 0.333333333333
(9, 100.0, 100.0, 0.3): 0.333333333333

Accuracy mean :0.6251572327044026
Std deviation :0.22024435261452102
Loss mean :0.3748427672955975
Std deviation :0.22024435261452097



QuantileConstPiecewise_4dim, number of iterations: 10

Parameters info
Tradeoffs parameter: [  0.1   1.   10.  100. ]
Using same parameters for all the clusterization: True
Gaussian kernel sigmas: [0.2   0.225 0.25  0.275 0.3  ]
Number of principal dimension considerated: 4
Dataset length: 150

Clusterization info
Minimum size of a cluster: in perc: 0.01, in int: 2
Type of mu: Binary Muzzifier
Fuzzifier: QuantileConstPiecewise
Cluster graph uses all connections: False
Cluster to label info
Force the number of cluster to be the number of different labels: False
Force the labels to be always represent by a cluster: False

Validation info
Conflict resolution: random
Number of cluster considerated for validation (top_k): None


RESULTS

On TEST set

Accuracy on test set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 0.1, 0.1, 0.3): 0.133333333333
(1, 1.0, 1.0, 0.3): 0.333333333333
(2, 0.1, 0.1, 0.275): 0.266666666667
(3, 1.0, 1.0, 0.25): 0.533333333333
(4, 100.0, 100.0, 0.25): 0.533333333333
(5, 10.0, 10.0, 0.275): 0.333333333333
(6, 10.0, 10.0, 0.225): 0.266666666667
(7, 100.0, 100.0, 0.25): 0.0666666666667
(8, 10.0, 10.0, 0.25): 0.533333333333
(9, 100.0, 100.0, 0.225): 0.333333333333

Loss on test set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 0.1, 0.1, 0.3): 0.866666666667
(1, 1.0, 1.0, 0.3): 0.666666666667
(2, 0.1, 0.1, 0.275): 0.733333333333
(3, 1.0, 1.0, 0.25): 0.466666666667
(4, 100.0, 100.0, 0.25): 0.466666666667
(5, 10.0, 10.0, 0.275): 0.666666666667
(6, 10.0, 10.0, 0.225): 0.733333333333
(7, 100.0, 100.0, 0.25): 0.933333333333
(8, 10.0, 10.0, 0.25): 0.466666666667
(9, 100.0, 100.0, 0.225): 0.666666666667

Accuracy mean :0.33333333333333337
Std deviation :0.15491933384829668
Loss mean :0.6666666666666667
Std deviation :0.15491933384829668

On TRAINING set

Accuracy on training set for every iteration (n_of_the_iter, c, sigma):
(0, 0.1, 0.1, 0.3): 0.355555555556
(1, 1.0, 1.0, 0.3): 0.466666666667
(2, 0.1, 0.1, 0.275): 0.451851851852
(3, 1.0, 1.0, 0.25): 0.481481481481
(4, 100.0, 100.0, 0.25): 0.444444444444
(5, 10.0, 10.0, 0.275): 0.451851851852
(6, 10.0, 10.0, 0.225): 0.333333333333
(7, 100.0, 100.0, 0.25): 0.37037037037
(8, 10.0, 10.0, 0.25): 0.385185185185
(9, 100.0, 100.0, 0.225): 0.362962962963
Loss on training set for every iteration (n_of_the_iter, best_c, best_sigma):
(0, 0.1, 0.1, 0.3): 0.644444444444
(1, 1.0, 1.0, 0.3): 0.533333333333
(2, 0.1, 0.1, 0.275): 0.548148148148
(3, 1.0, 1.0, 0.25): 0.518518518519
(4, 100.0, 100.0, 0.25): 0.555555555556
(5, 10.0, 10.0, 0.275): 0.548148148148
(6, 10.0, 10.0, 0.225): 0.666666666667
(7, 100.0, 100.0, 0.25): 0.62962962963
(8, 10.0, 10.0, 0.25): 0.614814814815
(9, 100.0, 100.0, 0.225): 0.637037037037

Accuracy mean :0.4103703703703704
Std deviation :0.05123441915789802
Loss mean :0.5896296296296296
Std deviation :0.051234419157898024

On ALL the sets

Accuracy on all the set for every iteration, for every couple c,sigma (n_of_the_iter, c, sigma):
(0, 0.1, 0.1, 0.25): 0.266666666667
(0, 0.1, 0.1, 0.275): 0.133333333333
(0, 0.1, 0.1, 0.3): 0.466666666667
(0, 1.0, 1.0, 0.2): 0.333333333333
(0, 1.0, 1.0, 0.225): 0.266666666667
(0, 1.0, 1.0, 0.25): 0.4
(0, 1.0, 1.0, 0.275): 0.2
(0, 1.0, 1.0, 0.3): 0.466666666667
(0, 10.0, 10.0, 0.2): 0.2
(0, 10.0, 10.0, 0.225): 0.333333333333
(0, 10.0, 10.0, 0.25): 0.266666666667
(0, 10.0, 10.0, 0.275): 0.333333333333
(0, 10.0, 10.0, 0.3): 0.4
(0, 100.0, 100.0, 0.2): 0.4
(0, 100.0, 100.0, 0.225): 0.0666666666667
(0, 100.0, 100.0, 0.25): 0.333333333333
(0, 100.0, 100.0, 0.275): 0.333333333333
(0, 100.0, 100.0, 0.3): 0.333333333333
(1, 0.1, 0.1, 0.275): 0.266666666667
(1, 0.1, 0.1, 0.3): 0.333333333333
(1, 1.0, 1.0, 0.2): 0.133333333333
(1, 1.0, 1.0, 0.225): 0.2
(1, 1.0, 1.0, 0.25): 0.133333333333
(1, 1.0, 1.0, 0.275): 0.4
(1, 1.0, 1.0, 0.3): 0.533333333333
(1, 10.0, 10.0, 0.2): 0.133333333333
(1, 10.0, 10.0, 0.225): 0.2
(1, 10.0, 10.0, 0.25): 0.133333333333
(1, 10.0, 10.0, 0.275): 0.266666666667
(1, 10.0, 10.0, 0.3): 0.266666666667
(1, 100.0, 100.0, 0.2): 0.133333333333
(1, 100.0, 100.0, 0.225): 0.4
(1, 100.0, 100.0, 0.25): 0.133333333333
(1, 100.0, 100.0, 0.275): 0.266666666667
(1, 100.0, 100.0, 0.3): 0.266666666667
(2, 0.1, 0.1, 0.2): 0.2
(2, 0.1, 0.1, 0.275): 0.533333333333
(2, 0.1, 0.1, 0.3): 0.4
(2, 1.0, 1.0, 0.2): 0.2
(2, 1.0, 1.0, 0.225): 0.2
(2, 1.0, 1.0, 0.25): 0.333333333333
(2, 1.0, 1.0, 0.275): 0.466666666667
(2, 1.0, 1.0, 0.3): 0.533333333333
(2, 10.0, 10.0, 0.2): 0.2
(2, 10.0, 10.0, 0.225): 0.333333333333
(2, 10.0, 10.0, 0.25): 0.466666666667
(2, 10.0, 10.0, 0.275): 0.4
(2, 10.0, 10.0, 0.3): 0.266666666667
(2, 100.0, 100.0, 0.2): 0.2
(2, 100.0, 100.0, 0.225): 0.4
(2, 100.0, 100.0, 0.25): 0.133333333333
(2, 100.0, 100.0, 0.275): 0.466666666667
(2, 100.0, 100.0, 0.3): 0.4
(3, 0.1, 0.1, 0.25): 0.2
(3, 0.1, 0.1, 0.275): 0.333333333333
(3, 1.0, 1.0, 0.225): 0.4
(3, 1.0, 1.0, 0.25): 0.533333333333
(3, 1.0, 1.0, 0.275): 0.2
(3, 1.0, 1.0, 0.3): 0.2
(3, 10.0, 10.0, 0.2): 0.533333333333
(3, 10.0, 10.0, 0.225): 0.2
(3, 10.0, 10.0, 0.25): 0.4
(3, 10.0, 10.0, 0.275): 0.266666666667
(3, 10.0, 10.0, 0.3): 0.333333333333
(3, 100.0, 100.0, 0.225): 0.2
(3, 100.0, 100.0, 0.25): 0.466666666667
(3, 100.0, 100.0, 0.275): 0.333333333333
(3, 100.0, 100.0, 0.3): 0.333333333333
(4, 0.1, 0.1, 0.275): 0.266666666667
(4, 1.0, 1.0, 0.25): 0.4
(4, 1.0, 1.0, 0.275): 0.533333333333
(4, 1.0, 1.0, 0.3): 0.2
(4, 10.0, 10.0, 0.25): 0.266666666667
(4, 10.0, 10.0, 0.275): 0.333333333333
(4, 10.0, 10.0, 0.3): 0.2
(4, 100.0, 100.0, 0.2): 0.2
(4, 100.0, 100.0, 0.225): 0.333333333333
(4, 100.0, 100.0, 0.25): 0.533333333333
(4, 100.0, 100.0, 0.275): 0.333333333333
(4, 100.0, 100.0, 0.3): 0.0666666666667
(5, 0.1, 0.1, 0.275): 0.4
(5, 0.1, 0.1, 0.3): 0.466666666667
(5, 1.0, 1.0, 0.2): 0.466666666667
(5, 1.0, 1.0, 0.225): 0.4
(5, 1.0, 1.0, 0.25): 0.466666666667
(5, 1.0, 1.0, 0.275): 0.4
(5, 1.0, 1.0, 0.3): 0.466666666667
(5, 10.0, 10.0, 0.2): 0.533333333333
(5, 10.0, 10.0, 0.225): 0.4
(5, 10.0, 10.0, 0.25): 0.4
(5, 10.0, 10.0, 0.275): 0.533333333333
(5, 10.0, 10.0, 0.3): 0.466666666667
(5, 100.0, 100.0, 0.2): 0.466666666667
(5, 100.0, 100.0, 0.225): 0.466666666667
(5, 100.0, 100.0, 0.25): 0.466666666667
(5, 100.0, 100.0, 0.275): 0.466666666667
(5, 100.0, 100.0, 0.3): 0.466666666667
(6, 0.1, 0.1, 0.2): 0.2
(6, 0.1, 0.1, 0.275): 0.2
(6, 0.1, 0.1, 0.3): 0.266666666667
(6, 1.0, 1.0, 0.2): 0.2
(6, 1.0, 1.0, 0.225): 0.2
(6, 1.0, 1.0, 0.25): 0.333333333333
(6, 1.0, 1.0, 0.275): 0.4
(6, 1.0, 1.0, 0.3): 0.333333333333
(6, 10.0, 10.0, 0.2): 0.4
(6, 10.0, 10.0, 0.225): 0.533333333333
(6, 10.0, 10.0, 0.25): 0.266666666667
(6, 10.0, 10.0, 0.275): 0.266666666667
(6, 10.0, 10.0, 0.3): 0.4
(6, 100.0, 100.0, 0.2): 0.266666666667
(6, 100.0, 100.0, 0.225): 0.466666666667
(6, 100.0, 100.0, 0.25): 0.2
(6, 100.0, 100.0, 0.275): 0.4
(6, 100.0, 100.0, 0.3): 0.133333333333
(7, 0.1, 0.1, 0.275): 0.466666666667
(7, 1.0, 1.0, 0.2): 0.333333333333
(7, 1.0, 1.0, 0.225): 0.266666666667
(7, 1.0, 1.0, 0.25): 0.266666666667
(7, 1.0, 1.0, 0.275): 0.266666666667
(7, 1.0, 1.0, 0.3): 0.466666666667
(7, 10.0, 10.0, 0.2): 0.266666666667
(7, 10.0, 10.0, 0.225): 0.266666666667
(7, 10.0, 10.0, 0.25): 0.266666666667
(7, 10.0, 10.0, 0.275): 0.266666666667
(7, 10.0, 10.0, 0.3): 0.4
(7, 100.0, 100.0, 0.2): 0.333333333333
(7, 100.0, 100.0, 0.225): 0.266666666667
(7, 100.0, 100.0, 0.25): 0.533333333333
(7, 100.0, 100.0, 0.275): 0.333333333333
(7, 100.0, 100.0, 0.3): 0.466666666667
(8, 0.1, 0.1, 0.275): 0.2
(8, 1.0, 1.0, 0.2): 0.133333333333
(8, 1.0, 1.0, 0.225): 0.333333333333
(8, 1.0, 1.0, 0.25): 0.2
(8, 1.0, 1.0, 0.275): 0.266666666667
(8, 1.0, 1.0, 0.3): 0.266666666667
(8, 10.0, 10.0, 0.2): 0.266666666667
(8, 10.0, 10.0, 0.225): 0.266666666667
(8, 10.0, 10.0, 0.25): 0.466666666667
(8, 10.0, 10.0, 0.275): 0.266666666667
(8, 10.0, 10.0, 0.3): 0.133333333333
(8, 100.0, 100.0, 0.2): 0.266666666667
(8, 100.0, 100.0, 0.225): 0.266666666667
(8, 100.0, 100.0, 0.25): 0.4
(8, 100.0, 100.0, 0.275): 0.333333333333
(8, 100.0, 100.0, 0.3): 0.2
(9, 0.1, 0.1, 0.225): 0.466666666667
(9, 1.0, 1.0, 0.2): 0.466666666667
(9, 1.0, 1.0, 0.225): 0.333333333333
(9, 1.0, 1.0, 0.25): 0.266666666667
(9, 1.0, 1.0, 0.275): 0.266666666667
(9, 1.0, 1.0, 0.3): 0.533333333333
(9, 10.0, 10.0, 0.2): 0.333333333333
(9, 10.0, 10.0, 0.225): 0.2
(9, 10.0, 10.0, 0.25): 0.266666666667
(9, 10.0, 10.0, 0.275): 0.266666666667
(9, 10.0, 10.0, 0.3): 0.333333333333
(9, 100.0, 100.0, 0.2): 0.4
(9, 100.0, 100.0, 0.225): 0.6
(9, 100.0, 100.0, 0.25): 0.4
(9, 100.0, 100.0, 0.275): 0.266666666667
(9, 100.0, 100.0, 0.3): 0.466666666667

Loss on all the set for every iteration, for every couple c,sigma (n_of_the_iter, best_c, best_sigma):
(0, 0.1, 0.1, 0.25): 0.733333333333
(0, 0.1, 0.1, 0.275): 0.866666666667
(0, 0.1, 0.1, 0.3): 0.533333333333
(0, 1.0, 1.0, 0.2): 0.666666666667
(0, 1.0, 1.0, 0.225): 0.733333333333
(0, 1.0, 1.0, 0.25): 0.6
(0, 1.0, 1.0, 0.275): 0.8
(0, 1.0, 1.0, 0.3): 0.533333333333
(0, 10.0, 10.0, 0.2): 0.8
(0, 10.0, 10.0, 0.225): 0.666666666667
(0, 10.0, 10.0, 0.25): 0.733333333333
(0, 10.0, 10.0, 0.275): 0.666666666667
(0, 10.0, 10.0, 0.3): 0.6
(0, 100.0, 100.0, 0.2): 0.6
(0, 100.0, 100.0, 0.225): 0.933333333333
(0, 100.0, 100.0, 0.25): 0.666666666667
(0, 100.0, 100.0, 0.275): 0.666666666667
(0, 100.0, 100.0, 0.3): 0.666666666667
(1, 0.1, 0.1, 0.275): 0.733333333333
(1, 0.1, 0.1, 0.3): 0.666666666667
(1, 1.0, 1.0, 0.2): 0.866666666667
(1, 1.0, 1.0, 0.225): 0.8
(1, 1.0, 1.0, 0.25): 0.866666666667
(1, 1.0, 1.0, 0.275): 0.6
(1, 1.0, 1.0, 0.3): 0.466666666667
(1, 10.0, 10.0, 0.2): 0.866666666667
(1, 10.0, 10.0, 0.225): 0.8
(1, 10.0, 10.0, 0.25): 0.866666666667
(1, 10.0, 10.0, 0.275): 0.733333333333
(1, 10.0, 10.0, 0.3): 0.733333333333
(1, 100.0, 100.0, 0.2): 0.866666666667
(1, 100.0, 100.0, 0.225): 0.6
(1, 100.0, 100.0, 0.25): 0.866666666667
(1, 100.0, 100.0, 0.275): 0.733333333333
(1, 100.0, 100.0, 0.3): 0.733333333333
(2, 0.1, 0.1, 0.2): 0.8
(2, 0.1, 0.1, 0.275): 0.466666666667
(2, 0.1, 0.1, 0.3): 0.6
(2, 1.0, 1.0, 0.2): 0.8
(2, 1.0, 1.0, 0.225): 0.8
(2, 1.0, 1.0, 0.25): 0.666666666667
(2, 1.0, 1.0, 0.275): 0.533333333333
(2, 1.0, 1.0, 0.3): 0.466666666667
(2, 10.0, 10.0, 0.2): 0.8
(2, 10.0, 10.0, 0.225): 0.666666666667
(2, 10.0, 10.0, 0.25): 0.533333333333
(2, 10.0, 10.0, 0.275): 0.6
(2, 10.0, 10.0, 0.3): 0.733333333333
(2, 100.0, 100.0, 0.2): 0.8
(2, 100.0, 100.0, 0.225): 0.6
(2, 100.0, 100.0, 0.25): 0.866666666667
(2, 100.0, 100.0, 0.275): 0.533333333333
(2, 100.0, 100.0, 0.3): 0.6
(3, 0.1, 0.1, 0.25): 0.8
(3, 0.1, 0.1, 0.275): 0.666666666667
(3, 1.0, 1.0, 0.225): 0.6
(3, 1.0, 1.0, 0.25): 0.466666666667
(3, 1.0, 1.0, 0.275): 0.8
(3, 1.0, 1.0, 0.3): 0.8
(3, 10.0, 10.0, 0.2): 0.466666666667
(3, 10.0, 10.0, 0.225): 0.8
(3, 10.0, 10.0, 0.25): 0.6
(3, 10.0, 10.0, 0.275): 0.733333333333
(3, 10.0, 10.0, 0.3): 0.666666666667
(3, 100.0, 100.0, 0.225): 0.8
(3, 100.0, 100.0, 0.25): 0.533333333333
(3, 100.0, 100.0, 0.275): 0.666666666667
(3, 100.0, 100.0, 0.3): 0.666666666667
(4, 0.1, 0.1, 0.275): 0.733333333333
(4, 1.0, 1.0, 0.25): 0.6
(4, 1.0, 1.0, 0.275): 0.466666666667
(4, 1.0, 1.0, 0.3): 0.8
(4, 10.0, 10.0, 0.25): 0.733333333333
(4, 10.0, 10.0, 0.275): 0.666666666667
(4, 10.0, 10.0, 0.3): 0.8
(4, 100.0, 100.0, 0.2): 0.8
(4, 100.0, 100.0, 0.225): 0.666666666667
(4, 100.0, 100.0, 0.25): 0.466666666667
(4, 100.0, 100.0, 0.275): 0.666666666667
(4, 100.0, 100.0, 0.3): 0.933333333333
(5, 0.1, 0.1, 0.275): 0.6
(5, 0.1, 0.1, 0.3): 0.533333333333
(5, 1.0, 1.0, 0.2): 0.533333333333
(5, 1.0, 1.0, 0.225): 0.6
(5, 1.0, 1.0, 0.25): 0.533333333333
(5, 1.0, 1.0, 0.275): 0.6
(5, 1.0, 1.0, 0.3): 0.533333333333
(5, 10.0, 10.0, 0.2): 0.466666666667
(5, 10.0, 10.0, 0.225): 0.6
(5, 10.0, 10.0, 0.25): 0.6
(5, 10.0, 10.0, 0.275): 0.466666666667
(5, 10.0, 10.0, 0.3): 0.533333333333
(5, 100.0, 100.0, 0.2): 0.533333333333
(5, 100.0, 100.0, 0.225): 0.533333333333
(5, 100.0, 100.0, 0.25): 0.533333333333
(5, 100.0, 100.0, 0.275): 0.533333333333
(5, 100.0, 100.0, 0.3): 0.533333333333
(6, 0.1, 0.1, 0.2): 0.8
(6, 0.1, 0.1, 0.275): 0.8
(6, 0.1, 0.1, 0.3): 0.733333333333
(6, 1.0, 1.0, 0.2): 0.8
(6, 1.0, 1.0, 0.225): 0.8
(6, 1.0, 1.0, 0.25): 0.666666666667
(6, 1.0, 1.0, 0.275): 0.6
(6, 1.0, 1.0, 0.3): 0.666666666667
(6, 10.0, 10.0, 0.2): 0.6
(6, 10.0, 10.0, 0.225): 0.466666666667
(6, 10.0, 10.0, 0.25): 0.733333333333
(6, 10.0, 10.0, 0.275): 0.733333333333
(6, 10.0, 10.0, 0.3): 0.6
(6, 100.0, 100.0, 0.2): 0.733333333333
(6, 100.0, 100.0, 0.225): 0.533333333333
(6, 100.0, 100.0, 0.25): 0.8
(6, 100.0, 100.0, 0.275): 0.6
(6, 100.0, 100.0, 0.3): 0.866666666667
(7, 0.1, 0.1, 0.275): 0.533333333333
(7, 1.0, 1.0, 0.2): 0.666666666667
(7, 1.0, 1.0, 0.225): 0.733333333333
(7, 1.0, 1.0, 0.25): 0.733333333333
(7, 1.0, 1.0, 0.275): 0.733333333333
(7, 1.0, 1.0, 0.3): 0.533333333333
(7, 10.0, 10.0, 0.2): 0.733333333333
(7, 10.0, 10.0, 0.225): 0.733333333333
(7, 10.0, 10.0, 0.25): 0.733333333333
(7, 10.0, 10.0, 0.275): 0.733333333333
(7, 10.0, 10.0, 0.3): 0.6
(7, 100.0, 100.0, 0.2): 0.666666666667
(7, 100.0, 100.0, 0.225): 0.733333333333
(7, 100.0, 100.0, 0.25): 0.466666666667
(7, 100.0, 100.0, 0.275): 0.666666666667
(7, 100.0, 100.0, 0.3): 0.533333333333
(8, 0.1, 0.1, 0.275): 0.8
(8, 1.0, 1.0, 0.2): 0.866666666667
(8, 1.0, 1.0, 0.225): 0.666666666667
(8, 1.0, 1.0, 0.25): 0.8
(8, 1.0, 1.0, 0.275): 0.733333333333
(8, 1.0, 1.0, 0.3): 0.733333333333
(8, 10.0, 10.0, 0.2): 0.733333333333
(8, 10.0, 10.0, 0.225): 0.733333333333
(8, 10.0, 10.0, 0.25): 0.533333333333
(8, 10.0, 10.0, 0.275): 0.733333333333
(8, 10.0, 10.0, 0.3): 0.866666666667
(8, 100.0, 100.0, 0.2): 0.733333333333
(8, 100.0, 100.0, 0.225): 0.733333333333
(8, 100.0, 100.0, 0.25): 0.6
(8, 100.0, 100.0, 0.275): 0.666666666667
(8, 100.0, 100.0, 0.3): 0.8
(9, 0.1, 0.1, 0.225): 0.533333333333
(9, 1.0, 1.0, 0.2): 0.533333333333
(9, 1.0, 1.0, 0.225): 0.666666666667
(9, 1.0, 1.0, 0.25): 0.733333333333
(9, 1.0, 1.0, 0.275): 0.733333333333
(9, 1.0, 1.0, 0.3): 0.466666666667
(9, 10.0, 10.0, 0.2): 0.666666666667
(9, 10.0, 10.0, 0.225): 0.8
(9, 10.0, 10.0, 0.25): 0.733333333333
(9, 10.0, 10.0, 0.275): 0.733333333333
(9, 10.0, 10.0, 0.3): 0.666666666667
(9, 100.0, 100.0, 0.2): 0.6
(9, 100.0, 100.0, 0.225): 0.4
(9, 100.0, 100.0, 0.25): 0.6
(9, 100.0, 100.0, 0.275): 0.733333333333
(9, 100.0, 100.0, 0.3): 0.533333333333

Accuracy mean :0.3267893660531697
Std deviation :0.11843439595230723
Loss mean :0.6732106339468302
Std deviation :0.11843439595230722



